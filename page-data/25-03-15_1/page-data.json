{"componentChunkName":"component---src-templates-blog-template-js","path":"/25-03-15_1/","result":{"data":{"cur":{"id":"432191ef-a5a1-521e-9966-40d179d9dfe6","html":"<p>논문 : <strong>Burges, C. J. C. (1998). A tutorial on support vector machines for pattern recognition. Data mining and knowledge discovery, 2(2), 121-167.</strong></p>\n<p> </p>\n<p>최근 핸즈온 머신러닝 교재에서 SVM(Support Vector Machine)에 대해 공부하면서 논문을 읽어보고 싶었다. Survey 논문으로 시작하는 것이 좋을 것 같아 논문을 서칭해 ‘패턴 인식을 위한 서포트 벡터 머신 튜토리얼’이라는 주제의 논문을 선택했다. 논문을 읽었을 때 해당 기술에 대한 배경과 의도를 알 수 있어서 좋다. 그 배경을 알면 그 활용법을 조금 더 이해하지 않을까 기대를 한다.</p>\n<p>바로 레츠고오.</p>\n<p> </p>\n<h2 id=\"abstract\" style=\"position:relative;\"><a href=\"#abstract\" aria-label=\"abstract permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Abstract</h2>\n<hr>\n<p>이 논문은 키워드를 ’<strong>서포트 벡터 머신</strong>’, ’<strong>통계적 학습 이론</strong>’, ’<strong>VC 차원</strong>’, ’<strong>패턴 인식</strong>‘로 선택했다. 이 중에 VC 차원에 대해 먼저 알고 가는 것이 좋을 것 같다.</p>\n<p> </p>\n<p><strong>VC 차원</strong>(Vapnik-Chervonenkis dimension)은 모델의 복잡도와 학습 능력을 측정하는 지표인데, <strong>주어진 모델이 얼마나 다양한 데이터를 정확히 구분할 수 있는지</strong>를 나타낸다. 어떤 모델(분류기)로 데이터셋을 분류한다고 하자. 분류기는 선형(직선), 원 등의 모델을 가질 수 있다. 즉, 직선으로 클래스를 나눌 수 있고, 원으로 원의 안쪽과 바깥쪽의 클래스를 나눌 수 있다.</p>\n<p>각 데이터 포인트는 자신의 실제 클래스(레이블)가 있을 것이다.\n<strong>얼마나 많은 데이터 포인트(점)까지 각 분류기로 자신의 클래스에 맞게 분류될 수 있는지</strong>에 관한 것이 <strong>VC 차원</strong>이라는 개념이다.</p>\n<p> </p>\n<p>그러면, ”<strong>직선 분류기(선형 모델)</strong>“를 먼저 생각해보자.\n(각 데이터셋은 2차원, 3차원, 그보다 높은 차원에 나타낼 수 있지만 2차원으로 나타낸다고 하자.)</p>\n<ul>\n<li>\n<p><strong>직선 하나로 서로 다른 점 2개를 두 그룹으로 분리할 수 있는가?</strong> <strong>=></strong> <strong>그렇다.</strong></p>\n<p>조금 더 자세히 설명해보면,</p>\n<p>이진 분류에서 두 점이 같은 클래스를 갖는다(+, +).</p>\n<p>그러면 직선 |에 대해 ”<strong>+ + |</strong>“와 같이 클래스를 나눌 수 있다.</p>\n<p>이진 분류에서 두 점이 다른 클래스를 갖는다(+, -).</p>\n<p>그러면 직선 |에 대해 ” <strong>+ | -</strong>“와 같이 클래스를 나눌 수 있다.</p>\n</li>\n<li>\n<p><strong>직선 하나로 서로 다른 점 3개를 두 그룹으로 분리할 수 있는가?</strong> <strong>=></strong> <strong>그렇다.</strong></p>\n<p>그림으로 좀 더 자세히 보자.</p>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 720px; \"\n    >\n      <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 50%; position: relative; bottom: 0; left: 0; background-image: url('data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAAKABQDASIAAhEBAxEB/8QAFgABAQEAAAAAAAAAAAAAAAAAAAEF/8QAFAEBAAAAAAAAAAAAAAAAAAAAAP/aAAwDAQACEAMQAAAB3qgB/8QAFBABAAAAAAAAAAAAAAAAAAAAIP/aAAgBAQABBQJf/8QAFBEBAAAAAAAAAAAAAAAAAAAAEP/aAAgBAwEBPwE//8QAFBEBAAAAAAAAAAAAAAAAAAAAEP/aAAgBAgEBPwE//8QAFBABAAAAAAAAAAAAAAAAAAAAIP/aAAgBAQAGPwJf/8QAGBABAAMBAAAAAAAAAAAAAAAAEBFRYYH/2gAIAQEAAT8h6RpR/9oADAMBAAIAAwAAABCwD//EABQRAQAAAAAAAAAAAAAAAAAAABD/2gAIAQMBAT8QP//EABQRAQAAAAAAAAAAAAAAAAAAABD/2gAIAQIBAT8QP//EABoQAQADAAMAAAAAAAAAAAAAAAEAESExQYH/2gAIAQEAAT8QoRNe8RqzY2cUo3IB0hl1P//Z'); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"img-0\"\n        title=\"img-0\"\n        src=\"/static/e00d42057aa46b7baf3b85d45373c0b7/80e3c/img-0.jpg\"\n        srcset=\"/static/e00d42057aa46b7baf3b85d45373c0b7/4ec73/img-0.jpg 180w,\n/static/e00d42057aa46b7baf3b85d45373c0b7/158ba/img-0.jpg 360w,\n/static/e00d42057aa46b7baf3b85d45373c0b7/80e3c/img-0.jpg 720w,\n/static/e00d42057aa46b7baf3b85d45373c0b7/34e35/img-0.jpg 777w\"\n        sizes=\"(max-width: 720px) 100vw, 720px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n        decoding=\"async\"\n      />\n    </span></p>\n<ul>\n<li>\n<p>위와 같이 3개의 데이터 포인트는 직선 하나로 두 그룹으로 분리 가능하다.</p>\n</li>\n<li>\n<p>그런데 의문이 하나 있긴 하다..</p>\n<blockquote>\n<p><strong>3개의 데이터 포인트가 일자(-) 형태로 존재할 경우,</strong>\n<strong>양 끝의 데이터들이 같은 클래스이면 (+ - +) 이 데이터셋은 직선 하나로 분리할 수 없지 않는가…?</strong></p>\n<ul>\n<li><del>일반적으로 데이터들은 일직선 상에 존재하지 않기 때문에 그런 것인가..</del></li>\n<li>2.1 VC 차원에서 설명하듯, <strong>어떤 한 점을 기준으로 할 때 나머지 점들의 위치 벡터가 선형 독립임을 가정하고 있다</strong>!! (수학적으로 점들이 일직선 상에 없다는 것을 가정한다는 것이다.)</li>\n</ul>\n</blockquote>\n</li>\n</ul>\n</li>\n</ul>\n<p> </p>\n<ul>\n<li>\n<p><strong>직선 하나로 서로 다른 점 4개를 두 그룹으로 분리할 수 있는가?</strong> => <strong>그렇지 않다!!</strong></p>\n<p><strong>XOR 문제</strong>를 알아보자.</p>\n<ul>\n<li>\n<p>논리 연산에서 배타적 논리합(Exclusive OR)은 <strong>두 값이 다를 때 참 (True)이고</strong>, <strong>같을 때 거짓</strong> **(False)**로 클래스를 나눈다.</p>\n</li>\n<li>\n<p>한 데이터의 특성 <span class=\"math math-inline\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>x</mi><mn>1</mn></msub></mrow><annotation encoding=\"application/x-tex\">x_1</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.5806em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">x</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.3011em;\"><span style=\"top:-2.55em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">1</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span></span>, <span class=\"math math-inline\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>x</mi><mn>2</mn></msub></mrow><annotation encoding=\"application/x-tex\">x_2</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.5806em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">x</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.3011em;\"><span style=\"top:-2.55em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">2</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span></span>에 대해 데이터 포인트 <span class=\"math math-inline\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mo stretchy=\"false\">(</mo><msub><mi>x</mi><mn>1</mn></msub><mo separator=\"true\">,</mo><msub><mi>x</mi><mn>2</mn></msub><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">(x_1, x_2)</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mopen\">(</span><span class=\"mord\"><span class=\"mord mathnormal\">x</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.3011em;\"><span style=\"top:-2.55em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">1</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.1667em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">x</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.3011em;\"><span style=\"top:-2.55em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">2</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mclose\">)</span></span></span></span></span>를 나타낼 수 있는데, 배타적 논리합에 의해 <strong>점 (0, 1) , (1, 0)은 참(True, +)인 클래스</strong>, <strong>(0, 0), (1, 1)은 거짓(False, -) 클래스</strong>이다.</p>\n</li>\n<li>\n<p><strong>(0,1) +</strong>    <strong>(1,1) -</strong></p>\n<p><strong>(0,0) -</strong>    <strong>(1,0) +</strong></p>\n<p>=> 위와 같이 나타낼 수 있는데, <strong>직선 하나로 분류가 불가능</strong>하다.</p>\n</li>\n</ul>\n</li>\n</ul>\n<p>결국, <strong>직선 분류기</strong>는 <strong>최대 3개의 점까지 정확히 분류가 가능</strong>하므로 <strong>직선 분류기의 VC 차원은 3</strong>이라고 할 수 있다.\n(원 분류기(타원 아님)도 비슷한 방법으로 생각해보면, 원 분류기의 VC 차원은 3이다.)</p>\n<p> </p>\n<p>VC 차원에 대한 더 자세한 설명은 나중에 하자.\n(그리고 Abstract에 따르면 VC 차원과 구조적 위험 최소화 개념에 대한 개요로 시작해서 분리 가능하고 분리 불가능한 데이터셋에 대한 선형 서포트 벡터 머신을 설명할 것이고, 목적 함수의 최솟값(지역, 전역 최솟값)이 있을 때 최적의 해에 대해 논의할 것이라 한다. 또한, 비선형인 해를 구하기 위해 서포트 벡터 머신에서 중요한 커널 매핑 기법에 대해 설명할 것이고, VC 차원과 일반화 성능 관련성에 대해 설명한다고 한다.)</p>\n<p>이제 하나씩 자세히 뜯어보자.</p>\n<p> </p>\n<h2 id=\"1-intoduction\" style=\"position:relative;\"><a href=\"#1-intoduction\" aria-label=\"1 intoduction permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>1. Intoduction</h2>\n<hr>\n<p>이 튜토리얼에서는 <strong>패턴 인식 문제</strong>에만 초점을 맞추고, 회귀 추정과 선형 연산자 역변환 등의 주제에 대한 탐구는 제외했다고 한다.</p>\n<p>SVM의 초기 연구자들은 <strong>편향-분산 트레이드오프</strong>(Bias Variance Tradeoff)과 <strong>용량 제어</strong>(Capacity Control), <strong>과적합</strong>(Overfitting)에 대해 초점을 맞췄다고 한다.</p>\n<p>유한한 양의 훈련 데이터로 최상의 일반화 성능을 달성해야 하는데, <strong>학습 데이터에서의 정확도(훈련 데이터에 얼마나 적합한지)와 기계의 용량(모델이 얼마나 복잡한 패턴을 학습할 수 있는지) 간의 균형이 필요</strong>하다고 한다. Capacity가 너무 크면 모델이 훈련 데이터에 과적합되어 새로운 데이터에 대한 일반화 성능이 좋지 않고, 반대로 Capacity가 너무 작으면 모델이 훈련 데이터에 과소적합되어 새로운 데이터에 대해 엉뚱한 결론을 내어 일반화 성능이 좋지 않다고 한다.</p>\n<p>앞으로 보게 될테지만 <strong>학습 데이터에서의 정확도</strong>는 <strong>경험적 위험(훈련 오차)</strong> <span class=\"math math-inline\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>R</mi><mtext>emp</mtext></msub></mrow><annotation encoding=\"application/x-tex\">R_{\\text{emp}}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.9694em;vertical-align:-0.2861em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.00773em;\">R</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.1514em;\"><span style=\"top:-2.55em;margin-left:-0.0077em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord text mtight\"><span class=\"mord mtight\">emp</span></span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2861em;\"><span></span></span></span></span></span></span></span></span></span></span>와 관련 있으며, 기계의 용량은 <strong>VC 차원</strong> <span class=\"math math-inline\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>h</mi></mrow><annotation encoding=\"application/x-tex\">h</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.6944em;\"></span><span class=\"mord mathnormal\">h</span></span></span></span></span>과 관련 있다!!</p>\n<p> </p>\n<h2 id=\"2-a-bound-on-the-generalization-performance-of-a-pattern-recognition-learning-machine\" style=\"position:relative;\"><a href=\"#2-a-bound-on-the-generalization-performance-of-a-pattern-recognition-learning-machine\" aria-label=\"2 a bound on the generalization performance of a pattern recognition learning machine permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>2. A Bound on the Generalization Performance of a Pattern Recognition Learning Machine</h2>\n<hr>\n<ol>\n<li>\n<p><strong>일반화 오차 <span class=\"math math-inline\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>R</mi><mo stretchy=\"false\">(</mo><mi>α</mi><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">R(\\alpha)</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.00773em;\">R</span><span class=\"mopen\">(</span><span class=\"mord mathnormal\" style=\"margin-right:0.0037em;\">α</span><span class=\"mclose\">)</span></span></span></span></span>는 경험적 위험(훈련 오차) <span class=\"math math-inline\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>R</mi><mtext>emp</mtext></msub></mrow><annotation encoding=\"application/x-tex\">R_{\\text{emp}}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.9694em;vertical-align:-0.2861em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.00773em;\">R</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.1514em;\"><span style=\"top:-2.55em;margin-left:-0.0077em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord text mtight\"><span class=\"mord mtight\">emp</span></span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2861em;\"><span></span></span></span></span></span></span></span></span></span></span>보다 커질 수 없다.</strong></p>\n<p><span class=\"math math-inline\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>R</mi><mo stretchy=\"false\">(</mo><mi>α</mi><mo stretchy=\"false\">)</mo><mo>≤</mo><msub><mi>R</mi><mtext>emp</mtext></msub><mo stretchy=\"false\">(</mo><mi>α</mi><mo stretchy=\"false\">)</mo><mo>+</mo><msqrt><mrow><mo fence=\"true\">(</mo><mfrac><mrow><mi>h</mi><mo stretchy=\"false\">(</mo><mi>log</mi><mo>⁡</mo><mo stretchy=\"false\">(</mo><mn>2</mn><mi>l</mi><mi mathvariant=\"normal\">/</mi><mi>h</mi><mo stretchy=\"false\">)</mo><mo>+</mo><mn>1</mn><mo stretchy=\"false\">)</mo><mo>−</mo><mi>log</mi><mo>⁡</mo><mo stretchy=\"false\">(</mo><mi>η</mi><mi mathvariant=\"normal\">/</mi><mn>4</mn><mo stretchy=\"false\">)</mo></mrow><mi>l</mi></mfrac><mo fence=\"true\">)</mo></mrow></msqrt></mrow><annotation encoding=\"application/x-tex\">R(\\alpha) \\leq R_{\\text{emp}}(\\alpha)+\\sqrt{\\left(\\frac{h(\\log (2 l / h)+1)-\\log (\\eta / 4)}{l}\\right)}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.00773em;\">R</span><span class=\"mopen\">(</span><span class=\"mord mathnormal\" style=\"margin-right:0.0037em;\">α</span><span class=\"mclose\">)</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span><span class=\"mrel\">≤</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1.0361em;vertical-align:-0.2861em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.00773em;\">R</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.1514em;\"><span style=\"top:-2.55em;margin-left:-0.0077em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord text mtight\"><span class=\"mord mtight\">emp</span></span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2861em;\"><span></span></span></span></span></span></span><span class=\"mopen\">(</span><span class=\"mord mathnormal\" style=\"margin-right:0.0037em;\">α</span><span class=\"mclose\">)</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span><span class=\"mbin\">+</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:2.44em;vertical-align:-0.905em;\"></span><span class=\"mord sqrt\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.535em;\"><span class=\"svg-align\" style=\"top:-4.4em;\"><span class=\"pstrut\" style=\"height:4.4em;\"></span><span class=\"mord\" style=\"padding-left:1em;\"><span class=\"minner\"><span class=\"mopen delimcenter\" style=\"top:0em;\"><span class=\"delimsizing size2\">(</span></span><span class=\"mord\"><span class=\"mopen nulldelimiter\"></span><span class=\"mfrac\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.01em;\"><span style=\"top:-2.655em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.01968em;\">l</span></span></span></span><span style=\"top:-3.23em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"frac-line\" style=\"border-bottom-width:0.04em;\"></span></span><span style=\"top:-3.485em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">h</span><span class=\"mopen mtight\">(</span><span class=\"mop mtight\"><span class=\"mtight\">l</span><span class=\"mtight\">o</span><span class=\"mtight\" style=\"margin-right:0.01389em;\">g</span></span><span class=\"mopen mtight\">(</span><span class=\"mord mtight\">2</span><span class=\"mord mathnormal mtight\" style=\"margin-right:0.01968em;\">l</span><span class=\"mord mtight\">/</span><span class=\"mord mathnormal mtight\">h</span><span class=\"mclose mtight\">)</span><span class=\"mbin mtight\">+</span><span class=\"mord mtight\">1</span><span class=\"mclose mtight\">)</span><span class=\"mbin mtight\">−</span><span class=\"mop mtight\"><span class=\"mtight\">l</span><span class=\"mtight\">o</span><span class=\"mtight\" style=\"margin-right:0.01389em;\">g</span></span><span class=\"mopen mtight\">(</span><span class=\"mord mathnormal mtight\" style=\"margin-right:0.03588em;\">η</span><span class=\"mord mtight\">/4</span><span class=\"mclose mtight\">)</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.345em;\"><span></span></span></span></span></span><span class=\"mclose nulldelimiter\"></span></span><span class=\"mclose delimcenter\" style=\"top:0em;\"><span class=\"delimsizing size2\">)</span></span></span></span></span><span style=\"top:-3.495em;\"><span class=\"pstrut\" style=\"height:4.4em;\"></span><span class=\"hide-tail\" style=\"min-width:1.02em;height:2.48em;\"><svg xmlns=\"http://www.w3.org/2000/svg\" width=\"400em\" height=\"2.48em\" viewBox=\"0 0 400000 2592\" preserveAspectRatio=\"xMinYMin slice\"><path d=\"M424,2478\nc-1.3,-0.7,-38.5,-172,-111.5,-514c-73,-342,-109.8,-513.3,-110.5,-514\nc0,-2,-10.7,14.3,-32,49c-4.7,7.3,-9.8,15.7,-15.5,25c-5.7,9.3,-9.8,16,-12.5,20\ns-5,7,-5,7c-4,-3.3,-8.3,-7.7,-13,-13s-13,-13,-13,-13s76,-122,76,-122s77,-121,77,-121\ns209,968,209,968c0,-2,84.7,-361.7,254,-1079c169.3,-717.3,254.7,-1077.7,256,-1081\nl0 -0c4,-6.7,10,-10,18,-10 H400000\nv40H1014.6\ns-87.3,378.7,-272.6,1166c-185.3,787.3,-279.3,1182.3,-282,1185\nc-2,6,-10,9,-24,9\nc-8,0,-12,-0.7,-12,-2z M1001 80\nh400000v40h-400000z\"></path></svg></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.905em;\"><span></span></span></span></span></span></span></span></span></span></p>\n<ul>\n<li>\n<p><span class=\"math math-inline\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>R</mi><mtext>emp</mtext></msub><mo stretchy=\"false\">(</mo><mi>α</mi><mo stretchy=\"false\">)</mo><mo>+</mo><msqrt><mrow><mo fence=\"true\">(</mo><mfrac><mrow><mi>h</mi><mo stretchy=\"false\">(</mo><mi>log</mi><mo>⁡</mo><mo stretchy=\"false\">(</mo><mn>2</mn><mi>l</mi><mi mathvariant=\"normal\">/</mi><mi>h</mi><mo stretchy=\"false\">)</mo><mo>+</mo><mn>1</mn><mo stretchy=\"false\">)</mo><mo>−</mo><mi>log</mi><mo>⁡</mo><mo stretchy=\"false\">(</mo><mi>η</mi><mi mathvariant=\"normal\">/</mi><mn>4</mn><mo stretchy=\"false\">)</mo></mrow><mi>l</mi></mfrac><mo fence=\"true\">)</mo></mrow></msqrt></mrow><annotation encoding=\"application/x-tex\">R_{\\text{emp}}(\\alpha)+\\sqrt{\\left(\\frac{h(\\log (2 l / h)+1)-\\log (\\eta / 4)}{l}\\right)}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1.0361em;vertical-align:-0.2861em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.00773em;\">R</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.1514em;\"><span style=\"top:-2.55em;margin-left:-0.0077em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord text mtight\"><span class=\"mord mtight\">emp</span></span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2861em;\"><span></span></span></span></span></span></span><span class=\"mopen\">(</span><span class=\"mord mathnormal\" style=\"margin-right:0.0037em;\">α</span><span class=\"mclose\">)</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span><span class=\"mbin\">+</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:2.44em;vertical-align:-0.905em;\"></span><span class=\"mord sqrt\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.535em;\"><span class=\"svg-align\" style=\"top:-4.4em;\"><span class=\"pstrut\" style=\"height:4.4em;\"></span><span class=\"mord\" style=\"padding-left:1em;\"><span class=\"minner\"><span class=\"mopen delimcenter\" style=\"top:0em;\"><span class=\"delimsizing size2\">(</span></span><span class=\"mord\"><span class=\"mopen nulldelimiter\"></span><span class=\"mfrac\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.01em;\"><span style=\"top:-2.655em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.01968em;\">l</span></span></span></span><span style=\"top:-3.23em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"frac-line\" style=\"border-bottom-width:0.04em;\"></span></span><span style=\"top:-3.485em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">h</span><span class=\"mopen mtight\">(</span><span class=\"mop mtight\"><span class=\"mtight\">l</span><span class=\"mtight\">o</span><span class=\"mtight\" style=\"margin-right:0.01389em;\">g</span></span><span class=\"mopen mtight\">(</span><span class=\"mord mtight\">2</span><span class=\"mord mathnormal mtight\" style=\"margin-right:0.01968em;\">l</span><span class=\"mord mtight\">/</span><span class=\"mord mathnormal mtight\">h</span><span class=\"mclose mtight\">)</span><span class=\"mbin mtight\">+</span><span class=\"mord mtight\">1</span><span class=\"mclose mtight\">)</span><span class=\"mbin mtight\">−</span><span class=\"mop mtight\"><span class=\"mtight\">l</span><span class=\"mtight\">o</span><span class=\"mtight\" style=\"margin-right:0.01389em;\">g</span></span><span class=\"mopen mtight\">(</span><span class=\"mord mathnormal mtight\" style=\"margin-right:0.03588em;\">η</span><span class=\"mord mtight\">/4</span><span class=\"mclose mtight\">)</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.345em;\"><span></span></span></span></span></span><span class=\"mclose nulldelimiter\"></span></span><span class=\"mclose delimcenter\" style=\"top:0em;\"><span class=\"delimsizing size2\">)</span></span></span></span></span><span style=\"top:-3.495em;\"><span class=\"pstrut\" style=\"height:4.4em;\"></span><span class=\"hide-tail\" style=\"min-width:1.02em;height:2.48em;\"><svg xmlns=\"http://www.w3.org/2000/svg\" width=\"400em\" height=\"2.48em\" viewBox=\"0 0 400000 2592\" preserveAspectRatio=\"xMinYMin slice\"><path d=\"M424,2478\nc-1.3,-0.7,-38.5,-172,-111.5,-514c-73,-342,-109.8,-513.3,-110.5,-514\nc0,-2,-10.7,14.3,-32,49c-4.7,7.3,-9.8,15.7,-15.5,25c-5.7,9.3,-9.8,16,-12.5,20\ns-5,7,-5,7c-4,-3.3,-8.3,-7.7,-13,-13s-13,-13,-13,-13s76,-122,76,-122s77,-121,77,-121\ns209,968,209,968c0,-2,84.7,-361.7,254,-1079c169.3,-717.3,254.7,-1077.7,256,-1081\nl0 -0c4,-6.7,10,-10,18,-10 H400000\nv40H1014.6\ns-87.3,378.7,-272.6,1166c-185.3,787.3,-279.3,1182.3,-282,1185\nc-2,6,-10,9,-24,9\nc-8,0,-12,-0.7,-12,-2z M1001 80\nh400000v40h-400000z\"></path></svg></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.905em;\"><span></span></span></span></span></span></span></span></span></span> : <strong>위험 경계</strong> (risk bound, 상한)</p>\n</li>\n<li>\n<p><span class=\"math math-inline\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msqrt><mrow><mo fence=\"true\">(</mo><mfrac><mrow><mi>h</mi><mo stretchy=\"false\">(</mo><mi>log</mi><mo>⁡</mo><mo stretchy=\"false\">(</mo><mn>2</mn><mi>l</mi><mi mathvariant=\"normal\">/</mi><mi>h</mi><mo stretchy=\"false\">)</mo><mo>+</mo><mn>1</mn><mo stretchy=\"false\">)</mo><mo>−</mo><mi>log</mi><mo>⁡</mo><mo stretchy=\"false\">(</mo><mi>η</mi><mi mathvariant=\"normal\">/</mi><mn>4</mn><mo stretchy=\"false\">)</mo></mrow><mi>l</mi></mfrac><mo fence=\"true\">)</mo></mrow></msqrt></mrow><annotation encoding=\"application/x-tex\">\\sqrt{\\left(\\frac{h(\\log (2 l / h)+1)-\\log (\\eta / 4)}{l}\\right)}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:2.44em;vertical-align:-0.905em;\"></span><span class=\"mord sqrt\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.535em;\"><span class=\"svg-align\" style=\"top:-4.4em;\"><span class=\"pstrut\" style=\"height:4.4em;\"></span><span class=\"mord\" style=\"padding-left:1em;\"><span class=\"minner\"><span class=\"mopen delimcenter\" style=\"top:0em;\"><span class=\"delimsizing size2\">(</span></span><span class=\"mord\"><span class=\"mopen nulldelimiter\"></span><span class=\"mfrac\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.01em;\"><span style=\"top:-2.655em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.01968em;\">l</span></span></span></span><span style=\"top:-3.23em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"frac-line\" style=\"border-bottom-width:0.04em;\"></span></span><span style=\"top:-3.485em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">h</span><span class=\"mopen mtight\">(</span><span class=\"mop mtight\"><span class=\"mtight\">l</span><span class=\"mtight\">o</span><span class=\"mtight\" style=\"margin-right:0.01389em;\">g</span></span><span class=\"mopen mtight\">(</span><span class=\"mord mtight\">2</span><span class=\"mord mathnormal mtight\" style=\"margin-right:0.01968em;\">l</span><span class=\"mord mtight\">/</span><span class=\"mord mathnormal mtight\">h</span><span class=\"mclose mtight\">)</span><span class=\"mbin mtight\">+</span><span class=\"mord mtight\">1</span><span class=\"mclose mtight\">)</span><span class=\"mbin mtight\">−</span><span class=\"mop mtight\"><span class=\"mtight\">l</span><span class=\"mtight\">o</span><span class=\"mtight\" style=\"margin-right:0.01389em;\">g</span></span><span class=\"mopen mtight\">(</span><span class=\"mord mathnormal mtight\" style=\"margin-right:0.03588em;\">η</span><span class=\"mord mtight\">/4</span><span class=\"mclose mtight\">)</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.345em;\"><span></span></span></span></span></span><span class=\"mclose nulldelimiter\"></span></span><span class=\"mclose delimcenter\" style=\"top:0em;\"><span class=\"delimsizing size2\">)</span></span></span></span></span><span style=\"top:-3.495em;\"><span class=\"pstrut\" style=\"height:4.4em;\"></span><span class=\"hide-tail\" style=\"min-width:1.02em;height:2.48em;\"><svg xmlns=\"http://www.w3.org/2000/svg\" width=\"400em\" height=\"2.48em\" viewBox=\"0 0 400000 2592\" preserveAspectRatio=\"xMinYMin slice\"><path d=\"M424,2478\nc-1.3,-0.7,-38.5,-172,-111.5,-514c-73,-342,-109.8,-513.3,-110.5,-514\nc0,-2,-10.7,14.3,-32,49c-4.7,7.3,-9.8,15.7,-15.5,25c-5.7,9.3,-9.8,16,-12.5,20\ns-5,7,-5,7c-4,-3.3,-8.3,-7.7,-13,-13s-13,-13,-13,-13s76,-122,76,-122s77,-121,77,-121\ns209,968,209,968c0,-2,84.7,-361.7,254,-1079c169.3,-717.3,254.7,-1077.7,256,-1081\nl0 -0c4,-6.7,10,-10,18,-10 H400000\nv40H1014.6\ns-87.3,378.7,-272.6,1166c-185.3,787.3,-279.3,1182.3,-282,1185\nc-2,6,-10,9,-24,9\nc-8,0,-12,-0.7,-12,-2z M1001 80\nh400000v40h-400000z\"></path></svg></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.905em;\"><span></span></span></span></span></span></span></span></span></span>: <strong>VC 신뢰도</strong></p>\n<ul>\n<li><strong>일반화 오차와 경험적 위험 사이의 오차 상한</strong> **(일반화 오차의 상한)**이라고 생각하면 된다.\n즉, 모델이 학습 데이터뿐만 아니라 새로운 데이터에 대해 일반화할 때 추가로 발생할 수 있는 오차의 상한이다.</li>\n<li>모델의 복잡도(VC 차원 <span class=\"math math-inline\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>h</mi></mrow><annotation encoding=\"application/x-tex\">h</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.6944em;\"></span><span class=\"mord mathnormal\">h</span></span></span></span></span>), 훈련 데이터의 수(<span class=\"math math-inline\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>l</mi></mrow><annotation encoding=\"application/x-tex\">l</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.6944em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.01968em;\">l</span></span></span></span></span>), 신뢰 수준(<span class=\"math math-inline\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>η</mi></mrow><annotation encoding=\"application/x-tex\">\\eta</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.625em;vertical-align:-0.1944em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">η</span></span></span></span></span>)에 따라 결정된다.</li>\n<li>모델의 복잡도(<span class=\"math math-inline\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>h</mi></mrow><annotation encoding=\"application/x-tex\">h</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.6944em;\"></span><span class=\"mord mathnormal\">h</span></span></span></span></span>)가 커지면 일반화 오차의 상한이 커진다.</li>\n<li>훈련 데이터(<span class=\"math math-inline\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>l</mi></mrow><annotation encoding=\"application/x-tex\">l</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.6944em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.01968em;\">l</span></span></span></span></span>)가 많아질수록 일반화 오차의 상한이 작아진다.</li>\n<li>신뢰구간에 대한 확률 <span class=\"math math-inline\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>η</mi></mrow><annotation encoding=\"application/x-tex\">\\eta</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.625em;vertical-align:-0.1944em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">η</span></span></span></span></span>이 작을수록 일반화 오차의 상한이 커진다.\n=> 신뢰도 <span class=\"math math-inline\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mn>1</mn><mo>−</mo><mi>η</mi></mrow><annotation encoding=\"application/x-tex\">1-\\eta</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.7278em;vertical-align:-0.0833em;\"></span><span class=\"mord\">1</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span><span class=\"mbin\">−</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.625em;vertical-align:-0.1944em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">η</span></span></span></span></span> 를 크게 해 일반화 오차가 상한 안에 있을 가능성을 높이므로(상한을 더 커지게 해서 상한 이하의 범위을 넢힘), 그만큼 일반화 오차의 상한을 크게 만든다.</li>\n</ul>\n</li>\n</ul>\n</li>\n</ol>\n<p> </p>\n<ol start=\"2\">\n<li><strong>구조적 위험을 최소화(SRM)하기 위해 경험적 위험 <span class=\"math math-inline\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>R</mi><mtext>emp</mtext></msub></mrow><annotation encoding=\"application/x-tex\">R_{\\text{emp}}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.9694em;vertical-align:-0.2861em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.00773em;\">R</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.1514em;\"><span style=\"top:-2.55em;margin-left:-0.0077em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord text mtight\"><span class=\"mord mtight\">emp</span></span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2861em;\"><span></span></span></span></span></span></span></span></span></span></span>과 모델 복잡도(VC 차원) <span class=\"math math-inline\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>h</mi></mrow><annotation encoding=\"application/x-tex\">h</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.6944em;\"></span><span class=\"mord mathnormal\">h</span></span></span></span></span> 간의 균형을 맞추는 것이 중요하다.</strong>\n<ul>\n<li><span class=\"math math-inline\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>R</mi><mo stretchy=\"false\">(</mo><mi>α</mi><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">R(\\alpha)</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.00773em;\">R</span><span class=\"mopen\">(</span><span class=\"mord mathnormal\" style=\"margin-right:0.0037em;\">α</span><span class=\"mclose\">)</span></span></span></span></span>을 계산하는 것은 일반적으로 불가능한데, 모델의 복잡도(VC 차원 <span class=\"math math-inline\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>h</mi></mrow><annotation encoding=\"application/x-tex\">h</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.6944em;\"></span><span class=\"mord mathnormal\">h</span></span></span></span></span>)를 알면 위험 경계를 쉽게 계산할 수 있다.\n즉, <strong>우선 <span class=\"math math-inline\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>η</mi></mrow><annotation encoding=\"application/x-tex\">\\eta</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.625em;vertical-align:-0.1944em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">η</span></span></span></span></span>를 충분히 작게 한 후(일반화 오차가 상한 안에 있을 가능성(신뢰성)은 높여 놓고), 모델의 복잡도(VC 차원 <span class=\"math math-inline\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>h</mi></mrow><annotation encoding=\"application/x-tex\">h</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.6944em;\"></span><span class=\"mord mathnormal\">h</span></span></span></span></span>)와 경험적 위험 <span class=\"math math-inline\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>R</mi><mtext>emp</mtext></msub></mrow><annotation encoding=\"application/x-tex\">R_{\\text{emp}}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.9694em;vertical-align:-0.2861em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.00773em;\">R</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.1514em;\"><span style=\"top:-2.55em;margin-left:-0.0077em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord text mtight\"><span class=\"mord mtight\">emp</span></span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2861em;\"><span></span></span></span></span></span></span></span></span></span></span> 사이의 최적점을 찾아서 위험 경계를 최소화하는 것</strong>이 쟁점이다.\n=> <strong>서로 다른 VC 차원을 갖는 여러 모델 중에서 위험 경계가 가장 작은 모델을 선택하면 된다</strong>!!</li>\n<li>참고로 모델의 복잡도(<span class=\"math math-inline\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>h</mi></mrow><annotation encoding=\"application/x-tex\">h</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.6944em;\"></span><span class=\"mord mathnormal\">h</span></span></span></span></span>)가 커지면 과대적합 가능성이 높아지고, 훈련 데이터(<span class=\"math math-inline\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>l</mi></mrow><annotation encoding=\"application/x-tex\">l</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.6944em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.01968em;\">l</span></span></span></span></span>)가 많아질수록 과소적합 가능성이 높아진다.</li>\n</ul>\n</li>\n</ol>\n<p> </p>\n<h3 id=\"21-vc-dimension\" style=\"position:relative;\"><a href=\"#21-vc-dimension\" aria-label=\"21 vc dimension permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>2.1 VC Dimension</h3>\n<p>VC 차원이 무엇인지는 Abstract에서 설명했다. 하지만 VC 차원에 대한 정의를 좀 더 명확히 할 필요가 있다.</p>\n<p>VC 차원을 좀 더 엄밀히 정의하기 위해 단계적으로 서술해보자. (참고로 직선 분류기를 이용)</p>\n<ol>\n<li><strong><span class=\"math math-inline\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>l</mi></mrow><annotation encoding=\"application/x-tex\">l</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.6944em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.01968em;\">l</span></span></span></span></span>개의 점의 위치(배치)를 먼저 정해준다.</strong></li>\n<li><strong>해당 배치에서 각 점마다 1과 -1 레이블을 정해주는 모든 경우(<span class=\"math math-inline\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msup><mn>2</mn><mi>l</mi></msup></mrow><annotation encoding=\"application/x-tex\">2^{l}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8491em;\"></span><span class=\"mord\"><span class=\"mord\">2</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8491em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.01968em;\">l</span></span></span></span></span></span></span></span></span></span></span></span></span>가지)에서 각각 분할할 수 있는 직선이 존재할 때,</strong>\n<strong>해당 점의 배치에서 <span class=\"math math-inline\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msup><mn>2</mn><mi>l</mi></msup></mrow><annotation encoding=\"application/x-tex\">2^{l}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8491em;\"></span><span class=\"mord\"><span class=\"mord\">2</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8491em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.01968em;\">l</span></span></span></span></span></span></span></span></span></span></span></span></span>가지 레이블 조합을 함수 집합 내의 어떤 함수로든 정확히 분할 가능하다고 한다.</strong></li>\n<li><strong>결국, <span class=\"math math-inline\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>l</mi></mrow><annotation encoding=\"application/x-tex\">l</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.6944em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.01968em;\">l</span></span></span></span></span>개의 점의 배치마다 레이블을 정해주는 경우들이 있는데, 적어도 하나 <span class=\"math math-inline\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>l</mi></mrow><annotation encoding=\"application/x-tex\">l</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.6944em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.01968em;\">l</span></span></span></span></span>개의 점의 배치라도 모든 레이블 조합에서 분할 가능한 직선이 있으면 된다.</strong></li>\n<li><strong>점의 수 <span class=\"math math-inline\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>l</mi></mrow><annotation encoding=\"application/x-tex\">l</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.6944em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.01968em;\">l</span></span></span></span></span>을 늘려 그 최댓값 <span class=\"math math-inline\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>h</mi></mrow><annotation encoding=\"application/x-tex\">h</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.6944em;\"></span><span class=\"mord mathnormal\">h</span></span></span></span></span>을 찾으면 <span class=\"math math-inline\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>h</mi></mrow><annotation encoding=\"application/x-tex\">h</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.6944em;\"></span><span class=\"mord mathnormal\">h</span></span></span></span></span>가 VC 차원이다.</strong>\n<strong>(모든 레이블 조합에서 분류가 가능한 점의 배치가 존재하는데, 그 최대 점의 개수를 VC 차원)</strong></li>\n</ol>\n<p>결국 <strong><span class=\"math math-inline\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>h</mi></mrow><annotation encoding=\"application/x-tex\">h</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.6944em;\"></span><span class=\"mord mathnormal\">h</span></span></span></span></span>개의 점 집합(배치) 중 적어도 하나가 분할 가능해야 하며, 모든 <span class=\"math math-inline\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>h</mi></mrow><annotation encoding=\"application/x-tex\">h</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.6944em;\"></span><span class=\"mord mathnormal\">h</span></span></span></span></span>개의 점 집합(배치)가 반드시 분할 가능한 것은 아니며, <span class=\"math math-inline\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>h</mi><mo>+</mo><mn>1</mn></mrow><annotation encoding=\"application/x-tex\">h+1</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.7778em;vertical-align:-0.0833em;\"></span><span class=\"mord mathnormal\">h</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span><span class=\"mbin\">+</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.6444em;\"></span><span class=\"mord\">1</span></span></span></span></span>점은 어떠한 배치에서도 모든 레이블 조합을 분할하는 경우는 없다</strong>.</p>\n<p>차근차근 읽어보면서 그 예시를 생각해보면 이해갈 것이다. (점 4개에서는 XOR문제 떠올리기!!)</p>\n<p>아, 함수에 대해 잠시 설명하고 넘어가자.\n<span class=\"math math-inline\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mo stretchy=\"false\">{</mo><mi>f</mi><mo stretchy=\"false\">(</mo><mi>α</mi><mo stretchy=\"false\">)</mo><mo stretchy=\"false\">}</mo></mrow><annotation encoding=\"application/x-tex\">\\{f(\\alpha)\\}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mopen\">{</span><span class=\"mord mathnormal\" style=\"margin-right:0.10764em;\">f</span><span class=\"mopen\">(</span><span class=\"mord mathnormal\" style=\"margin-right:0.0037em;\">α</span><span class=\"mclose\">)}</span></span></span></span></span>는 모델이 사용할 수 있는 함수들의 집합(학습 알고리즘이 선택할 수 있는 가능한 함수들이며 여기서는 모든 직선임)이며, <span class=\"math math-inline\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>α</mi></mrow><annotation encoding=\"application/x-tex\">\\alpha</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.4306em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.0037em;\">α</span></span></span></span></span>는 특정 함수를 선택해주는 매개변수라 생각하면 된다(직선인 경우 기울기와 절편을 포함할 것임).\n그리고, <span class=\"math math-inline\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>f</mi><mo stretchy=\"false\">(</mo><mi>x</mi><mo separator=\"true\">,</mo><mi>α</mi><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">f(x,\\alpha)</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.10764em;\">f</span><span class=\"mopen\">(</span><span class=\"mord mathnormal\">x</span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.1667em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.0037em;\">α</span><span class=\"mclose\">)</span></span></span></span></span>은 <span class=\"math math-inline\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>α</mi></mrow><annotation encoding=\"application/x-tex\">\\alpha</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.4306em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.0037em;\">α</span></span></span></span></span>로 정해지는 직선에 의한 특정 데이터 x에 대한 입력의 출력 레이블 값 1 또는 -1이다.</p>\n<p> </p>\n<h3 id=\"22-shattering-points-with-oriented-hyperplanes-in-rn\" style=\"position:relative;\"><a href=\"#22-shattering-points-with-oriented-hyperplanes-in-rn\" aria-label=\"22 shattering points with oriented hyperplanes in rn permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>2.2 Shattering Points with Oriented Hyperplanes in <span class=\"math math-inline\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msup><mi>R</mi><mi>n</mi></msup></mrow><annotation encoding=\"application/x-tex\">R^{n}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.6833em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.00773em;\">R</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.6644em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">n</span></span></span></span></span></span></span></span></span></span></span></span></span></h3>\n<p>Abstract에서 스포했듯이(?) 2차원 공간(<span class=\"math math-inline\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msup><mi>R</mi><mn>2</mn></msup></mrow><annotation encoding=\"application/x-tex\">R^{2}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8141em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.00773em;\">R</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8141em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\">2</span></span></span></span></span></span></span></span></span></span></span></span></span>)에서 3개의 점까지 직선으로 분리(분할, Shattering)할 수 있었다. 그러면 <strong>n차원 공간(<span class=\"math math-inline\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msup><mi>R</mi><mi>n</mi></msup></mrow><annotation encoding=\"application/x-tex\">R^{n}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.6833em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.00773em;\">R</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.6644em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">n</span></span></span></span></span></span></span></span></span></span></span></span></span>)으로 확장해서 보았을 때 hyperplane(초평면)은 최대로 n+1개의 점들까지 분리할 수 있지 않을까?</strong> => Yeeeeees!!!</p>\n<p>수학적으로 보았을 때, n+1개의 점 중에서 1개의 점을 기준(원점)으로 잡고, 나머지 n개의 점들의 위치벡터를 선형 독립 관계를 갖도록 선택할 수 있다. (n차원 공간까지 있으니 n개의 위치벡터를 n개의 기저 벡터로 선택할 수 있다!!)</p>\n<p>반면에 <span class=\"math math-inline\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msup><mi>R</mi><mi>n</mi></msup></mrow><annotation encoding=\"application/x-tex\">R^{n}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.6833em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.00773em;\">R</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.6644em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">n</span></span></span></span></span></span></span></span></span></span></span></span></span> 공간에서 n+2개 점은 hyperplane(초평면)으로 분리할 수 없다. 1개 점 선택하고, 나머지 n+1개의 점의 위치 벡터를 정해줘야 하는데 반드시 1개의 위치 벡터는 일차 종속이 될 수 밖에 없다. (이 부분에 대한 이해가 부족하다면 선형대수학 학습을 추천한다.)</p>\n<p>결국, <strong>n차원 공간 <span class=\"math math-inline\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msup><mi>R</mi><mi>n</mi></msup></mrow><annotation encoding=\"application/x-tex\">R^{n}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.6833em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.00773em;\">R</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.6644em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">n</span></span></span></span></span></span></span></span></span></span></span></span></span>에서 VC 차원은 n+1이다.</strong></p>\n<p>아 참고로, hyperplane은 2차원에서 직선을 확장한 것이라 생각하면 된다. 3차원에서는 초평면이 평면이라고 생각하면 된다!!</p>\n<p> </p>\n<h3 id=\"23-the-vc-dimension-and-the-number-of-parameters\" style=\"position:relative;\"><a href=\"#23-the-vc-dimension-and-the-number-of-parameters\" aria-label=\"23 the vc dimension and the number of parameters permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>2.3 The VC Dimension and the Number of Parameters</h3>\n<p>2.3절은 <strong>(1) 어떤 모델이 VC 차원이 무한하지만, (2) <span class=\"math math-inline\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>l</mi></mrow><annotation encoding=\"application/x-tex\">l</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.6944em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.01968em;\">l</span></span></span></span></span>개의 점의 어떤 특정 배치에서 레이블의 모든 조합을 분할할 수 없는 하나의 예시</strong>를 보여준다.\n(참고로, VC 차원의 정의에 따라 해당 점의 개수에서 <strong>다른 특정 하나의 배치에서만이라도</strong> 모든 레이블 조합을 분할할 수 있기만 하면 된다.)</p>\n<p> </p>\n<p>아래와 같은 선형 분류기 모델이 있다고 하자.</p>\n<p><span class=\"math math-inline\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>f</mi><mo stretchy=\"false\">(</mo><mi>x</mi><mo separator=\"true\">,</mo><mi>α</mi><mo stretchy=\"false\">)</mo><mo>≡</mo><mi>θ</mi><mo stretchy=\"false\">(</mo><mi>sin</mi><mo>⁡</mo><mo stretchy=\"false\">(</mo><mi>α</mi><mi>x</mi><mo stretchy=\"false\">)</mo><mo stretchy=\"false\">)</mo><mo separator=\"true\">,</mo><mspace width=\"1em\"></mspace><mi>x</mi><mo separator=\"true\">,</mo><mi>α</mi><mo>∈</mo><mi mathvariant=\"bold\">R</mi></mrow><annotation encoding=\"application/x-tex\">f(x, \\alpha) \\equiv \\theta(\\sin (\\alpha x)), \\quad x, \\alpha \\in \\mathbf{R}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.10764em;\">f</span><span class=\"mopen\">(</span><span class=\"mord mathnormal\">x</span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.1667em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.0037em;\">α</span><span class=\"mclose\">)</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span><span class=\"mrel\">≡</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.02778em;\">θ</span><span class=\"mopen\">(</span><span class=\"mop\">sin</span><span class=\"mopen\">(</span><span class=\"mord mathnormal\">αx</span><span class=\"mclose\">))</span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:1em;\"></span><span class=\"mspace\" style=\"margin-right:0.1667em;\"></span><span class=\"mord mathnormal\">x</span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.1667em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.0037em;\">α</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span><span class=\"mrel\">∈</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.6861em;\"></span><span class=\"mord mathbf\">R</span></span></span></span></span></p>\n<ul>\n<li><span class=\"math math-inline\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>θ</mi><mo stretchy=\"false\">(</mo><mi>x</mi><mo stretchy=\"false\">)</mo><mo separator=\"true\">,</mo><mi>x</mi><mo>∈</mo><mi mathvariant=\"bold\">R</mi><mo>:</mo><mo stretchy=\"false\">{</mo><mi>θ</mi><mo stretchy=\"false\">(</mo><mi>x</mi><mo stretchy=\"false\">)</mo><mo>=</mo><mn>1</mn><mo separator=\"true\">,</mo><mi mathvariant=\"normal\">∀</mi><mi>x</mi><mo>></mo><mn>0</mn><mo separator=\"true\">;</mo><mspace width=\"1em\"></mspace><mi>θ</mi><mo stretchy=\"false\">(</mo><mi>x</mi><mo stretchy=\"false\">)</mo><mo>=</mo><mo>−</mo><mn>1</mn><mo separator=\"true\">,</mo><mi mathvariant=\"normal\">∀</mi><mi>x</mi><mo>≤</mo><mn>0</mn><mo stretchy=\"false\">}</mo></mrow><annotation encoding=\"application/x-tex\">\\theta(x), x \\in \\mathbf{R}:\\{\\theta(x)=1, \\forall x>0 ; \\quad \\theta(x)=-1, \\forall x \\leq 0\\}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.02778em;\">θ</span><span class=\"mopen\">(</span><span class=\"mord mathnormal\">x</span><span class=\"mclose\">)</span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.1667em;\"></span><span class=\"mord mathnormal\">x</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span><span class=\"mrel\">∈</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.6861em;\"></span><span class=\"mord mathbf\">R</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span><span class=\"mrel\">:</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mopen\">{</span><span class=\"mord mathnormal\" style=\"margin-right:0.02778em;\">θ</span><span class=\"mopen\">(</span><span class=\"mord mathnormal\">x</span><span class=\"mclose\">)</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.8889em;vertical-align:-0.1944em;\"></span><span class=\"mord\">1</span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.1667em;\"></span><span class=\"mord\">∀</span><span class=\"mord mathnormal\">x</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span><span class=\"mrel\">></span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord\">0</span><span class=\"mpunct\">;</span><span class=\"mspace\" style=\"margin-right:1em;\"></span><span class=\"mspace\" style=\"margin-right:0.1667em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.02778em;\">θ</span><span class=\"mopen\">(</span><span class=\"mord mathnormal\">x</span><span class=\"mclose\">)</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.8889em;vertical-align:-0.1944em;\"></span><span class=\"mord\">−</span><span class=\"mord\">1</span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.1667em;\"></span><span class=\"mord\">∀</span><span class=\"mord mathnormal\">x</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span><span class=\"mrel\">≤</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord\">0</span><span class=\"mclose\">}</span></span></span></span></span></li>\n</ul>\n<p> </p>\n<p><strong>(1) VC 차원이 무한하다고 한다.</strong></p>\n<p>즉, 점의 개수 <span class=\"math math-inline\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>l</mi></mrow><annotation encoding=\"application/x-tex\">l</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.6944em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.01968em;\">l</span></span></span></span></span>마다 점의 배치 <span class=\"math math-inline\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>x</mi><mi>i</mi></msub></mrow><annotation encoding=\"application/x-tex\">x_i</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.5806em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">x</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.3117em;\"><span style=\"top:-2.55em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">i</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span></span>를 적절히 정해주면 어떠한 레이블 조합 <span class=\"math math-inline\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>y</mi><mi>i</mi></msub></mrow><annotation encoding=\"application/x-tex\">y_i</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.625em;vertical-align:-0.1944em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">y</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.3117em;\"><span style=\"top:-2.55em;margin-left:-0.0359em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">i</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span></span>이든 <span class=\"math math-inline\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>α</mi></mrow><annotation encoding=\"application/x-tex\">\\alpha</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.4306em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.0037em;\">α</span></span></span></span></span>가 적절히 정해져 모델이 정확히 분할 가능하다는 것이다.\n그런데, <strong>이 논문에서 VC 차원의 증명 아이디어가 잘못된 것으로 보인다</strong>. (누가 정답을 알려주십쇼..)</p>\n<ul>\n<li><span class=\"math math-inline\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>x</mi><mi>i</mi></msub><mo>=</mo><mn>1</mn><msup><mn>0</mn><mrow><mo>−</mo><mi>i</mi></mrow></msup><mo separator=\"true\">,</mo><mspace width=\"1em\"></mspace><mi>i</mi><mo>=</mo><mn>1</mn><mo separator=\"true\">,</mo><mo>⋯</mo><mtext> </mtext><mo separator=\"true\">,</mo><mi>l</mi></mrow><annotation encoding=\"application/x-tex\">x_{i}=10^{-i}, \\quad i=1, \\cdots, l</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.5806em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">x</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.3117em;\"><span style=\"top:-2.55em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">i</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1.0191em;vertical-align:-0.1944em;\"></span><span class=\"mord\">1</span><span class=\"mord\"><span class=\"mord\">0</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8247em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\">−</span><span class=\"mord mathnormal mtight\">i</span></span></span></span></span></span></span></span></span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:1em;\"></span><span class=\"mspace\" style=\"margin-right:0.1667em;\"></span><span class=\"mord mathnormal\">i</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.8889em;vertical-align:-0.1944em;\"></span><span class=\"mord\">1</span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.1667em;\"></span><span class=\"minner\">⋯</span><span class=\"mspace\" style=\"margin-right:0.1667em;\"></span><span class=\"mspace\" style=\"margin-right:0.1667em;\"></span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.1667em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.01968em;\">l</span></span></span></span></span> (점의 위치)</li>\n<li><span class=\"math math-inline\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>y</mi><mn>1</mn></msub><mo separator=\"true\">,</mo><msub><mi>y</mi><mn>2</mn></msub><mo separator=\"true\">,</mo><mo>⋯</mo><mtext> </mtext><mo separator=\"true\">,</mo><msub><mi>y</mi><mi>l</mi></msub><mo separator=\"true\">,</mo><mspace width=\"1em\"></mspace><msub><mi>y</mi><mi>i</mi></msub><mo>∈</mo><mo stretchy=\"false\">{</mo><mo>−</mo><mn>1</mn><mo separator=\"true\">,</mo><mn>1</mn><mo stretchy=\"false\">}</mo></mrow><annotation encoding=\"application/x-tex\">y_{1}, y_{2}, \\cdots, y_{l}, \\quad y_{i} \\in\\{-1,1\\}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.7335em;vertical-align:-0.1944em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">y</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.3011em;\"><span style=\"top:-2.55em;margin-left:-0.0359em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\">1</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.1667em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">y</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.3011em;\"><span style=\"top:-2.55em;margin-left:-0.0359em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\">2</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.1667em;\"></span><span class=\"minner\">⋯</span><span class=\"mspace\" style=\"margin-right:0.1667em;\"></span><span class=\"mspace\" style=\"margin-right:0.1667em;\"></span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.1667em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">y</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.3361em;\"><span style=\"top:-2.55em;margin-left:-0.0359em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.01968em;\">l</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:1em;\"></span><span class=\"mspace\" style=\"margin-right:0.1667em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">y</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.3117em;\"><span style=\"top:-2.55em;margin-left:-0.0359em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">i</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span><span class=\"mrel\">∈</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mopen\">{</span><span class=\"mord\">−</span><span class=\"mord\">1</span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.1667em;\"></span><span class=\"mord\">1</span><span class=\"mclose\">}</span></span></span></span></span></li>\n<li><span class=\"math math-inline\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>α</mi><mo>=</mo><mi>π</mi><mrow><mo fence=\"true\">(</mo><mn>1</mn><mo>+</mo><msubsup><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>l</mi></msubsup><mfrac><mrow><mrow><mo fence=\"true\">(</mo><mn>1</mn><mo>−</mo><msub><mi>y</mi><mi>i</mi></msub><mo fence=\"true\">)</mo></mrow><mn>1</mn><msup><mn>0</mn><mi>i</mi></msup></mrow><mn>2</mn></mfrac><mo fence=\"true\">)</mo></mrow></mrow><annotation encoding=\"application/x-tex\">\\alpha=\\pi\\left(1+\\sum_{i=1}^{l} \\frac{\\left(1-y_{i}\\right) 10^{i}}{2}\\right)</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.4306em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.0037em;\">α</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1.8em;vertical-align:-0.65em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">π</span><span class=\"mspace\" style=\"margin-right:0.1667em;\"></span><span class=\"minner\"><span class=\"mopen delimcenter\" style=\"top:0em;\"><span class=\"delimsizing size2\">(</span></span><span class=\"mord\">1</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span><span class=\"mbin\">+</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span><span class=\"mop\"><span class=\"mop op-symbol small-op\" style=\"position:relative;top:0em;\">∑</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.989em;\"><span style=\"top:-2.4003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">i</span><span class=\"mrel mtight\">=</span><span class=\"mord mtight\">1</span></span></span></span><span style=\"top:-3.2029em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.01968em;\">l</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2997em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.1667em;\"></span><span class=\"mord\"><span class=\"mopen nulldelimiter\"></span><span class=\"mfrac\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.1165em;\"><span style=\"top:-2.655em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\">2</span></span></span></span><span style=\"top:-3.23em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"frac-line\" style=\"border-bottom-width:0.04em;\"></span></span><span style=\"top:-3.485em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"minner mtight\"><span class=\"mopen mtight delimcenter\" style=\"top:0em;\"><span class=\"mtight\">(</span></span><span class=\"mord mtight\">1</span><span class=\"mbin mtight\">−</span><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.03588em;\">y</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.3281em;\"><span style=\"top:-2.357em;margin-left:-0.0359em;margin-right:0.0714em;\"><span class=\"pstrut\" style=\"height:2.5em;\"></span><span class=\"sizing reset-size3 size1 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">i</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.143em;\"><span></span></span></span></span></span></span><span class=\"mclose mtight delimcenter\" style=\"top:0em;\"><span class=\"mtight\">)</span></span></span><span class=\"mord mtight\">1</span><span class=\"mord mtight\"><span class=\"mord mtight\">0</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.9021em;\"><span style=\"top:-2.931em;margin-right:0.0714em;\"><span class=\"pstrut\" style=\"height:2.5em;\"></span><span class=\"sizing reset-size3 size1 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">i</span></span></span></span></span></span></span></span></span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.345em;\"><span></span></span></span></span></span><span class=\"mclose nulldelimiter\"></span></span><span class=\"mclose delimcenter\" style=\"top:0em;\"><span class=\"delimsizing size2\">)</span></span></span></span></span></span></span></li>\n</ul>\n<p>와 같이 점의 위치(배치)를 정해주고, 레이블 조합 <span class=\"math math-inline\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>y</mi><mi>i</mi></msub></mrow><annotation encoding=\"application/x-tex\">y_i</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.625em;vertical-align:-0.1944em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">y</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.3117em;\"><span style=\"top:-2.55em;margin-left:-0.0359em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">i</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span></span> 값에 따라 <span class=\"math math-inline\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>α</mi></mrow><annotation encoding=\"application/x-tex\">\\alpha</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.4306em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.0037em;\">α</span></span></span></span></span>값이 정해지도록 했다.\n즉, 점의 위치(배치)를 정해준 후 레이블 조합마다 <span class=\"math math-inline\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>α</mi></mrow><annotation encoding=\"application/x-tex\">\\alpha</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.4306em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.0037em;\">α</span></span></span></span></span>가 알아서 정해지고, <span class=\"math math-inline\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>f</mi><mo stretchy=\"false\">(</mo><mi>x</mi><mo separator=\"true\">,</mo><mi>α</mi><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">f(x, \\alpha)</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.10764em;\">f</span><span class=\"mopen\">(</span><span class=\"mord mathnormal\">x</span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.1667em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.0037em;\">α</span><span class=\"mclose\">)</span></span></span></span></span>의 값이 정해진다. 해당 레이블 조합에서 <span class=\"math math-inline\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>f</mi><mo stretchy=\"false\">(</mo><mi>x</mi><mo separator=\"true\">,</mo><mi>α</mi><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">f(x, \\alpha)</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.10764em;\">f</span><span class=\"mopen\">(</span><span class=\"mord mathnormal\">x</span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.1667em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.0037em;\">α</span><span class=\"mclose\">)</span></span></span></span></span>의 값과 <span class=\"math math-inline\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>y</mi><mi>i</mi></msub></mrow><annotation encoding=\"application/x-tex\">y_i</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.625em;vertical-align:-0.1944em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">y</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.3117em;\"><span style=\"top:-2.55em;margin-left:-0.0359em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">i</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span></span> 값이 같으면 분할 가능한 것이다.</p>\n<p> </p>\n<p>=> 그렇지만… <strong>이 논문에서 위와 같은 <span class=\"math math-inline\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>x</mi><mi>i</mi></msub></mrow><annotation encoding=\"application/x-tex\">x_i</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.5806em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">x</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.3117em;\"><span style=\"top:-2.55em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">i</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span></span>에서는 증명이 되지 않는 것 같다..</strong></p>\n<p> </p>\n<blockquote>\n<p><strong>[증명이 되지 않았던 이유]</strong></p>\n<p>점의 개수(<span class=\"math math-inline\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>l</mi></mrow><annotation encoding=\"application/x-tex\">l</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.6944em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.01968em;\">l</span></span></span></span></span>)는 3이고, <strong>점의 위치는 <span class=\"math math-inline\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>x</mi><mi>i</mi></msub><mo>=</mo><mn>1</mn><msup><mn>0</mn><mrow><mo>−</mo><mi>i</mi></mrow></msup><mo stretchy=\"false\">(</mo><mi>i</mi><mo>=</mo><mn>1</mn><mo separator=\"true\">,</mo><mo>⋯</mo><mtext> </mtext><mo separator=\"true\">,</mo><mi>l</mi></mrow><annotation encoding=\"application/x-tex\">x_{i}=10^{-i} (i=1, \\cdots, l</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.5806em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">x</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.3117em;\"><span style=\"top:-2.55em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">i</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1.0747em;vertical-align:-0.25em;\"></span><span class=\"mord\">1</span><span class=\"mord\"><span class=\"mord\">0</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8247em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\">−</span><span class=\"mord mathnormal mtight\">i</span></span></span></span></span></span></span></span></span><span class=\"mopen\">(</span><span class=\"mord mathnormal\">i</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.8889em;vertical-align:-0.1944em;\"></span><span class=\"mord\">1</span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.1667em;\"></span><span class=\"minner\">⋯</span><span class=\"mspace\" style=\"margin-right:0.1667em;\"></span><span class=\"mspace\" style=\"margin-right:0.1667em;\"></span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.1667em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.01968em;\">l</span></span></span></span></span>)</strong> 일 때, **레이블 조합이 (-1, +1, -1)**인 경우</p>\n<ul>\n<li><span class=\"math math-inline\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>α</mi><mo>=</mo><mi>π</mi><mo stretchy=\"false\">(</mo><mn>1</mn><mo>+</mo><mn>10</mn><mo>+</mo><mn>0</mn><mo>+</mo><mn>1000</mn><mo stretchy=\"false\">)</mo><mo>=</mo><mn>1011</mn><mi>π</mi></mrow><annotation encoding=\"application/x-tex\">\\alpha=\\pi(1+10+0+1000)=1011\\pi</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.4306em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.0037em;\">α</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">π</span><span class=\"mopen\">(</span><span class=\"mord\">1</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span><span class=\"mbin\">+</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.7278em;vertical-align:-0.0833em;\"></span><span class=\"mord\">10</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span><span class=\"mbin\">+</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.7278em;vertical-align:-0.0833em;\"></span><span class=\"mord\">0</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span><span class=\"mbin\">+</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord\">1000</span><span class=\"mclose\">)</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.6444em;\"></span><span class=\"mord\">1011</span><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">π</span></span></span></span></span>이므로, <span class=\"math math-inline\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>f</mi><mo stretchy=\"false\">(</mo><mi>x</mi><mo separator=\"true\">,</mo><mi>α</mi><mo stretchy=\"false\">)</mo><mo>=</mo><mi>θ</mi><mo stretchy=\"false\">(</mo><mi>sin</mi><mo>⁡</mo><mo stretchy=\"false\">(</mo><mn>1011</mn><mi>π</mi><mi>x</mi><mo stretchy=\"false\">)</mo><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">f(x, \\alpha)=\\theta(\\sin(1011\\pi x))</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.10764em;\">f</span><span class=\"mopen\">(</span><span class=\"mord mathnormal\">x</span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.1667em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.0037em;\">α</span><span class=\"mclose\">)</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.02778em;\">θ</span><span class=\"mopen\">(</span><span class=\"mop\">sin</span><span class=\"mopen\">(</span><span class=\"mord\">1011</span><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">π</span><span class=\"mord mathnormal\">x</span><span class=\"mclose\">))</span></span></span></span></span>이다.</li>\n<li><span class=\"math math-inline\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>x</mi><mn>1</mn></msub><mo>=</mo><mn>1</mn><msup><mn>0</mn><mrow><mo>−</mo><mn>1</mn></mrow></msup></mrow><annotation encoding=\"application/x-tex\">x_1=10^{-1}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.5806em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">x</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.3011em;\"><span style=\"top:-2.55em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">1</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.8141em;\"></span><span class=\"mord\">1</span><span class=\"mord\"><span class=\"mord\">0</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8141em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\">−</span><span class=\"mord mtight\">1</span></span></span></span></span></span></span></span></span></span></span></span></span>의 레이블 <span class=\"math math-inline\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>y</mi><mn>1</mn></msub><mo>=</mo><mn>1</mn></mrow><annotation encoding=\"application/x-tex\">y_1=1</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.625em;vertical-align:-0.1944em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">y</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.3011em;\"><span style=\"top:-2.55em;margin-left:-0.0359em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">1</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.6444em;\"></span><span class=\"mord\">1</span></span></span></span></span>인데 <span class=\"math math-inline\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>f</mi><mo stretchy=\"false\">(</mo><mi>x</mi><mo separator=\"true\">,</mo><mi>α</mi><mo stretchy=\"false\">)</mo><mo>=</mo><mi>θ</mi><mo stretchy=\"false\">(</mo><mi>sin</mi><mo>⁡</mo><mo stretchy=\"false\">(</mo><mn>1011</mn><mi>π</mi><mo>⋅</mo><mn>1</mn><msup><mn>0</mn><mrow><mo>−</mo><mn>1</mn></mrow></msup><mo stretchy=\"false\">)</mo><mo stretchy=\"false\">)</mo><mo>=</mo><mi>θ</mi><mo stretchy=\"false\">(</mo><mi>sin</mi><mo>⁡</mo><mo stretchy=\"false\">(</mo><mn>101.1</mn><mi>π</mi><mo stretchy=\"false\">)</mo><mo stretchy=\"false\">)</mo><mo>=</mo><mo>−</mo><mn>1</mn></mrow><annotation encoding=\"application/x-tex\">f(x, \\alpha)=\\theta(\\sin(1011\\pi \\cdot 10^{-1})) = \\theta(\\sin(101.1\\pi))=-1</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.10764em;\">f</span><span class=\"mopen\">(</span><span class=\"mord mathnormal\">x</span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.1667em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.0037em;\">α</span><span class=\"mclose\">)</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.02778em;\">θ</span><span class=\"mopen\">(</span><span class=\"mop\">sin</span><span class=\"mopen\">(</span><span class=\"mord\">1011</span><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">π</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span><span class=\"mbin\">⋅</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1.0641em;vertical-align:-0.25em;\"></span><span class=\"mord\">1</span><span class=\"mord\"><span class=\"mord\">0</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8141em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\">−</span><span class=\"mord mtight\">1</span></span></span></span></span></span></span></span></span><span class=\"mclose\">))</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.02778em;\">θ</span><span class=\"mopen\">(</span><span class=\"mop\">sin</span><span class=\"mopen\">(</span><span class=\"mord\">101.1</span><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">π</span><span class=\"mclose\">))</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.7278em;vertical-align:-0.0833em;\"></span><span class=\"mord\">−</span><span class=\"mord\">1</span></span></span></span></span>이므로, 그 값은 <span class=\"math math-inline\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>y</mi><mn>1</mn></msub><mo>=</mo><mn>1</mn></mrow><annotation encoding=\"application/x-tex\">y_{1}=1</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.625em;vertical-align:-0.1944em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">y</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.3011em;\"><span style=\"top:-2.55em;margin-left:-0.0359em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\">1</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.6444em;\"></span><span class=\"mord\">1</span></span></span></span></span>과 다르다.</li>\n<li>결국엔 현재 점의 배치에서는 어떤 레이블 조합을 분할할 수 없다는 이야기다.</li>\n</ul>\n<p>결론은 <strong>점의 개수마다 적절한 배치를 설정하면 VC 차원이 무한함을 증명할 수 있지 않을까</strong> 한다..</p>\n</blockquote>\n<p> </p>\n<p>(2) <span class=\"math math-inline\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>l</mi></mrow><annotation encoding=\"application/x-tex\">l</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.6944em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.01968em;\">l</span></span></span></span></span>개의 점의 어떤 특정 배치에서 레이블의 모든 조합을 분할할 수 없는 예시</p>\n<p>간단하다. 위와 같은 모델에 대해 <strong>동일한 간격의 배치</strong>에서는 모든 레이블 조합에 대해 분할이 불가능하다고 한다.\n스킵해도 충분하다고 생각한다.</p>\n<p> </p>\n<h3 id=\"24-minimizing-the-bound-by-minimizing-h\" style=\"position:relative;\"><a href=\"#24-minimizing-the-bound-by-minimizing-h\" aria-label=\"24 minimizing the bound by minimizing h permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>2.4 Minimizing The Bound by Minimizing <span class=\"math math-inline\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>h</mi></mrow><annotation encoding=\"application/x-tex\">h</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.6944em;\"></span><span class=\"mord mathnormal\">h</span></span></span></span></span></h3>\n<p>VC 차원을 최소화함으로써 위험 경계를 최소화하는 것에 대해 설명하고 있다.</p>\n<p>아까 봤던 <span class=\"math math-inline\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>R</mi><mo stretchy=\"false\">(</mo><mi>α</mi><mo stretchy=\"false\">)</mo><mo>≤</mo><msub><mi>R</mi><mtext>emp</mtext></msub><mo stretchy=\"false\">(</mo><mi>α</mi><mo stretchy=\"false\">)</mo><mo>+</mo><msqrt><mrow><mo fence=\"true\">(</mo><mfrac><mrow><mi>h</mi><mo stretchy=\"false\">(</mo><mi>log</mi><mo>⁡</mo><mo stretchy=\"false\">(</mo><mn>2</mn><mi>l</mi><mi mathvariant=\"normal\">/</mi><mi>h</mi><mo stretchy=\"false\">)</mo><mo>+</mo><mn>1</mn><mo stretchy=\"false\">)</mo><mo>−</mo><mi>log</mi><mo>⁡</mo><mo stretchy=\"false\">(</mo><mi>η</mi><mi mathvariant=\"normal\">/</mi><mn>4</mn><mo stretchy=\"false\">)</mo></mrow><mi>l</mi></mfrac><mo fence=\"true\">)</mo></mrow></msqrt></mrow><annotation encoding=\"application/x-tex\">R(\\alpha) \\leq R_{\\text{emp}}(\\alpha)+\\sqrt{\\left(\\frac{h(\\log (2 l / h)+1)-\\log (\\eta / 4)}{l}\\right)}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.00773em;\">R</span><span class=\"mopen\">(</span><span class=\"mord mathnormal\" style=\"margin-right:0.0037em;\">α</span><span class=\"mclose\">)</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span><span class=\"mrel\">≤</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1.0361em;vertical-align:-0.2861em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.00773em;\">R</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.1514em;\"><span style=\"top:-2.55em;margin-left:-0.0077em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord text mtight\"><span class=\"mord mtight\">emp</span></span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2861em;\"><span></span></span></span></span></span></span><span class=\"mopen\">(</span><span class=\"mord mathnormal\" style=\"margin-right:0.0037em;\">α</span><span class=\"mclose\">)</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span><span class=\"mbin\">+</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:2.44em;vertical-align:-0.905em;\"></span><span class=\"mord sqrt\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.535em;\"><span class=\"svg-align\" style=\"top:-4.4em;\"><span class=\"pstrut\" style=\"height:4.4em;\"></span><span class=\"mord\" style=\"padding-left:1em;\"><span class=\"minner\"><span class=\"mopen delimcenter\" style=\"top:0em;\"><span class=\"delimsizing size2\">(</span></span><span class=\"mord\"><span class=\"mopen nulldelimiter\"></span><span class=\"mfrac\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.01em;\"><span style=\"top:-2.655em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.01968em;\">l</span></span></span></span><span style=\"top:-3.23em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"frac-line\" style=\"border-bottom-width:0.04em;\"></span></span><span style=\"top:-3.485em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">h</span><span class=\"mopen mtight\">(</span><span class=\"mop mtight\"><span class=\"mtight\">l</span><span class=\"mtight\">o</span><span class=\"mtight\" style=\"margin-right:0.01389em;\">g</span></span><span class=\"mopen mtight\">(</span><span class=\"mord mtight\">2</span><span class=\"mord mathnormal mtight\" style=\"margin-right:0.01968em;\">l</span><span class=\"mord mtight\">/</span><span class=\"mord mathnormal mtight\">h</span><span class=\"mclose mtight\">)</span><span class=\"mbin mtight\">+</span><span class=\"mord mtight\">1</span><span class=\"mclose mtight\">)</span><span class=\"mbin mtight\">−</span><span class=\"mop mtight\"><span class=\"mtight\">l</span><span class=\"mtight\">o</span><span class=\"mtight\" style=\"margin-right:0.01389em;\">g</span></span><span class=\"mopen mtight\">(</span><span class=\"mord mathnormal mtight\" style=\"margin-right:0.03588em;\">η</span><span class=\"mord mtight\">/4</span><span class=\"mclose mtight\">)</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.345em;\"><span></span></span></span></span></span><span class=\"mclose nulldelimiter\"></span></span><span class=\"mclose delimcenter\" style=\"top:0em;\"><span class=\"delimsizing size2\">)</span></span></span></span></span><span style=\"top:-3.495em;\"><span class=\"pstrut\" style=\"height:4.4em;\"></span><span class=\"hide-tail\" style=\"min-width:1.02em;height:2.48em;\"><svg xmlns=\"http://www.w3.org/2000/svg\" width=\"400em\" height=\"2.48em\" viewBox=\"0 0 400000 2592\" preserveAspectRatio=\"xMinYMin slice\"><path d=\"M424,2478\nc-1.3,-0.7,-38.5,-172,-111.5,-514c-73,-342,-109.8,-513.3,-110.5,-514\nc0,-2,-10.7,14.3,-32,49c-4.7,7.3,-9.8,15.7,-15.5,25c-5.7,9.3,-9.8,16,-12.5,20\ns-5,7,-5,7c-4,-3.3,-8.3,-7.7,-13,-13s-13,-13,-13,-13s76,-122,76,-122s77,-121,77,-121\ns209,968,209,968c0,-2,84.7,-361.7,254,-1079c169.3,-717.3,254.7,-1077.7,256,-1081\nl0 -0c4,-6.7,10,-10,18,-10 H400000\nv40H1014.6\ns-87.3,378.7,-272.6,1166c-185.3,787.3,-279.3,1182.3,-282,1185\nc-2,6,-10,9,-24,9\nc-8,0,-12,-0.7,-12,-2z M1001 80\nh400000v40h-400000z\"></path></svg></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.905em;\"><span></span></span></span></span></span></span></span></span></span> 식을 기억하자. 아래의 그림은 <span class=\"math math-inline\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mn>95</mn><mi mathvariant=\"normal\">%</mi></mrow><annotation encoding=\"application/x-tex\">95 \\%</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8056em;vertical-align:-0.0556em;\"></span><span class=\"mord\">95%</span></span></span></span></span> 신뢰 수준 <span class=\"math math-inline\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mo stretchy=\"false\">(</mo><mi>η</mi><mo>=</mo><mn>0.05</mn><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">(\\eta=0.05)</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mopen\">(</span><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">η</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord\">0.05</span><span class=\"mclose\">)</span></span></span></span></span>을 선택하고 훈련 샘플 크기 10,000을 가정할 때 VC 차원 <span class=\"math math-inline\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>h</mi></mrow><annotation encoding=\"application/x-tex\">h</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.6944em;\"></span><span class=\"mord mathnormal\">h</span></span></span></span></span>에 따라 VC 신뢰도 항이 어떻게 보여주는지를 보여준다.</p>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 541px; \"\n    >\n      <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 78.33333333333333%; position: relative; bottom: 0; left: 0; background-image: url('data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAAQABQDASIAAhEBAxEB/8QAFgABAQEAAAAAAAAAAAAAAAAAAQAF/8QAFAEBAAAAAAAAAAAAAAAAAAAAAP/aAAwDAQACEAMQAAAB3kBqP//EABYQAAMAAAAAAAAAAAAAAAAAABARIP/aAAgBAQABBQKGP//EABQRAQAAAAAAAAAAAAAAAAAAABD/2gAIAQMBAT8BP//EABQRAQAAAAAAAAAAAAAAAAAAABD/2gAIAQIBAT8BP//EABQQAQAAAAAAAAAAAAAAAAAAACD/2gAIAQEABj8CX//EABgQAQADAQAAAAAAAAAAAAAAAAABETEh/9oACAEBAAE/IY6pLFWv/9oADAMBAAIAAwAAABAQD//EABQRAQAAAAAAAAAAAAAAAAAAABD/2gAIAQMBAT8QP//EABQRAQAAAAAAAAAAAAAAAAAAABD/2gAIAQIBAT8QP//EABwQAAMAAQUAAAAAAAAAAAAAAAABEVEhQWFxof/aAAgBAQABPxBlTzGdPTQy26nNjnMknD//2Q=='); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"img-1\"\n        title=\"img-1\"\n        src=\"/static/45fca1ade645773aa33c0401ace08fc1/8af7b/img-1.jpg\"\n        srcset=\"/static/45fca1ade645773aa33c0401ace08fc1/4ec73/img-1.jpg 180w,\n/static/45fca1ade645773aa33c0401ace08fc1/158ba/img-1.jpg 360w,\n/static/45fca1ade645773aa33c0401ace08fc1/8af7b/img-1.jpg 541w\"\n        sizes=\"(max-width: 541px) 100vw, 541px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n        decoding=\"async\"\n      />\n    </span></p>\n<ul>\n<li><span class=\"math math-inline\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>l</mi></mrow><annotation encoding=\"application/x-tex\">l</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.6944em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.01968em;\">l</span></span></span></span></span>의 값에 관계없이, <strong>VC 차원이 증가할수록 VC 신뢰도가 커진다</strong>. (<strong>단조 증가 함수</strong>)</li>\n<li>경험적 위험 <span class=\"math math-inline\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>R</mi><mtext>emp</mtext></msub></mrow><annotation encoding=\"application/x-tex\">R_{\\text{emp}}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.9694em;vertical-align:-0.2861em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.00773em;\">R</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.1514em;\"><span style=\"top:-2.55em;margin-left:-0.0077em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord text mtight\"><span class=\"mord mtight\">emp</span></span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2861em;\"><span></span></span></span></span></span></span></span></span></span></span>이 0인 경우, VC 신뢰도 항만 최소화하는 기계를 선택하면 된다.</li>\n<li>일반적으로 경험적 위험 <span class=\"math math-inline\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>R</mi><mtext>emp</mtext></msub></mrow><annotation encoding=\"application/x-tex\">R_{\\text{emp}}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.9694em;vertical-align:-0.2861em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.00773em;\">R</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.1514em;\"><span style=\"top:-2.55em;margin-left:-0.0077em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord text mtight\"><span class=\"mord mtight\">emp</span></span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2861em;\"><span></span></span></span></span></span></span></span></span></span></span>이 0이 아닌 경우, 위험 경계 전체 항을 최소화하는 기계를 선택한다.</li>\n<li><strong><span class=\"math math-inline\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>h</mi></mrow><annotation encoding=\"application/x-tex\">h</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.6944em;\"></span><span class=\"mord mathnormal\">h</span></span></span></span></span>가 작을수록 훈련 데이터에 과소적합 되어 경험적 위험 <span class=\"math math-inline\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>R</mi><mtext>emp</mtext></msub></mrow><annotation encoding=\"application/x-tex\">R_{\\text{emp}}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.9694em;vertical-align:-0.2861em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.00773em;\">R</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.1514em;\"><span style=\"top:-2.55em;margin-left:-0.0077em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord text mtight\"><span class=\"mord mtight\">emp</span></span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2861em;\"><span></span></span></span></span></span></span></span></span></span></span>이 커질 수 있지만,</strong>\n<strong>VC 신뢰도가 낮아 실제 위험(오류율) <span class=\"math math-inline\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>R</mi><mo stretchy=\"false\">(</mo><mi>α</mi><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">R(\\alpha)</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.00773em;\">R</span><span class=\"mopen\">(</span><span class=\"mord mathnormal\" style=\"margin-right:0.0037em;\">α</span><span class=\"mclose\">)</span></span></span></span></span>가 더 tight한 상한에 제한되어, 예측의 오류율이 적어질 수 있는 가능성이 있다.</strong></li>\n<li><strong><span class=\"math math-inline\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>h</mi></mrow><annotation encoding=\"application/x-tex\">h</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.6944em;\"></span><span class=\"mord mathnormal\">h</span></span></span></span></span>가 클수록 훈련 데이터에 과대적합 되어 경험적 위험 <span class=\"math math-inline\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>R</mi><mtext>emp</mtext></msub></mrow><annotation encoding=\"application/x-tex\">R_{\\text{emp}}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.9694em;vertical-align:-0.2861em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.00773em;\">R</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.1514em;\"><span style=\"top:-2.55em;margin-left:-0.0077em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord text mtight\"><span class=\"mord mtight\">emp</span></span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2861em;\"><span></span></span></span></span></span></span></span></span></span></span>이 작아질 수 있지만,</strong>\n<strong>VC 신뢰도가 높아 실제 위험(오류율) <span class=\"math math-inline\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>R</mi><mo stretchy=\"false\">(</mo><mi>α</mi><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">R(\\alpha)</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.00773em;\">R</span><span class=\"mopen\">(</span><span class=\"mord mathnormal\" style=\"margin-right:0.0037em;\">α</span><span class=\"mclose\">)</span></span></span></span></span>가 느슨한 상한에 제한되어, 예측의 오류율이 커질 수 있는 가능성이 있다.</strong></li>\n<li><span class=\"math math-inline\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>h</mi><mi mathvariant=\"normal\">/</mi><mi>l</mi><mo>></mo><mn>3.7</mn></mrow><annotation encoding=\"application/x-tex\">h/l>3.7</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathnormal\">h</span><span class=\"mord\">/</span><span class=\"mord mathnormal\" style=\"margin-right:0.01968em;\">l</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span><span class=\"mrel\">></span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.6444em;\"></span><span class=\"mord\">3.7</span></span></span></span></span>일 때 VC 신뢰도가 1을 초과한다. VC 신뢰도가 1을 넘으면 상한(위험 경계)도 1이상인데, 이는 실제 위험(오류율) <span class=\"math math-inline\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>R</mi><mo stretchy=\"false\">(</mo><mi>α</mi><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">R(\\alpha)</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.00773em;\">R</span><span class=\"mopen\">(</span><span class=\"mord mathnormal\" style=\"margin-right:0.0037em;\">α</span><span class=\"mclose\">)</span></span></span></span></span>를 0과 1 사이의 범위를 제한하지 못하기 때문에 의미가 없는 상황이다. 결론적으로, <strong>적어도 VC 신뢰도가 1미만이 되도록 <span class=\"math math-inline\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>h</mi><mi mathvariant=\"normal\">/</mi><mi>l</mi></mrow><annotation encoding=\"application/x-tex\">h/l</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathnormal\">h</span><span class=\"mord\">/</span><span class=\"mord mathnormal\" style=\"margin-right:0.01968em;\">l</span></span></span></span></span>의 값을 제한해야 상한이 유의미하다.</strong></li>\n</ul>\n<p> </p>\n<p>그래서 결론이 무엇이냐.\nVC 차원을 크게 설정한다고 좋은 상황이 되는 것도 아니고, 작게한다고 좋은 상황이 되는 것이 아니다.</p>\n<p><strong>“VC 차원이 증가할수록 VC 신뢰도가 커져야 한다. 그리고 VC 신뢰도가 1미만이 되도록 하는 <span class=\"math math-inline\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>h</mi><mi mathvariant=\"normal\">/</mi><mi>l</mi></mrow><annotation encoding=\"application/x-tex\">h/l</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathnormal\">h</span><span class=\"mord\">/</span><span class=\"mord mathnormal\" style=\"margin-right:0.01968em;\">l</span></span></span></span></span>을 먼저 선택해야 하고, <span class=\"math math-inline\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>h</mi></mrow><annotation encoding=\"application/x-tex\">h</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.6944em;\"></span><span class=\"mord mathnormal\">h</span></span></span></span></span>의 값에 따라 경험적 위험과 VC 신뢰도는 반대로 변화하기 때문에 위험 경계(경험적 위험과 VC 신뢰도의 합)를 최소화하는 적절한 <span class=\"math math-inline\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>h</mi></mrow><annotation encoding=\"application/x-tex\">h</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.6944em;\"></span><span class=\"mord mathnormal\">h</span></span></span></span></span>값을 찾아야 한다는 것이다.”</strong></p>\n<p> </p>\n<h3 id=\"25-two-examples\" style=\"position:relative;\"><a href=\"#25-two-examples\" aria-label=\"25 two examples permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>2.5 Two Examples</h3>\n<p><strong>k=1인 KNN(k-최근접 이웃) 분류기</strong>와 <strong>notebook 분류기</strong>로 두 가지 예시를 들고 있다.</p>\n<p><strong>(1) k=1인 KNN 분류기</strong></p>\n<p>k=1인 KNN 분류기는 주변의 이웃 1개의 레이블을 가지고 학습하기 때문에 <strong>반대 클래스의 두 점이 서로 겹치지 않으면, 정확히 직선으로 분할할 수 있다.</strong> 즉, 점의 개수가 얼마나 많든 직선으로 분할 가능하기 때문에 <strong>VC 차원이 무한</strong>이다. 그래서 어떤 결정 경계가 있다고 해도 잘 일반화시킬 수 있다. 결국에는 <strong>높은 용량(VC 차원 높음)이어도 성능이 나쁘지 않을 수 있다</strong>는 것을 알 수 있다.</p>\n<p>라고 했는데, 결국 <strong>반대 클래스의 두 점이 서로 겹치지 않을 때만 VC 차원이 무한대</strong>가 된다. k=1인 KNN 분류기들이 VC 차원이 항상 무한대는 아니고, <strong>높은 용량이어도 성능이 나쁘지 않을 수 있다는 상황을 보여주기 위한 예제</strong>임을 기억하자.</p>\n<p> </p>\n<p><strong>(2) notebook 분류기</strong></p>\n<p><del>이 분류기에 대한 설명이 이해를 잘하지 못했다.. 우선 <strong>경계를 위반하는 분류기</strong>라고 한다.</del></p>\n<p>논문에서 서술하기에는 VC 차원에 대한 정의를 조금 다르게(?) 하고 있는 것으로 보였다. 이전까지 VC 차원에서는 훈련 데이터와 전체 데이터를 구분하여 설명하지 않았는데, 여기서는 <strong>먼저 훈련 데이터를 분류기를 통해 라벨링을 해준 후에, 그 훈련 데이터를 포함한 전체 데이터를 분할하려는데 최대 몇 개의 데이터까지 완벽하게 분할할 수 있는지</strong>에 관한 것으로 VC 차원을 설명하고 있다.</p>\n<p> </p>\n<ul>\n<li><strong>notebook 분류기는 모든 데이터 포인트를 동일한 클래스로 분류한다.</strong></li>\n</ul>\n<blockquote>\n<p>먼저, <span class=\"math math-inline\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>m</mi></mrow><annotation encoding=\"application/x-tex\">m</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.4306em;\"></span><span class=\"mord mathnormal\">m</span></span></span></span></span>개의 훈련 데이터를 해당 분류기를 통해 라벨링(노트북에 기록해준다라는 표현을 씀)을 해준다. (+1 또는 -1이다.)</p>\n<p>이후, 데이터를 1개부터 <span class=\"math math-inline\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>l</mi></mrow><annotation encoding=\"application/x-tex\">l</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.6944em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.01968em;\">l</span></span></span></span></span>개(전체 데이터)까지 늘리면서 해당 분류기로 얼마나 많은 데이터까지 정확히 분류할 수 있는지를 본다.</p>\n<p><span class=\"math math-inline\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>m</mi></mrow><annotation encoding=\"application/x-tex\">m</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.4306em;\"></span><span class=\"mord mathnormal\">m</span></span></span></span></span>개까지의 훈련 데이터는 이전의 동일한 클래스로 라벨링했기 때문에 정확히 분류할 것인데, 노트북에 기록되지 않은 데이터인 m+1개부터는 이전 훈련 데이터와 동일한 클래스로 분류하므로 정확히 분류할 수 없다.</p>\n</blockquote>\n<p>결국, <strong>notebook 분류기의 VC 차원은</strong> <strong><span class=\"math math-inline\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>m</mi></mrow><annotation encoding=\"application/x-tex\">m</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.4306em;\"></span><span class=\"mord mathnormal\">m</span></span></span></span></span></strong> (&#x3C;=l)이다.</p>\n<p> </p>\n<ul>\n<li><strong>경험적 위험이 m개의 관측값에 대해 0, 나머지에 대해 0.5이다.</strong></li>\n</ul>\n<blockquote>\n<p>처음 m개의 데이터는 해당 분류기가 레이블을 정확히 기억하므로 <strong>오류율은 0</strong>이다.</p>\n<p><strong>나머지 l-m개의 데이터가 클래스 +1와 -1의 샘플이 동일한 비율로 있다고 가정</strong>했을 때, 해당 분류기는 이 데이터들에 대해 <strong>항상 같은 레이블을 예측하기 때문에 평균 오류율을 0.5</strong>라고 생각할 수 있다.</p>\n</blockquote>\n<p> </p>\n<p>아까 전에 봤던 실제 위험과 위험 경계 관련 식에 대입하면,</p>\n<div class=\"math math-display\"><span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><semantics><mrow><mfrac><mi>m</mi><mrow><mn>4</mn><mi>l</mi></mrow></mfrac><mo>≤</mo><mi>ln</mi><mo>⁡</mo><mo stretchy=\"false\">(</mo><mn>2</mn><mi>l</mi><mi mathvariant=\"normal\">/</mi><mi>m</mi><mo stretchy=\"false\">)</mo><mo>+</mo><mn>1</mn><mo>−</mo><mo stretchy=\"false\">(</mo><mn>1</mn><mi mathvariant=\"normal\">/</mi><mi>m</mi><mo stretchy=\"false\">)</mo><mi>ln</mi><mo>⁡</mo><mo stretchy=\"false\">(</mo><mi>η</mi><mi mathvariant=\"normal\">/</mi><mn>4</mn><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">\\frac{m}{4 l} \\leq \\ln (2 l / m)+1-(1 / m) \\ln (\\eta / 4)</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1.7936em;vertical-align:-0.686em;\"></span><span class=\"mord\"><span class=\"mopen nulldelimiter\"></span><span class=\"mfrac\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.1076em;\"><span style=\"top:-2.314em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord\">4</span><span class=\"mord mathnormal\" style=\"margin-right:0.01968em;\">l</span></span></span><span style=\"top:-3.23em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"frac-line\" style=\"border-bottom-width:0.04em;\"></span></span><span style=\"top:-3.677em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">m</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.686em;\"><span></span></span></span></span></span><span class=\"mclose nulldelimiter\"></span></span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span><span class=\"mrel\">≤</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mop\">ln</span><span class=\"mopen\">(</span><span class=\"mord\">2</span><span class=\"mord mathnormal\" style=\"margin-right:0.01968em;\">l</span><span class=\"mord\">/</span><span class=\"mord mathnormal\">m</span><span class=\"mclose\">)</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span><span class=\"mbin\">+</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.7278em;vertical-align:-0.0833em;\"></span><span class=\"mord\">1</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span><span class=\"mbin\">−</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mopen\">(</span><span class=\"mord\">1/</span><span class=\"mord mathnormal\">m</span><span class=\"mclose\">)</span><span class=\"mspace\" style=\"margin-right:0.1667em;\"></span><span class=\"mop\">ln</span><span class=\"mopen\">(</span><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">η</span><span class=\"mord\">/4</span><span class=\"mclose\">)</span></span></span></span></span></div>\n<p>와 같이 된다. 아래와 같이 변형하면, 모든 <span class=\"math math-inline\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>η</mi></mrow><annotation encoding=\"application/x-tex\">\\eta</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.625em;vertical-align:-0.1944em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">η</span></span></span></span></span></p>\n<div class=\"math math-display\"><span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><semantics><mrow><mi>f</mi><mo stretchy=\"false\">(</mo><mi>z</mi><mo stretchy=\"false\">)</mo><mo>=</mo><mrow><mo fence=\"true\">(</mo><mfrac><mi>z</mi><mn>2</mn></mfrac><mo fence=\"true\">)</mo></mrow><msup><mrow><mi>exp</mi><mo>⁡</mo></mrow><mrow><mo stretchy=\"false\">(</mo><mi>z</mi><mi mathvariant=\"normal\">/</mi><mn>4</mn><mo>−</mo><mn>1</mn><mo stretchy=\"false\">)</mo></mrow></msup><mo>≤</mo><mn>1</mn><mo separator=\"true\">,</mo><mspace width=\"1em\"></mspace><mi>z</mi><mo>≡</mo><mo stretchy=\"false\">(</mo><mi>m</mi><mi mathvariant=\"normal\">/</mi><mi>l</mi><mo stretchy=\"false\">)</mo><mo separator=\"true\">,</mo><mspace width=\"1em\"></mspace><mn>0</mn><mo>≤</mo><mi>z</mi><mo>≤</mo><mn>1</mn></mrow><annotation encoding=\"application/x-tex\">f(z)=\\left(\\frac{z}{2}\\right) \\exp ^{(z / 4-1)} \\leq 1, \\quad z \\equiv(m / l), \\quad 0 \\leq z \\leq 1</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.10764em;\">f</span><span class=\"mopen\">(</span><span class=\"mord mathnormal\" style=\"margin-right:0.04398em;\">z</span><span class=\"mclose\">)</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1.836em;vertical-align:-0.686em;\"></span><span class=\"minner\"><span class=\"mopen delimcenter\" style=\"top:0em;\"><span class=\"delimsizing size2\">(</span></span><span class=\"mord\"><span class=\"mopen nulldelimiter\"></span><span class=\"mfrac\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.1076em;\"><span style=\"top:-2.314em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord\">2</span></span></span><span style=\"top:-3.23em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"frac-line\" style=\"border-bottom-width:0.04em;\"></span></span><span style=\"top:-3.677em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.04398em;\">z</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.686em;\"><span></span></span></span></span></span><span class=\"mclose nulldelimiter\"></span></span><span class=\"mclose delimcenter\" style=\"top:0em;\"><span class=\"delimsizing size2\">)</span></span></span><span class=\"mspace\" style=\"margin-right:0.1667em;\"></span><span class=\"mop\"><span class=\"mop\">exp</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.938em;\"><span style=\"top:-3.113em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mopen mtight\">(</span><span class=\"mord mathnormal mtight\" style=\"margin-right:0.04398em;\">z</span><span class=\"mord mtight\">/4</span><span class=\"mbin mtight\">−</span><span class=\"mord mtight\">1</span><span class=\"mclose mtight\">)</span></span></span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span><span class=\"mrel\">≤</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.8389em;vertical-align:-0.1944em;\"></span><span class=\"mord\">1</span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:1em;\"></span><span class=\"mspace\" style=\"margin-right:0.1667em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.04398em;\">z</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span><span class=\"mrel\">≡</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mopen\">(</span><span class=\"mord mathnormal\">m</span><span class=\"mord\">/</span><span class=\"mord mathnormal\" style=\"margin-right:0.01968em;\">l</span><span class=\"mclose\">)</span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:1em;\"></span><span class=\"mspace\" style=\"margin-right:0.1667em;\"></span><span class=\"mord\">0</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span><span class=\"mrel\">≤</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.7719em;vertical-align:-0.136em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.04398em;\">z</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span><span class=\"mrel\">≤</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.6444em;\"></span><span class=\"mord\">1</span></span></span></span></span></div>\n<p>이 성립하게 되는데, 이는 <span class=\"math math-inline\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>f</mi><mo stretchy=\"false\">(</mo><mi>z</mi><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">f(z)</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.10764em;\">f</span><span class=\"mopen\">(</span><span class=\"mord mathnormal\" style=\"margin-right:0.04398em;\">z</span><span class=\"mclose\">)</span></span></span></span></span><strong>가 단조 증가하고</strong>, <span class=\"math math-inline\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>f</mi><mo stretchy=\"false\">(</mo><mi>z</mi><mo>=</mo><mn>1</mn><mo stretchy=\"false\">)</mo><mo>=</mo><mn>0.236</mn><mo>&#x3C;</mo><mn>1</mn></mrow><annotation encoding=\"application/x-tex\">f(z=1)=0.236&#x3C;1</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.10764em;\">f</span><span class=\"mopen\">(</span><span class=\"mord mathnormal\" style=\"margin-right:0.04398em;\">z</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord\">1</span><span class=\"mclose\">)</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.6835em;vertical-align:-0.0391em;\"></span><span class=\"mord\">0.236</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span><span class=\"mrel\">&#x3C;</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.6444em;\"></span><span class=\"mord\">1</span></span></span></span></span><strong>이기 때문에</strong> <strong>2.4에 따라 모든 Vapnik의 경계가 실제로 유효하다</strong>고 할 수 있다.</p>\n<p> </p>\n<p>2장은 <strong>VC 차원</strong>과 <strong>Vapnik의 경계</strong>과 관련된 의미를 파악하는 것이 가장 중요해보입니다. 현재까지 논문을 읽으면서 어렵고 힘들었지만 조금 이해한 것 같아 뿌듯하네요..</p>\n<p>논문이 조금 길어서 끊고 가겠습니다. 2편에서 봐요!</p>\n<div class=\"table-of-contents\">\n<ul>\n<li>\n<p><a href=\"#abstract\">Abstract</a></p>\n</li>\n<li>\n<p><a href=\"#1-intoduction\">1. Intoduction</a></p>\n</li>\n<li>\n<p><a href=\"#2-a-bound-on-the-generalization-performance-of-a-pattern-recognition-learning-machine\">2. A Bound on the Generalization Performance of a Pattern Recognition Learning Machine</a></p>\n<ul>\n<li><a href=\"#21-vc-dimension\">2.1 VC Dimension</a></li>\n<li><a href=\"#22-shattering-points-with-oriented-hyperplanes-in-rn\">2.2 Shattering Points with Oriented Hyperplanes in <span class=\"math math-inline\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msup><mi>R</mi><mi>n</mi></msup></mrow><annotation encoding=\"application/x-tex\">R^{n}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.6833em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.00773em;\">R</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.6644em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">n</span></span></span></span></span></span></span></span></span></span></span></span></span></a></li>\n<li><a href=\"#23-the-vc-dimension-and-the-number-of-parameters\">2.3 The VC Dimension and the Number of Parameters</a></li>\n<li><a href=\"#24-minimizing-the-bound-by-minimizing-h\">2.4 Minimizing The Bound by Minimizing <span class=\"math math-inline\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>h</mi></mrow><annotation encoding=\"application/x-tex\">h</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.6944em;\"></span><span class=\"mord mathnormal\">h</span></span></span></span></span></a></li>\n<li><a href=\"#25-two-examples\">2.5 Two Examples</a></li>\n</ul>\n</li>\n</ul>\n</div>","excerpt":"논문 : Burges, C. J. C. (1998). A tutorial on support vector machines for pattern recognition. Data mining and knowledge discovery, 2(2), 121-167.   최근 핸즈온 머신러닝 교재에서 SVM(Support Vector Machine)에 대해 공부하면서 논문을 읽어보고 싶었다. Survey 논문으로 시작하는 것이 좋을 것 같아 논문을 서칭해 ‘패턴 인식을 위한 서포트 벡터 머신 튜토리얼’이라는 주제의 논문을 선택했다. 논문을 읽었을 때 해당 기술에 대한 배경과 의도를 알 수 있어서 좋다. 그 배경을 알면 그 활용법을 조금 더 이해하지 않을까 기대를 한다. 바로 레츠고오.   Abstract 이 논문은 키워드를 ’서포트 벡터 머신’, ’통계적 학습 이론’, ’VC 차원’, ’패턴 인식‘로 선택했다. 이 중에 VC 차원에 대해 먼저 알고 가는 것이 좋을 것 같다.   VC 차원(…","frontmatter":{"date":"March 16, 2025","title":"[논문 리뷰] A Tutorial on Support Vector Machines for Pattern Recognition (1)","categories":"Paper","author":"변우중","emoji":"✍🏻"},"fields":{"slug":"/25-03-15_1/"}},"next":{"id":"afd5a24d-7f38-5ab5-a413-5f8ff667a157","html":"<p>참고 : Hands-On Machine Learning with Scikit-Learn, Keras &#x26; TensorFlow 2판, 오렐리앙 제롱, 한빛미디어.</p>\n<p>소스코드 참고 : <a href=\"https://github.com/codingalzi/handson-ml2\">https://github.com/codingalzi/handson-ml2</a></p>\n<p> </p>\n<p>빅데이터 관련 곧 박사 졸업하는 지인께서 기본부터 잘 쌓아야 이 분야에서 오래 살아남을 수 있다는 이야기로,\nHands-On Machine Learning with Scikit-Learn, Keras &#x26; TensorFlow (앞으로 핸즈온이라고 부를 것임) 이라는 교재를 정독하게 되었다.</p>\n<p>교재를 보고 공부를 시작한지는 3달이 넘어가는데, 깃허브 블로그에 대해 잘 알지 못해서 노션에 정리만 해두고 그동안 묵혀 두었다.(본 교재는 현재 5장 읽는 중이다..) 최근 자격증 시험(ADsP, SQLD), 알고리즘 공부, ML 인터넷 강의 수강 등으로 정리 속도가 느려졌는데, 더 속도를 내어 완독하자아아앗!!</p>\n<p> </p>\n<blockquote>\n<p>참고로, 노션에 정리한 모든 내용은 모두 올리지 못한다. 킹작권 이슈로…</p>\n<p>모르는 내용 있으면 끝까지 파고드는 습관이 있어서 본 교재 내용뿐만 아니라, 새롭게 찾아본 내용들도 노션에 함께 정리해두었는데, 올릴 수가 없다…ㅎㅎ</p>\n<p>그래서 <strong>짧게 회고(Reflection)만 올리기로 결정</strong>했다.</p>\n</blockquote>\n<p>고럼 레츠기릿.</p>\n<p> </p>\n<hr>\n<p>목차는 아래와 같이 분류했다.</p>\n<ul>\n<li>머신러닝이란</li>\n<li>왜 머신러닝을 사용하는가</li>\n<li>애플리케이션</li>\n<li>머신러닝 시스템 종류\n<ul>\n<li>지도, 비지도, 준지도, 강화학습</li>\n<li>배치 학습, 온라인 학습</li>\n<li>사례기반 학습과 모델기반 학습</li>\n</ul>\n</li>\n<li>머신러닝 프로젝트 형태</li>\n<li>머신러닝 주요 과제</li>\n<li>테스트와 검증</li>\n<li>공짜 점심 없음 (No Free Lunch, NFL) 이론</li>\n</ul>\n<p>목차만 봐도 어느 알고리즘에 대한 깊은 내용은 없을 것 같다. 그렇다. 머신러닝에 대한 깊이 있는 내용보다는 머신러닝이 무엇인지, 어디에 사용되는지와 여러 학습 방식에 대해 간단한 설명이 써져 있다. 처음 머신러닝을 접하는 사람에게 전체적으로 학습의 틀을 잡기에 좋았다.</p>\n<p>참고로, <strong>몇 가지 목차에 대해서만 회고를 남길 것</strong>이다!</p>\n<p> </p>\n<h3 id=\"머신러닝이란\" style=\"position:relative;\"><a href=\"#%EB%A8%B8%EC%8B%A0%EB%9F%AC%EB%8B%9D%EC%9D%B4%EB%9E%80\" aria-label=\"머신러닝이란 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>머신러닝이란</h3>\n<hr>\n<p>머신러닝은 [아서 새뮤얼(Arthur Samuel)]보다는 <strong>[톰 미첼(Tom Mitchell)]의 머신러닝 정의</strong>가 통용된다고 한다.\n“어떤 작업 T에 대한 컴퓨터 프로그램의 성능을 P로 측정했을 때 경험 E로 인해 성능이 향상됐다면, 이 컴퓨터 프로그램은 작업 T와 성능 측정 P에 대해 경험 E로 학습한 것이다.”</p>\n<p>즉, 머신러닝은 이전의 어떤 경험을 통해 학습한 결과를 바탕으로 현재의 일을 더 높은 성능으로 수행하는 것이라 할 수 있다.</p>\n<p>그렇다면, 머신러닝의 과정은 ’<strong>사전 학습</strong>‘과 ’<strong>현재의 일</strong>’, ’<strong>사전 학습을 통한 높아진 성능</strong>’ 3가지 키워드로 정리할 수 있을 것 같다.</p>\n<p> </p>\n<h3 id=\"애플리케이션\" style=\"position:relative;\"><a href=\"#%EC%95%A0%ED%94%8C%EB%A6%AC%EC%BC%80%EC%9D%B4%EC%85%98\" aria-label=\"애플리케이션 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>애플리케이션</h3>\n<hr>\n<p>머신러닝은 반도체 생산 라인에서 이미지를 분석하여 스크래치 등을 자동으로 분류할 때, 이전의 뇌 종양의 모습들과 비교해 종양 진단할 때에 이용되고, 신용 카드의 일반적인 거래와 비교하여 부정 거래도 탐지에도 이용된다. 참고로, 최근 많이 사용하는 Chat-GPT는 머신러닝의 한 종류인 딥러닝, 특히 트랜스포머 모델로 만들어진 것이다. (머신러닝이 딥러닝을 포함한다.)</p>\n<p>최근에 읽었던 <strong>IT 트렌드 2025(김지현)</strong> 책에서 몇 년 전 화두가 되었던 ’<strong>메타버스에서 AI 에이전트 서비스가 구현될 때 모바일이나 웹으로 사용하는 것보다 더 나은 사용자 경험을 제공할 것</strong>‘이라 하였다. 작년 2024년 말에 SK Summit, 삼성 개발자 콘퍼런스, 네이버 Dan24를 영상을 보고, 다녀오면서 올해 2025년 키워드를 <strong>AI 에이전트</strong>로 보는 듯 했다. 기업들에서 관심을 가지고 있는 것들을 보았을 때 AI가 녹여 들어갈 분야는 정말 무궁무진하다고 생각이 든다.\n(참고로 LG 전자에서는 냉장고가 필요 없도록 AI 에이전트가 원하는 음식의 재료를 가져와서 세팅까지 해주는 것을 연구 중이라 했다.)</p>\n<p> </p>\n<h3 id=\"머신러닝-시스템-종류\" style=\"position:relative;\"><a href=\"#%EB%A8%B8%EC%8B%A0%EB%9F%AC%EB%8B%9D-%EC%8B%9C%EC%8A%A4%ED%85%9C-%EC%A2%85%EB%A5%98\" aria-label=\"머신러닝 시스템 종류 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>머신러닝 시스템 종류</h3>\n<hr>\n<p>머신러닝의 시스템 종류는 ‘사람의 감독하에 훈련하는 것인지’, ‘실시간으로 점진적인 학습을 하는지’, ‘단순히 알고 있는 데이터 포인트와 새로운 데이터 포인트를 비교하는 건지, 훈련 데이터셋에서 패턴을 발견하여 예측 모델을 만드는 건지’ 등의 기준으로 나눌 수 있다.</p>\n<p>첫 번째 : <strong>사람의 감독하에 훈련하는 것인지</strong></p>\n<ul>\n<li>\n<p><strong>지도 학습, 비지도 학습, 준지도 학습, 강화 학습</strong>으로 나눌 수 있다.</p>\n</li>\n<li>\n<p>말 그대로, 지도 학습은 사람이 지도하여 기계를 훈련시키는 것이다.\n<strong>그러면 어떻게 지도하는 것인가?</strong></p>\n<ul>\n<li>여기서 중요한 키워드 ’<strong>레이블(label, 라벨, 타깃 데이터)</strong>‘이다.\n어떤 훈련 데이터로서 입력 데이터와 타깃 데이터를 함께 주고, 기계한테 ‘너 입력 데이터의 정답은 타깃 데이터야.’ 라고 직접 훈련시키는 것이다. <strong>정답을 알려주는 것</strong>.</li>\n<li>그러면 비지도 학습은? 레이블이 없다. ‘훈련 데이터 줄테니 너가 알아서 학습해’ 라고 한다.</li>\n</ul>\n</li>\n<li>\n<p><strong>지도 학습</strong>의 유형은 크게 <strong>회귀</strong>(<strong>연속적인 값</strong>을 예측)와 <strong>분류</strong>(<strong>범주형 값</strong>을 예측)으로 나눈다.</p>\n<ul>\n<li>회귀는 선형 회귀, 다항 회귀, 결정트리 회귀, 랜덤 포레스트 회귀, 서포트 벡터 회귀 등등이 있고,\n분류는 로지스틱 회귀 분류, 결정 트리, 랜덤 포레스트, 서포트 벡터 머신 등이 있는데\n다음에 깊이 설명한다!!</li>\n</ul>\n</li>\n<li>\n<p><strong>비지도 학습</strong>의 유형은 <strong>군집</strong> 등이 있는데, 이것도 나중에 깊이 설명 한다!</p>\n</li>\n<li>\n<p><strong>준지도 학습</strong>은 무엇인가? 지도 학습과 비지도 학습을 동시에 이용한 것이다.\n어느 훈련 데이터는 레이블이 함께 있지만, 없는 것도 있다는 것이다. 아예 레이블이 없는 것보다는 훈련의 정확도가 높아지지 않을까?</p>\n</li>\n<li>\n<p><strong>강화 학습</strong>은 무엇인가? (참고로 최근 중국에서 공개한 <strong>딥시크</strong>가 강화 학습으로 만들어졌다고 한다.)</p>\n<ul>\n<li>중등 교사 임용 공부를 하면서 교육학에서 강화 학습에 대해 깊이 배웠다. 사람을 학습시키는 것과 기계를 학습시키는 것은 이론적으로 보았을 때 별반 다를 게 없다.</li>\n<li>강화는 어떤 특정 행동의 빈도 수를 높이는 것 (벌은 어떤 특정 행동의 빈도 수를 낮추는 것)인데,\n<strong>특정 행동(잘한 행동, 못한 행동)의 빈도 수를 높이고 낮추기 위해</strong> <strong>강화물(칭찬)을 주거나 뺏거나, 벌(혼냄)을 주거나 뺏거나</strong> 할 수 있다.</li>\n<li>뭐 어떤 방법으로든 ”<strong><u>잘한 행동의 빈도 수를 높이고, 잘못된 행동의 빈도 수를 높이면 된다.</u></strong>”\n=> <strong>그러면, 내가 만들고자 하는 프로그램에 따라 ‘잘한 행동의 모습을 더 보여야 하는건지’, ‘잘못된 행동의 모습을 덜 보여야 하는 건지’ 적절히 정해서 강화 학습을 진행하면 될 것 같다!!!</strong></li>\n</ul>\n</li>\n</ul>\n<p> </p>\n<p>두 번째 : <strong>실시간으로 점진적인 학습을 하는지</strong></p>\n<ul>\n<li><strong>실시간으로 점진적으로 학습</strong>하면 ’<strong>온라인 학습</strong>’, 그렇지 않으면 ’<strong>배치학습</strong>‘이다.</li>\n<li>참고로 <strong>Chat-GPT</strong>는 <strong>사전 학습(Pre-training)</strong> 과 <strong>후속 미세 조정(Fine-tuning)</strong> 으로 만들어졌다. 실시간으로 훈련시키는 것이 아닌, 따로 모델을 학습시켜서 그 버전을 배포하는 식이다. 그 이후에 미세 조정을 하는 식이다.</li>\n</ul>\n<p> </p>\n<p>세 번째 : <strong>단순히 알고 있는 데이터 포인트와 새로운 데이터 포인트를 비교하는 건지, 훈련 데이터셋에서 패턴을 발견하여 예측 모델을 만드는 건지</strong></p>\n<ul>\n<li>단순히 알고 있는 데이터 포인트와 새로운 데이터 포인트를 비교하는 것은 <strong>사례 기반 학습</strong>이다.\n훈련 샘플들을 기억해 그 사례들과 유사도를 측정하면서 일반화하는 것이다.\n(KNN 알고리즘이 사례 기반 학습의 대표적인 알고리즘이다!! 요거 재밌다..)</li>\n<li>훈련 데이터셋에서 패턴을 발견하여 예측 모델을 만드는 것은 <strong>모델 기반 학습</strong>이다.\n훈련 데이터셋으로 모델을 학습시키고, 그 모델로 다른 데이터에 대해 예측하는 것이다.</li>\n</ul>\n<p> </p>\n<h3 id=\"머신러닝-주요-과제\" style=\"position:relative;\"><a href=\"#%EB%A8%B8%EC%8B%A0%EB%9F%AC%EB%8B%9D-%EC%A3%BC%EC%9A%94-%EA%B3%BC%EC%A0%9C\" aria-label=\"머신러닝 주요 과제 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>머신러닝 주요 과제</h3>\n<hr>\n<p>머신러닝 프로젝트의 전과정에서 주의 깊이 고려할 것을 정리해두고 있다.</p>\n<p><strong>훈련 데이터가 충분한지, 잡음이 있는 훈련 데이터가 없는지, 훈련 데이터가 대표성을 가지고 있는지, 훈련 데이터의 특성 중에 중요하고 중요하지 않은 것을 어떻게 처리할지, 모델이 훈련 데이터에 어느정도로 적합시킬지</strong> 등에 대한 설명이 있다.</p>\n<p>당시 이 챕터를 보면서 <strong>머신러닝 공부의 방향성을 설정하는 데에 가장 유용했다</strong>. 머신러닝을 처음 접해 어떻게 학습을 해야할지 몰랐는데, 계속 어느 포인트에 집중하여 이 과제들을 어떻게 해결할지를 생각하게 해주었다.</p>\n<p> </p>\n<h3 id=\"테스트와-검증\" style=\"position:relative;\"><a href=\"#%ED%85%8C%EC%8A%A4%ED%8A%B8%EC%99%80-%EA%B2%80%EC%A6%9D\" aria-label=\"테스트와 검증 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>테스트와 검증</h3>\n<hr>\n<p>모델을 훈련하는 과정에서 검증(Validation)을 해야 하고, 모델 훈련을 마친 후에도 테스트(Test)를 해야 한다.</p>\n<p>가장 중요한 내용은</p>\n<p>”<strong>테스트(Test)용의 데이터를 따로 떼어 내어 모델을 다 훈련할 때까지 절대 건들지 말자.</strong>”</p>\n<p>”<strong>모델을 훈련하면서 여러 모델을 비교하기 위해 검증(Validation) 과정을 거칠 수 있는데, 이것도 모델을 훈련하는 데이터셋과 검증 세트를 따로 분리해야 한다.</strong>”</p>\n<p>추가로,</p>\n<p>“훈련 데이터에서 훈련 세트와 검증 세트로 분리할 때, 각각 <strong>전체의 훈련 데이터셋의 대표성</strong>을 띄우도록 한다.”</p>\n<p>“검증 과정에서 <strong>홀드아웃 검증</strong>, <strong>교차 검증</strong> 등의 방법을 활용할 수 있다.”</p>\n<p>(자세한 내용은 다음에 할 것이다!!)</p>\n<p>  </p>\n<h3 id=\"공짜-점심-없음-no-free-lunch-nfl-이론\" style=\"position:relative;\"><a href=\"#%EA%B3%B5%EC%A7%9C-%EC%A0%90%EC%8B%AC-%EC%97%86%EC%9D%8C-no-free-lunch-nfl-%EC%9D%B4%EB%A1%A0\" aria-label=\"공짜 점심 없음 no free lunch nfl 이론 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>공짜 점심 없음 (No Free Lunch, NFL) 이론</h3>\n<hr>\n<p>말 그대로 “너 OO하지 않으면 국물도 없어.” 이론이다..\n어떤 데이터에 대해 어떠한 가정도 하지 않으면 그 모델을 다른 모델보다 선호할 근거가 없다는 의미라고 하는데,</p>\n<p>조금 더 자세히 말하면…</p>\n<p>머신러닝 모델이 정말 많다. <strong>이 모델들 중에 어떠한 데이터를 가져오든 항상 좋은 모델은 없다는 의미</strong>이다.\n<strong>데이터에 따라 좋은 성능을 내는 모델이 다르기 때문에 모델의 선택을 달라질 수 있다</strong>는 것이다.</p>\n<p>그러면, 우리는 하나의 데이터셋이 주어지면 여러 모델을 학습시키는 수고로움이 필요하다.\n그러한 수고로움이 있어야 좋은 성능을 내는 모델을 선택해 가질 수 있다.</p>\n<p> </p>\n<p>연습문제는 풀기는 했지만.. 한 가지만 중요하게 보고 가면 될 듯 하다.</p>\n<p>훈련을 진행한 모델이 <strong>훈련 세트에서는 좋은 성능</strong>을 냈는데, <strong>새로운 데이터에서 좋지 못한 성능</strong>을 냈다면?\n<strong>훈련 데이터에 과대 적합</strong>(훈련 데이터에 굉장히 맞춤형으로 제작한 모델이라는 의미)이므로,\n<strong>훈련 데이터를 더 많이 모으거나, 모델 단순화하거나, 훈련 데이터의 잡음을 제거</strong>해야 한다!</p>\n<p> </p>\n<p>끝.\n(나에게 시간만 무한정으로 주어진다면 얼른 다음 장 회고도 올리고 싶다.. 내 하루엔 회고 올리기를 위한 추가시간이 있었다면..)</p>","frontmatter":{"date":"March 14, 2025","title":"Hands-on Machine learning 1장 회고(24년 말 콘퍼런스 이야기를 곁들인)","categories":"Reflections(ML/DL)","author":"변우중","emoji":"✍🏻"},"fields":{"slug":"/25-03-14_1/"}},"prev":{"id":"18dbe677-fcc3-5b08-b72c-e5e49614e26b","html":"<h2 id=\"시작\" style=\"position:relative;\"><a href=\"#%EC%8B%9C%EC%9E%91\" aria-label=\"시작 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>시작</h2>\n<hr>\n<p>25년 3월 19일 수요일 ASAC 빅데이터 분석가 교육 과정이 시작됐다.</p>\n<p>그동안 혼자 파이썬 기본 문법부터 시작해서 SQL, 머신러닝의 전통적 모델들을 하루 9~12시간(?)씩 공부해 왔다.</p>\n<p>’<strong>내 속도에 맞게, 궁금한 것은 깊이 파면서</strong>’ 공부하는 습관대로 공부를 해왔는데 이 방향성이 맞을지에 대한 고민이 많았다.</p>\n<p>(아래는 공부했던 내용 중의 일부다.)</p>\n<span class=\"gatsby-resp-image-wrapper\" style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 720px; \">\n      <span class=\"gatsby-resp-image-background-image\" style=\"padding-bottom: 93.33333333333333%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAATCAYAAACQjC21AAAACXBIWXMAABYlAAAWJQFJUiTwAAABbklEQVQ4y52U666CMBCEeQjAC4LiFVBR0UQSouEn7/9Ce/I1aQOK2sOPzbalHWZ2p3Umk4mMx2Mhl2UpdV3L8/mUx+Mhi8VCoigy338F+5z2ZL1ey+12k/P5rMbb7VaBakDyt2CP87p5Pp8rENZGo5E1uw5DfehwOCiJrut2/qyB9Ziwkrzf76UoCkmSRLIskzRNTbBGZp1xm0hHchsQqcfjUcmezWYmwjA0gQKylWQOT6dTCYLAgLHu+35H9qe6dgAJuot17ve7yciEEaxfD/d2WW+AwW63M5ZZLpey2WxMPfkG+29df2sKh/Dh5XJRwIDhRX6G7F9+7G0KnaYxp9NJsaSeg32ou0jQkMHG1pPr9aokwxCT2165j02hZgDCkJq12Q9+HDRLakgJPl0zK0AYVlWlPNj3bP37tSHjNVh5nqdk67Bh+tZlJMMSP+rHAXMzXq1WVvV02pQxc9M0kue5AgVc35Y4jt/uc1/8AfFu+yiAmXjFAAAAAElFTkSuQmCC'); background-size: cover; display: block;\"></span>\n  <img class=\"gatsby-resp-image-image\" alt=\"img_0\" title=\"img_0\" src=\"/static/1ee53a029a30205b2a25721681ce3730/37523/img_0.png\" srcset=\"/static/1ee53a029a30205b2a25721681ce3730/e9ff0/img_0.png 180w,\n/static/1ee53a029a30205b2a25721681ce3730/f21e7/img_0.png 360w,\n/static/1ee53a029a30205b2a25721681ce3730/37523/img_0.png 720w,\n/static/1ee53a029a30205b2a25721681ce3730/302a4/img_0.png 1080w,\n/static/1ee53a029a30205b2a25721681ce3730/07a9c/img_0.png 1440w,\n/static/1ee53a029a30205b2a25721681ce3730/a83dd/img_0.png 1482w\" sizes=\"(max-width: 720px) 100vw, 720px\" style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\" loading=\"lazy\" decoding=\"async\">\n    </span>\n<p> </p>\n<p>엉덩이 무겁게 공부하는 것에는 자신이 있었지만 조금 더 방향성을 잘 잡고, 효율적으로 공부하기 위해 SK 플래닛에서 진행하는 ASAC 과정에 지원하게 되었다.</p>\n<p> </p>\n<h2 id=\"1주차\" style=\"position:relative;\"><a href=\"#1%EC%A3%BC%EC%B0%A8\" aria-label=\"1주차 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>1주차</h2>\n<hr>\n<p>공부하는 것이 즐겁다. (미친 소리 같겠지만..)</p>\n<p>정확히는 무언가에 대해 공부할 때 깊이 파는 걸 선호한다. aka. 대충하지 않는다.</p>\n<p>간단한 예시를 들면 [Hands-on machine learning] (이하 생략)을 공부할 때 이해한 것을 모두 다 적느라 주석이 좀 많다..</p>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 720px; \"\n    >\n      <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 105.55555555555556%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAVCAYAAABG1c6oAAAACXBIWXMAABYlAAAWJQFJUiTwAAAC3klEQVQ4y3VV7XKrOgzsQ3SaNF982RiMjW0CyWmnM23f/6H2zgroDaf3/lBkjLLWrmTxtNvtkOc57vc73t7exG63G76+vvD9/S2ez0VRSFxVVVBKoSxL7Pd7vL6+/hifn+Rhv4e1HdIwIISAmBKGYRCLMSKlhOv1Kn4cR/R9L6B/g9E/yeJwgDMGf7yHbxu8eYdorYAw8xiDgBGcgHVd4/n5eQP4kyF/DocD8qKEripopVBXlVAryhJZwbWC1rXQvFwysfPlgsuDnc/nfzM8Hg9QpkHXdfDeiYXew7sOxnZo2xYh9HCdhapKaFWJUdcsy0Rbgj4AHtE1NYa+xdBbJE+b11PscA0WwTUS03eNWHQtbKPR1Aqt0SjyfEvZO4fxmuBsgxBq+KDQNAppMAihQUgaja2g6xI+KjS2RK00WmOgtdpmKICdRew7xN7BWgtjDGpjUJSF6JXl2Y/lRT6vs1zo/qJMQNs2sK1B6GcNqZdoWGvRjVYtviwLVOWyXvrzd4bWYEoOt+QW/Vpce4v74GWfevId9aNmrjVw1qBr6/8uCsXlS9oqPI0F8g/PwbWIvpU4rUrUuvofyksF+YdHUGZj9FzJdc3qkvbpfJn7Mct+Z0gK19AJPWY1xk5oMpu1jSgLfeqtJLDpyW3bzIAMJIhQZT8uxoO4P0Ynax5CbSWB6ORw0t/t9g+N3dYSMGdjpYnph+UQFoRyMOa2sFjfEZA12ABao6WqQsm3iK4RP4ZObL5FM+AYrOxRgvX2lMUDZQKyoe9jwpi8+PfbFdMQMQ0BY+rxZxrET8v7MfqliPM1/AUYYpRx1fde5mBK82zk7OO0qeWKaShVwTQNaq03Rcn/vsuPk4OexnG1eu4zjvHrf06nE46n0+yPp23bcMxzmDrnZPTz+fPzE+/v75I5Pw3TNEnGjOEh/Hysg/VnYnOTgAwmIGl9fHzIdCYoJzSHBf26Tyk4gF9eXjaApPwPYcVgbTKfzfcAAAAASUVORK5CYII='); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"img_1\"\n        title=\"img_1\"\n        src=\"/static/d4bd2e2818864753624ec2d7161d095d/37523/img_1.png\"\n        srcset=\"/static/d4bd2e2818864753624ec2d7161d095d/e9ff0/img_1.png 180w,\n/static/d4bd2e2818864753624ec2d7161d095d/f21e7/img_1.png 360w,\n/static/d4bd2e2818864753624ec2d7161d095d/37523/img_1.png 720w,\n/static/d4bd2e2818864753624ec2d7161d095d/302a4/img_1.png 1080w,\n/static/d4bd2e2818864753624ec2d7161d095d/6569d/img_1.png 1328w\"\n        sizes=\"(max-width: 720px) 100vw, 720px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n        decoding=\"async\"\n      />\n    </span></p>\n<p>또 다른 예시를 보여주면…</p>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 720px; \"\n    >\n      <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 141.66666666666666%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAcCAYAAABh2p9gAAAACXBIWXMAABYlAAAWJQFJUiTwAAAFPUlEQVRIx4WV20+TZxzHuSQtjg1sKYdBoEA5lwJyCopy0nnnlUuUyJURNPoHCDNemBi9mP/B4pJdbMvczZbpBTq9UjzNeKKAUKScej69Le37vv0sz1Opkjl9k2+e5/316ef5/g5NcwoLCxkYGOD7a9e4evUqly9f5sqVK1y6dImLFy9y7tw5Jk6f5vz580xNTTE5OcXk1AeanJT67sIFOjs7yTEYDZwePw1JSHqS6CEdouBeXcXpnCMQDBKNxdB0iG/pfOoZGxsjx2g0curUKTRFIxQM4/P7CYcjuJaXJTAejxOJRPF6/WwlkyRTKZLJ9xIxIT2d5tixYxng+MS4vEGJx4knEkSiUdyra/j9ARJbW2zOLxNc86CRRtM0NE3PStU0KfEcP378HXA8A4xGY/h8PjY9HsLhMKmUmonHFDY9AWJKgnQ6jabrO6Xp/wUKJz5/QNoXB1KqKmPCcTyxJaVq7wHvHeo7Hebl5XHy5Ek8Xi/rGxsybZdrWTpc2QgTCEZR1t0klJisk/q5lA0GA2fOnCEUCvHk6VOeP3/B3b/v4fUGSKchmVTRlBTpFKgp/fNAkfLExIQM+P1+3O41nIsLOJdm2fS/JRDysjb/mg2Xk2Bkg5SaykBUNQtT1f9pShrweHy8XHiAy3efN5szrPlcvFl/jMv7EJfnMSktkTkozqeRtRb6KFDX07KOz549R4kkibkVUrEt1KROOBImEo0QCHmIKD42vG+JKuEdgz06OroTKG4ShQ/HFFzz66zPrBBb9RH0+nj84h6vFh6wsPqI+ZWHvHbd5+X8DKueJda8S2z6Vzj67dGdQFkXVUNP6yiROEokRtwTJBIMMbfkZH5llrdrr5hdduL2OFndXMS9sci614XH734PFD898YgZTKUyRVfCCvFoHFVTSSQSLLqWefT8CfOv7vPP3AJzszMowc1sLTM1HM2MzdmzZz/5o0cHbSnEljOKtroFUR0COmlPAmKx7LETJ8bIyc/P58iRI9y9d4/p6Wmmb9/mttCdO3KV79PT3PzpV/68/gt//Pgzt36/kdGN3/jr+g/cunlTnjt06BA5xcXFmEwmSktLsVZVUVNTQ21tLXW2OiorK7FardhsNmz1ddQ11lG4u4Dc3FyMBgMiO0NenlzzjEbJybFYLAhoS0sL+/bto7+/n71798p1ez80NMTQ4KDcDw8P09jUmL1MGKiurqasrExypMOioiJ5oL29nY6ODux2Ow6Hg1a7Xb43NzfL98bGRrmKy5uamuhub6ezo0PGBEeYyzqsq6ujq6uL3t5e+vr6pJuenh6p2poaqqqq5KWiNAUFBYi/DrPZLM2IdZsjHYqAsC1APb298j9GpDkiUh0Y4JvDhxkZGZFxURaRgXBdUVGRBWUdbm/Kvi6j2mqluqKSmuoaaoVEjaqs1FqrpbvyygqZiUi3vr6e8vLyHcCsQxksKaG00IzVsJtSSzFmQz4lufkUG76kapcJi/ErTMZ8dhcUym4KbcM+hGaBolsdjjZabQ20ORw02erpaWmjyWqjwlRMhbmEqqJSLEVFFFks8juifh+mu6PLDQ0NDAwOsn/ggByXru5u9g8OsKe7C7ujlcbmJprsLezZsyfbaVFHyzv4jhoKoJip3p5eDo4cZG9fn4TuF3PZ18eBAwcYHhpif3+/nEPRsMHBQdkkMRniu9tuc7ZvEINZa6vF3mqntc1BW1sbXZ2dOOx22dXtkRKrmE0xEeKM+KykpCTrNEfOkaDvNlOwKx/LFwWU55uyc2Yym+Uq9ybTR/eCsa1/AWyDn0H8XDz+AAAAAElFTkSuQmCC'); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"img_2\"\n        title=\"img_2\"\n        src=\"/static/28bbc5f5ce803ba5829ad1ee01cc7471/37523/img_2.png\"\n        srcset=\"/static/28bbc5f5ce803ba5829ad1ee01cc7471/e9ff0/img_2.png 180w,\n/static/28bbc5f5ce803ba5829ad1ee01cc7471/f21e7/img_2.png 360w,\n/static/28bbc5f5ce803ba5829ad1ee01cc7471/37523/img_2.png 720w,\n/static/28bbc5f5ce803ba5829ad1ee01cc7471/d9199/img_2.png 960w\"\n        sizes=\"(max-width: 720px) 100vw, 720px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n        decoding=\"async\"\n      />\n    </span></p>\n<p>이해가 안 되면, GPT를 괴롭히거나 그림을 직접 다 그려보면서 어떻게든 알고 기록해 놓는다.</p>\n<p> </p>\n<p>작은 한 부분을 놓치지 않으려는 습관 때문에 <strong>학습 시간이 많이 필요하다</strong>.</p>\n<p>그래서 내가 더 많이 공부하고 싶은 마음에 <strong>1주차 첫째 날부터 2주차 동안</strong> 9 to 6가 아닌, <strong>8 to 8</strong> 해왔다. (저녁 8시 30분에서 9시 사이에 퇴근한 적이 많긴 하다..)</p>\n<p>내가 열심히 하려는 모습이 다른 교육생분들께도 잘 와닿았는지 많은 분들이 함께 남아서 공부하고, 파이썬 알고리즘 아이디어를 공유한다.</p>\n<p> </p>\n<p>1주차 첫 날은 토스뱅크 데이터 분석 직무 현직자 특강과 프롬프트 엔지니어 현직자 특강을 했다.</p>\n<p>데이터를 분석한 이후에 하는 직무에 따라 데이터 분석가 직무를 더 세세히 나눌 수 있다는 것을 배웠다. 즉, 해당 회사에서는 데이터 분석을 한 결과를 바탕으로 어떤 프로세스에 의해 의사결정하고 있는지에 대한 것을 배웠다. 내가 Report, Sharing에 관심이 있는지, Action에 관심 있는지, Modeling에 관심 있는지 등을 좀 더 깊이 생각해 봐야겠다. (사실 지금은 Modeling을 너무나 하고 싶다.)</p>\n<p>이외에도 현직자 강사님께서 생각하시는 데이터 분석가가 가져야 할 역량에 대해 깊이 있게 이야기 들었고, 프롬프트 엔지니어가 실제로 하는 일들을 보았다.</p>\n<p>하고 싶은 프로젝트를 고민하고 정리해두고 있는데</p>\n<p>단순히 취업용 프로젝트를 진행하는 것이 아닌, 진심으로 내가 하고 싶고 가치를 만들어 낼 수 있는 프로젝트를 고민해 봐야겠다.</p>\n<p> </p>\n<h2 id=\"2주차\" style=\"position:relative;\"><a href=\"#2%EC%A3%BC%EC%B0%A8\" aria-label=\"2주차 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>2주차</h2>\n<hr>\n<h3 id=\"알고리즘-공부\" style=\"position:relative;\"><a href=\"#%EC%95%8C%EA%B3%A0%EB%A6%AC%EC%A6%98-%EA%B3%B5%EB%B6%80\" aria-label=\"알고리즘 공부 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>알고리즘 공부</h3>\n<p>1주차 금요일(3일차)부터 파이썬 프로그래밍을 2주차까지 이어서 배웠다. 백준, 프로그래머스, 나동빈님 문제를 기반으로 파이썬 알고리즘 공부를 했다.</p>\n<p>구현과 BFS/DFS에 대해 학습했는데, 아직까지 이전에 열심히 공부해왔어서 할 만 했다.</p>\n<p>단, 1문제 빼고.</p>\n<p><a href=\"https://school.programmers.co.kr/learn/courses/30/lessons/92343\">https://school.programmers.co.kr/learn/courses/30/lessons/92343</a></p>\n<p>프로그래머스 Lv.3 문제 [2022 카카오 블라인드 채용 - 양과 늑대]다..</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token comment\"># 프로그래머스 양과 늑대 (매우 어렵다...)</span>\n<span class=\"token comment\"># DFS (이진탐색 가능)</span>\n<span class=\"token comment\"># 방문했던 곳도 다시 방문하면서 모든 경우의 수를 탐색해야 함</span>\n<span class=\"token comment\"># queue.append([node, move_nodes[:i] + move_nodes[i+1:] + node_tree[node], num_sheep, num_wolf + 1]) 이 부분을 기억하자!!</span>\n\n\n<span class=\"token keyword\">from</span> collections <span class=\"token keyword\">import</span> deque\n\n<span class=\"token keyword\">def</span> <span class=\"token function\">dfs</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    nodes<span class=\"token punctuation\">,</span> max_sheep <span class=\"token operator\">=</span> stack<span class=\"token punctuation\">.</span>pop<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n    <span class=\"token keyword\">for</span> node <span class=\"token keyword\">in</span> nodes<span class=\"token punctuation\">:</span>\n        <span class=\"token keyword\">if</span> info<span class=\"token punctuation\">[</span>node<span class=\"token punctuation\">]</span> <span class=\"token operator\">==</span> <span class=\"token number\">0</span><span class=\"token punctuation\">:</span>\n            max_sheep <span class=\"token operator\">+=</span> <span class=\"token number\">1</span>\n    node_max_sheep<span class=\"token punctuation\">[</span>node<span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> max_sheep\n        \n    stack<span class=\"token punctuation\">.</span>append<span class=\"token punctuation\">(</span>stack<span class=\"token punctuation\">)</span>\n    \n    <span class=\"token keyword\">return</span> \n    \n\n<span class=\"token comment\"># info : 각 i번째 노드에 양(0) 또는 늑대(1)가 있음(리스트)</span>\n<span class=\"token comment\"># edges : 각 i번째 노드와 연결된 노드가 있음(리스트이고, 단방향으로 되어 있음, 되돌아오는 것은 고민해보자.)</span>\n<span class=\"token keyword\">def</span> <span class=\"token function\">solution</span><span class=\"token punctuation\">(</span>info<span class=\"token punctuation\">,</span> edges<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    answer <span class=\"token operator\">=</span> <span class=\"token number\">0</span>\n    node_tree <span class=\"token operator\">=</span> <span class=\"token punctuation\">{</span>i<span class=\"token punctuation\">:</span><span class=\"token punctuation\">[</span><span class=\"token punctuation\">]</span> <span class=\"token keyword\">for</span> i <span class=\"token keyword\">in</span> <span class=\"token builtin\">range</span><span class=\"token punctuation\">(</span><span class=\"token builtin\">len</span><span class=\"token punctuation\">(</span>info<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">}</span>\n\n    <span class=\"token comment\"># 트리모양에 대한 딕셔너리 코드화</span>\n    <span class=\"token keyword\">for</span> s<span class=\"token punctuation\">,</span> e <span class=\"token keyword\">in</span> edges<span class=\"token punctuation\">:</span>\n        node_tree<span class=\"token punctuation\">[</span>s<span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span>append<span class=\"token punctuation\">(</span>e<span class=\"token punctuation\">)</span>\n\n    <span class=\"token comment\"># [0번 노드, 연결된 노드들, 양 1마리, 늑대 1마리]를 넣어 초기화</span>\n    queue <span class=\"token operator\">=</span> deque<span class=\"token punctuation\">(</span><span class=\"token punctuation\">[</span><span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">,</span> node_tree<span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> <span class=\"token number\">1</span><span class=\"token punctuation\">,</span> <span class=\"token number\">0</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\n\n    <span class=\"token keyword\">while</span> queue<span class=\"token punctuation\">:</span>\n        new_node<span class=\"token punctuation\">,</span> move_nodes<span class=\"token punctuation\">,</span> num_sheep<span class=\"token punctuation\">,</span> num_wolf <span class=\"token operator\">=</span> queue<span class=\"token punctuation\">.</span>pop<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span> <span class=\"token comment\"># 스택 형식 -> DFS</span>\n        \n        <span class=\"token comment\"># 기존의 양의수보다 현재 경로의 양의 수가 많으면 갱신</span>\n        <span class=\"token keyword\">if</span> answer <span class=\"token operator\">&lt;</span> num_sheep<span class=\"token punctuation\">:</span>\n            answer <span class=\"token operator\">=</span> num_sheep\n        \n        <span class=\"token comment\"># 현재의 점도 다시 갈 수 있음</span>\n        <span class=\"token keyword\">for</span> i<span class=\"token punctuation\">,</span> node <span class=\"token keyword\">in</span> <span class=\"token builtin\">enumerate</span><span class=\"token punctuation\">(</span>move_nodes<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n            <span class=\"token comment\"># 늑대가 있다면</span>\n            <span class=\"token keyword\">if</span> info<span class=\"token punctuation\">[</span>node<span class=\"token punctuation\">]</span> <span class=\"token operator\">==</span> <span class=\"token number\">1</span><span class=\"token punctuation\">:</span>\n                <span class=\"token comment\"># 현재 모아온 양의 수가 다음 늑대의 수(현재 늑대의 수 + 1)보다 크면</span>\n                <span class=\"token keyword\">if</span> num_sheep <span class=\"token operator\">></span> num_wolf <span class=\"token operator\">+</span> <span class=\"token number\">1</span><span class=\"token punctuation\">:</span>\n                    <span class=\"token comment\"># 늑대 있는 곳으로 일단 가서 (num_wolf + 1)</span>\n                    <span class=\"token comment\"># 지금 늑대 있는 곳으로 가기 전의 노드에서 그 전에 방문했던 노드들과 다른 연결된 노드들, 지금 양 있는 곳에서 연결된 노드들을 모두 같이 넣어줌</span>\n                    queue<span class=\"token punctuation\">.</span>append<span class=\"token punctuation\">(</span><span class=\"token punctuation\">[</span>node<span class=\"token punctuation\">,</span> move_nodes<span class=\"token punctuation\">[</span><span class=\"token punctuation\">:</span>i<span class=\"token punctuation\">]</span> <span class=\"token operator\">+</span> move_nodes<span class=\"token punctuation\">[</span>i<span class=\"token operator\">+</span><span class=\"token number\">1</span><span class=\"token punctuation\">:</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">+</span> node_tree<span class=\"token punctuation\">[</span>node<span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> num_sheep<span class=\"token punctuation\">,</span> num_wolf <span class=\"token operator\">+</span> <span class=\"token number\">1</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\n            \n            <span class=\"token comment\"># 양이 있다면 </span>\n            <span class=\"token keyword\">else</span><span class=\"token punctuation\">:</span>\n                <span class=\"token comment\"># 양 있는 곳으로 일단 가서 (num_sheep + 1)</span>\n                <span class=\"token comment\"># 지금 양 있는 곳으로 가기 전의 노드에서 그 전에 방문했던 노드들과 다른 연결된 노드들, 지금 양 있는 곳에서 연결된 노드들을 모두 같이 넣어줌</span>\n                queue<span class=\"token punctuation\">.</span>append<span class=\"token punctuation\">(</span><span class=\"token punctuation\">[</span>node<span class=\"token punctuation\">,</span> move_nodes<span class=\"token punctuation\">[</span><span class=\"token punctuation\">:</span>i<span class=\"token punctuation\">]</span> <span class=\"token operator\">+</span> move_nodes<span class=\"token punctuation\">[</span>i<span class=\"token operator\">+</span><span class=\"token number\">1</span><span class=\"token punctuation\">:</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">+</span> node_tree<span class=\"token punctuation\">[</span>node<span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> num_sheep <span class=\"token operator\">+</span> <span class=\"token number\">1</span><span class=\"token punctuation\">,</span> num_wolf<span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\n    \n    <span class=\"token keyword\">return</span> answer</code></pre></div>\n<p>위 소스코드에서</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\">queue<span class=\"token punctuation\">.</span>append<span class=\"token punctuation\">(</span><span class=\"token punctuation\">[</span>node<span class=\"token punctuation\">,</span> move_nodes<span class=\"token punctuation\">[</span><span class=\"token punctuation\">:</span>i<span class=\"token punctuation\">]</span> <span class=\"token operator\">+</span> move_nodes<span class=\"token punctuation\">[</span>i<span class=\"token operator\">+</span><span class=\"token number\">1</span><span class=\"token punctuation\">:</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">+</span> node_tree<span class=\"token punctuation\">[</span>node<span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> num_sheep<span class=\"token punctuation\">,</span> num_wolf <span class=\"token operator\">+</span> <span class=\"token number\">1</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span></code></pre></div>\n<p>이 부분을 생각해보지 못했었다.</p>\n<p>이진트리 모양으로 각 노드에 양 또는 늑대가 있는데, 해당 노드에 방문 시 각 동물(양 또는 늑대)을 끌고 다녀야 한다. 그런데 노드 방문할 때 모은 양의 수와 모은 늑대의 수가 같아지거나 늑대의 수가 더 많아지면 양이 모두 잡아먹혀 그 전에 루트 노드로 돌아와야 한다. 최대한 많은 양의 수를 확보한다고 했을 때 양의 수는 몇 마리인지 출력하는 문제이다.</p>\n<p>여기서 단순히 내가 얼마만큼 깊은 곳까지 양을 데려올 수 있는지에 대한 문제가 아니다. <strong>방문했던 곳을 다시 방문할 수도 있다</strong>!!</p>\n<p><strong>오른쪽 노드에서 양을 데려와서 왼쪽 노드를 방문하면서 양을 더 데려올 수 있고, 그 상태에서 오른쪽 노드 깊이까지 방문하여 양을 데려올 수 있다</strong>. 이를 코드화 하는 것이 가장 문제였다…🫢</p>\n<p>변수 queue (주의: 여기서 queue 형식이 아니고 <strong>stack 형식</strong>이다. bfs로 풀다가 변수 이름 수정을 못했다..)에는 현재 노드, <strong>앞으로 갈 노드들</strong>(연결된 노드들), 현재까지 모은 양의 수, 현재까지 모은 늑대의 수를 저장했다.</p>\n<blockquote>\n<p>“내가 이번에 이동해서 양 또는 늑대를 데리고, 이전에 방문했던 곳들을 어떻게 방문할 수 있을까…?”</p>\n<p>-> <strong>이를 코드화하기 위해서는 더어어어어 구체화해야 한다!!!</strong></p>\n</blockquote>\n<p>나는 <strong>이번에 이동한 노드</strong>에서 <strong>양 또는 늑대의 수를 추가한 후에</strong>, <strong>이동하기 이전의 노드에서 연결된 노드들 중에 이미 방문했던 노드들(move_nodes[:i])과 아직 방문하지 않은 노드들(move_nodes[i+1:])을 방문하고 싶고</strong>, <strong>이번에 이동한 노드에서 연결된 노드들(node_tree[node])도 방문하고 싶다</strong>는 것이다.</p>\n<p>이렇게 구체화하면서 문제를 풀 수 있었다..</p>\n<p><strong>추상적으로 표현한 말</strong>을 더욱 <strong>구체화</strong>하여 <strong>코드화</strong>해야 한다. (2주차에서 인상 깊었던 나만의 결론…)</p>\n<p> </p>\n<h3 id=\"스터디\" style=\"position:relative;\"><a href=\"#%EC%8A%A4%ED%84%B0%EB%94%94\" aria-label=\"스터디 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>스터디</h3>\n<p>적극적으로 알고리즘 코딩 테스트 스터디를 구했다. 꾸준함을 보여주는 것이 알고리즘 공부라 생각한다. 꾸준히 하지 않으면 금방 까먹는 것들이기에 일찌감치 스터디원들을 구했다.</p>\n<span class=\"gatsby-resp-image-wrapper\" style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 718px; \">\n      <span class=\"gatsby-resp-image-background-image\" style=\"padding-bottom: 96.66666666666666%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAATCAYAAACQjC21AAAACXBIWXMAABYlAAAWJQFJUiTwAAAD00lEQVQ4y42T3U9bZRjA35XAtigtm7Q9bYHSIIXFcIdeDEWyv8MLbryAmKgRBCWbMRlkI3rnhTczjqjERXCbH1M+x1j4EEot5xRaoKX0EyoKbHyNQn+mnEIh7sI3+eV5n5z3/M5znvd9hclkwmSSMBpNFBVJNL+j42aLluvNukNutOj47FqaTzK0X9VyoyVDKm95V4dICc1mCb3exKUyI7NDOYT+yCI0kcXswyxWp7PgHw3E0kQ1ENFAXAPrGljTqM83zxBzZqeFpoxw9H4Wo/cEI3fPMNwtGLwjmPxV4HggGP9J4BkSuHoEcZeAkCAREOwtisOPOXvOnhaW240ogzpCk3ksjOThH8vDO3zhMM49ziMylQfLOpWojmREB5E8DkK5sKJBGcg5EprQGyzYS3JZ8g2gjgOeNw4OTpBMHq7a352BlfPI/dknhWbsL18kIL8Nic9JblyHzTaVrbbMfPskrbDTDk/eg7XskxVK6A0mykolZgcFgRFBaEyNgVGB3CfwPRbEHALvQ8HCI4HSK1D6VBaGU73NxtlzPrPL+XoTr1wyIvefw/soB/fAWVx92fgHzrE2+QI7fsH2nGDTK3jqUTmcp/NnPsHMoFCFR+fQWiTRUKej7SMtV9/X8mmjlh9uvcaDzjf45fvL9N+9Qm93Db3db9L3Yw0D967Q113Dz52X6et+nS/aK1WhJKnSVNTqzORqzbyolbhwsYgZT5idPVjfAIfTx/zCCvO+OLOeKFPOBWbnYjx5Ctu7MDauZCo8klosEgUFqTYYsVoLCQX96f3dZ96jEImFicXCLAUXcc8oRIPB4xMgTztPCyVJQq1YwmAwYi204PYGWFqOE1ycYnkrwf7GOrvPEiR2djnY2sT/t5/5qa/wb0UZm5g8EmZIySwWCyZLAXbzS3x5e5Br3VN8+91t3upaI/R1B56eOyx1deDqvEXj7x8z2VHGzaEPaP6m679Cg8FARUUFlZWvUmgx41ZmcUS3cTj9TAT22F5aJO5xse6ZZjMawRGfIRC8z8yKm6HxiedXaLVasdlsFBQUEAwuqQ1K7kNyj/30HdpPk0oSCXXJtOvP08KTPdTr9RQXFyPLMj6fH1lWmF/wocgyXq+XSDjMvNdLfGWZZFK9poqiZIQpyZHQaDSSn59PYWEhbrebUChENBolHA4TCAQIR6L8FQ2xI//GbsBBMr3LTqcTkXrZaDQcV5nK7XY7JSUllJeXs7q6yv8Zba2t1NbWIoqsNmy2klO/W1paekxdXR1NTU00NDSoNDbSmKah8UOampqpr6+nurqaqqoq/gWA9ctM+GcpAwAAAABJRU5ErkJggg=='); background-size: cover; display: block;\"></span>\n  <img class=\"gatsby-resp-image-image\" alt=\"img_3\" title=\"img_3\" src=\"/static/3df6b8fb4ee5d7af6cbb9d25373d7c9b/57dc1/img_3.png\" srcset=\"/static/3df6b8fb4ee5d7af6cbb9d25373d7c9b/e9ff0/img_3.png 180w,\n/static/3df6b8fb4ee5d7af6cbb9d25373d7c9b/f21e7/img_3.png 360w,\n/static/3df6b8fb4ee5d7af6cbb9d25373d7c9b/57dc1/img_3.png 718w\" sizes=\"(max-width: 718px) 100vw, 718px\" style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\" loading=\"lazy\" decoding=\"async\">\n    </span>\n<p> </p>\n<p>스터디 운영 경력(임용 고시 준비로 인해..)은 3년 이상이기에 스터디 방식을 짜고 의견 조율하는 것은 전혀 어렵지 않았다.</p>\n<p>스터디원들의 수준을 고려해 난이도별로 문제를 먼저 선정하여 자신이 생각하는 수준의 문제를 선택해 풀고, 스터디 시간에 자신이 고민한 흔적들, 좋은 코드와 라이브러리 등을 공유하기로 했다.</p>\n<p>나는 <strong>공유의 힘</strong>을 믿는다. 통신이 발달한 이래로 급격히 산업이 이렇게 발전한 것은 각자 알고 있는 지식을 공유하기 수월해졌기 때문이 아닌가. 또, 현재 다양한 오픈 소스들도 AI 발전을 위한 것이라 알고 있다. (TMI. 심지어 고등학교 교사 근무할 때 모둠학습을 많이 진행했다..)</p>\n<span class=\"gatsby-resp-image-wrapper\" style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 662px; \">\n      <span class=\"gatsby-resp-image-background-image\" style=\"padding-bottom: 90.55555555555556%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAASCAYAAABb0P4QAAAACXBIWXMAABYlAAAWJQFJUiTwAAACVElEQVQ4y42US08iQRDH53sQTZiZfjA8ZgAZ5DW8RECyKLCuZpPdw34tznwqI0E9mIjsleN/U9Ug62YFD7+p6u7penRXlyWEQLvdRhRF6HQ6KJVKaDabCMMQjuOA1qWUb/IQlm3b6Pf7mEwm6Ha76PV6GI1GPDcYDJDP59nwZ4yxQfLseR4ymQySyeQ7nSSN6Uel1EHYoOu6HEWlUoHv+yiXy9BaIxaL4ejoiDk+Pv4U8Xgc1nA4xMPDAx4fH7FYLPD09MTy/v4e8/mc5SHu7u7w/PyM6XQKazwe42W5xOvrK5bLJUP6avUbq9XqU9Ce9XqN2WwGi9KjlImTfB6FkxPkcjlkg2BH9m89+yHpdNqcYaPRRFRvsDzrnCMsFmE77g7bhu04BtI/gKrBksKFF4RQ0TV0ZQhdG8GrXUFHE+jqFXR1CF0e8JrKliGl2H/L27JJZXx4qQyE0hAqAakTkCSVhtSe0bnA3b1FbtGn2Wqh0+1zymyMNyvDxhAbZkce62zYJRzDxhGnrP0Qsn4DVRtDRROo6CtU9Qqq/g2qcQtVvzY0bqHbP6BKF5CJFKSXhkz6kF4GMpHcpEyvoHTBRvTZTyja0LiBan2HPv8FVR1BVS6h6AxrE6NXL42kAGoj8094BrFNWZW/mAW6FIqQ9M2Y0xQuJJ+beEttx/uxJYR8OwvHjhsc0qkMTClQafHcP93nf5fDEW6bgh8E/J6JIAgQBFnWqUmYccDv/KNb3kQouMJTqRSKxSIKhQL3QuqLp8Tp6bs5ck4R721fW7Zp7eNQw/0Da8d0Zcxxs5IAAAAASUVORK5CYII='); background-size: cover; display: block;\"></span>\n  <img class=\"gatsby-resp-image-image\" alt=\"img_4\" title=\"img_4\" src=\"/static/2dea1610b236fbc3a0393486aeca3e7e/be86f/img_4.png\" srcset=\"/static/2dea1610b236fbc3a0393486aeca3e7e/e9ff0/img_4.png 180w,\n/static/2dea1610b236fbc3a0393486aeca3e7e/f21e7/img_4.png 360w,\n/static/2dea1610b236fbc3a0393486aeca3e7e/be86f/img_4.png 662w\" sizes=\"(max-width: 662px) 100vw, 662px\" style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\" loading=\"lazy\" decoding=\"async\">\n    </span>\n<p> </p>\n<span class=\"gatsby-resp-image-wrapper\" style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 714px; \">\n      <span class=\"gatsby-resp-image-background-image\" style=\"padding-bottom: 98.88888888888889%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAUCAYAAACNiR0NAAAACXBIWXMAABYlAAAWJQFJUiTwAAAEFElEQVQ4y5WT7U9TZxiHj6Nlh8QxQ1tOTxVYkRYJbAokarZk0Q0RJYCLyb7wgYRs2ScT/oiRjGyJ26d9GmY6FXERCCit0tJS+gYCQl8o7+VFZWhSIItGB1zLOR1jqEu2k/xy38/z3Lnye577PoIsy5hMRjJ0Jo4WZxAKmukNVuMOnMYzcIr+gTJ6fFW4g+V4Bz7FEyzH7j3HbMQKDwU2FrVsLGpUbS6mILwKDAffwz1YiTugAD7BFahQpeSegTL8gydxBc7wZEqCxwI8+oeW9rwOfODLxR2swOUrw+apVkFO/1nueM5j6/8Mp7+S7v7zBO9/zGSokOjYEWJjHxAeLeH3ub27gcdLM5gNmxkdr2AoVE5grBrf8CniE1bW5/eRiOtYjetIzOlYmTHydNbAkxlJ1cqMDCtCEijLRgyZMoesmVz8Ws8P32bzfVMWF5uy+OXSUbpaCuhrN+NuO6jK05GHr9OCt9OKt9OCv8uCqz2P1iv5SaDRmIRKksw76UbS0zN5N10iTdxHS0sbD5ef8yC0SDj6iInpp8SmVpibXyO+uE58YZ35xXWm4+uMTq7tONyG7t8vqzpwwITBoMft7uX/fH8B3yydTofdblcLX7x4QTgcxuVy4ff78fn9BINBNSp7U1NTbG5u7gCNRqOq7XwbaLPZVODGxgYNDQ0UHDrE6YozlJ0+Q+XZsxz/8CMsFgtNTU1vdihJklpw7NgxDAbDLuCFCxfIy8ujpLiYkydOUFlZSVV1FdZ8K42Njf8ONJvNFBUVodfr/wZubW2pLmpqaqitraWuro76+nq++OpLqs9V09zcvBv46pUV8PaVE4kES0tLLC8vq2+laG5ujvn5eaKRqBoXFhZYW3utyzIm2YjJlOy0lGmgo6OdWCxKwO9jdHSEQMDPRGyctdUEq6sJVlZ+U6Oi58+f7Z5DxZneIKPTy+gNJtLT9fQ4+tSrrK4+4+VL+GPjP41N0qGiwgKJksMSh9+XKCzI4NqV75iK9TEy1E0s4mBy3EUs4iQacjAecRAN9RANO9SzyJhjB5iZKXMw14jtmkigS8uYQ8vgnVQcrQLedoEhm8C9FgFnq0DvTYH+NgH7VQHPLQHHDYE7lwUCna/8y/kWiWmvhoWBPYSdKYz1vMW4O4Uhm4aoS0M8qCHk0Kg1IaeGgdtaYn0aJjwa1ic08DgFIdlZpatGsrMlfvxmL50/p6lO7ddFnDdFNe++mkZfm7KXRu+vyTPbVZF7N0QcrSLDdpHgbXG7Kclxycraj5CSxec1eqZ9GvrbUwl0pTLYncqwXavmI3eTTzFk0xJ1afF2JPfct5I1wvYw5+TkUFp6BHNuIfW12fS1aWn7KY2uyyK3r4hq7LgkYr8mcvd6cq24V6LiVImO1rf5E0ueylY6/SReAAAAAElFTkSuQmCC'); background-size: cover; display: block;\"></span>\n  <img class=\"gatsby-resp-image-image\" alt=\"img_6\" title=\"img_6\" src=\"/static/ce3b35a4a984a28f246ba6a5c8eea73e/d67ca/img_6.png\" srcset=\"/static/ce3b35a4a984a28f246ba6a5c8eea73e/e9ff0/img_6.png 180w,\n/static/ce3b35a4a984a28f246ba6a5c8eea73e/f21e7/img_6.png 360w,\n/static/ce3b35a4a984a28f246ba6a5c8eea73e/d67ca/img_6.png 714w\" sizes=\"(max-width: 714px) 100vw, 714px\" style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\" loading=\"lazy\" decoding=\"async\">\n    </span>\n<p> </p>\n<span class=\"gatsby-resp-image-wrapper\" style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 712px; \">\n      <span class=\"gatsby-resp-image-background-image\" style=\"padding-bottom: 123.88888888888889%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAZCAYAAAAxFw7TAAAACXBIWXMAABYlAAAWJQFJUiTwAAAE+0lEQVQ4y32VW0yTZxjHPykVO9Sp0DMTlXmAhSxbRkSnWXa1uBuzLNELFy+WHZIt7mIHJhPciBwMzl3ojVviNkgchYmKUFprqQU5lHMQWI2cCyYopeVYSgv8lu8rJ49v8s/zvM/X/vN/v+d7n7+g1Wp5HjQajRTNZjNWq5XCwkKKioqw2+1SNBgMuFwuxNXX18eFCxeoqKhAeBHRUm6z2bh06RKXL1/GbDLR2dlJfX09DocDt9stEQ4PD1NTU0NTU9MKofjnJTIxqlQq1Go19spKSsuM2CurGBx6yNNrfn5+OZ+ZmXm+wtjYWHbt2iXty8uNXPnzd0wlxdw2lhDwTTI/M8mYZxSv18vCwoIEkXhycvJZQlFZfHw8+/fvQ6lS0VB7F+6b8TcUMdd5i2BXNTgtlBjy+cdQuKxQJH2CcPVxxajT6SRy8d3MzwXwTY4zOe6VlM34ppiYmJAIlgjn5uakmvCyhogQO9fd3U1//wAtLS00NTXzn9NJe3u71CCPx0MwGHxaoWaZQK/XoNep0WnVqNXR1NVVEwz4cY8M4/GMMOObZHzMw8SEV4JYm56eENuDz7dIqNGsqNywUYtWH0/stkS0+j1U2BqZnoFHI37cowEeu2dxe4J4xxfw+VnGlA8ej/hXFIZUavnowyi+PK7mi+NaPvtEw0/fvknOz++Snb6PrPR9ZJ/eT/bpUJ6Vnkx2ejKZaaH96ZS9K4RqtZatr2los66lp2YNXdVr6KhYw2CDQLtVYMAhcN8u0GYJRadd4J5FoKNCoMMa+k1frbD6HWrR67XU3IigqVyGozScMaeMYH84vm45/t4QZnpWINZFSHmXnDFnRIhQp9OiVGpJ2KOm6I9IbhsUmK4osBgUWAoU0t5aGMJSTYqLuVi3/aug5K9IBOlT0ahQvKLhyOHNDDTIqLwm5+51ObU35ThK5VRdl9NsDsdaKKflVjjVN8KxFMjptIfTUC6n1SLW5HTeWYug1+tJSNhNtOp1Pj2mZWFQoKc2DFdjGL11YfTXy3jYLKO3TkZXjYxAfxiMhsGjMHAvQswfypgfDEeIiYnhjYR4duzYTXJSLN9/tZFvPt8kIeXrVzmbqiD7RwXZJxXknFRI+9xTCs6lrSP3VAjn0iL4NX0dv3y3PnRkpVKJWq1iS5SaCIWO9Rt0CEIMxz7eQmv1dmxl26gyiYil2hzDHeMOLKW7sRnjsJbt5FbpHsw347Hd0D159cTmxMRo2BarQRGpI+OHjUx536a29RCtHe/jaPsAR9sh2p0HGR/aytjQVimOuuLwDG5n1hW5dFM0T9xf8fpt2KjjyOEt2G7upKw4CZsxGZvpANby97Ab36K5PIpGYzTNJhWNxiiay5Xcuap7dnytVrtps4riYiNdD/ooKryOwVCMoeAqty1V9PZ7GRgc50H3Y1xDE1Jsbet5uQUoldF0dLQzPT1Fztkczv92nry8v3E6O6WRdS73LHv3vkNubo60Dwb9Lx5fIUIljY2N0mi/ePEiJdeKJf8QV15eHmlpaUxNTZGRkUFBQYFUf6GnLHXfUV8fMgxXLbP3TGRmZko+I7pgSkqK9OjEiRMcPXqUM2fOPHtk0ZhEP0lKSiI6OloaqD7fNDkZ6RQXGZidnSUQCOD3+8nPz5fcLysri9TUVA4eOPh8wri4OBITEyWF9YsK+/oHGFm0zdVLHP3iEi1VtIv/AWV0ya2U1/bnAAAAAElFTkSuQmCC'); background-size: cover; display: block;\"></span>\n  <img class=\"gatsby-resp-image-image\" alt=\"img_5\" title=\"img_5\" src=\"/static/4a5ffa912dbfa8a86de19b6a16c1d0d9/3d4b6/img_5.png\" srcset=\"/static/4a5ffa912dbfa8a86de19b6a16c1d0d9/e9ff0/img_5.png 180w,\n/static/4a5ffa912dbfa8a86de19b6a16c1d0d9/f21e7/img_5.png 360w,\n/static/4a5ffa912dbfa8a86de19b6a16c1d0d9/3d4b6/img_5.png 712w\" sizes=\"(max-width: 712px) 100vw, 712px\" style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\" loading=\"lazy\" decoding=\"async\">\n    </span>\n<p> </p>\n<p>열심히 공유 중이다… 다함께 파이팅해서 나중에 하고 싶은 일을 하자고요💪🏻</p>\n<p> </p>\n<h3 id=\"자격증-합격\" style=\"position:relative;\"><a href=\"#%EC%9E%90%EA%B2%A9%EC%A6%9D-%ED%95%A9%EA%B2%A9\" aria-label=\"자격증 합격 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>자격증 합격</h3>\n<p>짧게 얘기하면, 2월, 3월달에 연달아 봤던 ADsP 자격증과 SQLD 자격증 시험에 합격했다!!!!</p>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 720px; \"\n    >\n      <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 18.333333333333336%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAECAYAAACOXx+WAAAACXBIWXMAABYlAAAWJQFJUiTwAAAA00lEQVQY0zWNgW6EIBBE/f8/a679gqZNr3eKAioCwgHKayTpJpudzL7MdIMYWYzB+Z1JKnohsN6zWdf0pBTPfuDixklye/9o+uLvjwe9GLHOI7Xm5/5LJ6TC74HwSkxK8xwEIb6IKTVY6rkF9q144+12Q88LqRz0g0AqTcqleZ9f33SpVI6jIKVCzzPjOLWbcmZeFqx1mG3DOkfOmXU1HMfBeVb+p1Zw3iOVorueIQTWdWXbLKsxGGOad4WEEPF+Zw+BXErjSinUWjnPs+2lr5wYI3/66zDPFtpOvAAAAABJRU5ErkJggg=='); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"img_7\"\n        title=\"img_7\"\n        src=\"/static/278a54a30f47d18e06ffbb6a0a4e3d3b/37523/img_7.png\"\n        srcset=\"/static/278a54a30f47d18e06ffbb6a0a4e3d3b/e9ff0/img_7.png 180w,\n/static/278a54a30f47d18e06ffbb6a0a4e3d3b/f21e7/img_7.png 360w,\n/static/278a54a30f47d18e06ffbb6a0a4e3d3b/37523/img_7.png 720w,\n/static/278a54a30f47d18e06ffbb6a0a4e3d3b/302a4/img_7.png 1080w,\n/static/278a54a30f47d18e06ffbb6a0a4e3d3b/07a9c/img_7.png 1440w,\n/static/278a54a30f47d18e06ffbb6a0a4e3d3b/31d79/img_7.png 1954w\"\n        sizes=\"(max-width: 720px) 100vw, 720px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n        decoding=\"async\"\n      />\n    </span></p>\n<p>열심히 머신러닝 공부했던 것이 ADsP 공부하는 데에 도움이 많이 됐었고, MySQL로 실습하면서 열심히 공부했던 것이 SQLD 시험에 도움이 많이 됐었다.</p>\n<p>자격증만이 중요한 분야는 아니지만, 이정도는 기본으로 있어야지라는 마음으로 공부했다. 이것도 따지 못하면 ML, DL은 어찌 공부하랴 이 마인드로 하다보니, 아침에 공부 시작해서 저녁 늦게까지 한끼도 안 먹고 공부한 적도 있다. (몰입하다보니 시간이 어느새..)</p>\n<p>아무튼 기분이 좋다.. 끝.</p>\n<div class=\"table-of-contents\">\n<ul>\n<li>\n<p><a href=\"#%EC%8B%9C%EC%9E%91\">시작</a></p>\n</li>\n<li>\n<p><a href=\"#1%EC%A3%BC%EC%B0%A8\">1주차</a></p>\n</li>\n<li>\n<p><a href=\"#2%EC%A3%BC%EC%B0%A8\">2주차</a></p>\n<ul>\n<li><a href=\"#%EC%95%8C%EA%B3%A0%EB%A6%AC%EC%A6%98-%EA%B3%B5%EB%B6%80\">알고리즘 공부</a></li>\n<li><a href=\"#%EC%8A%A4%ED%84%B0%EB%94%94\">스터디</a></li>\n<li><a href=\"#%EC%9E%90%EA%B2%A9%EC%A6%9D-%ED%95%A9%EA%B2%A9\">자격증 합격</a></li>\n</ul>\n</li>\n</ul>\n</div>","frontmatter":{"date":"March 29, 2025","title":"[ASAC 회고] 1-2주차: 미러링","categories":"ASAC","author":"변우중","emoji":"🌤️"},"fields":{"slug":"/25-03-29_1/"}},"site":{"siteMetadata":{"siteUrl":"https://www.zoomkoding.com","comments":{"utterances":{"repo":""}}}}},"pageContext":{"slug":"/25-03-15_1/","nextSlug":"/25-03-14_1/","prevSlug":"/25-03-29_1/"}},"staticQueryHashes":["1073350324","1956554647","2938748437"]}