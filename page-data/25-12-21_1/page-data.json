{"componentChunkName":"component---src-templates-blog-template-js","path":"/25-12-21_1/","result":{"data":{"cur":{"id":"905bdc07-3be5-56b6-b025-f3fdad7ea637","html":"<p>참고 : 테디노트의 RAG 비법노트 (<a href=\"https://fastcampus.co.kr/data_online_teddy)\">https://fastcampus.co.kr/data_online_teddy)</a><br>소스코드: <a href=\"https://github.com/teddylee777/langchain-kr\">https://github.com/teddylee777/langchain-kr</a><br>위키독스: <a href=\"https://wikidocs.net/book/14314\">https://wikidocs.net/book/14314</a></p>\n<p> </p>\n<p>오늘은 출력 파서에 대해 알아보고자 합니다.</p>\n<p>며칠 글이 올라오지 않았던 것은<br>streamlit 활용한 UI에서 사용자가 프롬프트 템플릿을 선택하고 업로드한 PDF를 기반해 질문하면, PDF를 파싱해서 RAG를 구현하는 미니 프로젝트를 했었습니다.</p>\n<p>RAG 개발 관련한 게시글은 좀 더 깊이 있게 공부한 후에 올리고자 합니다.</p>\n<p>고럼 레츠고~!</p>\n<p> </p>\n<p> </p>\n<p>LLM은 수렴보다 발산을 더 잘하기 떄문에 응답의 포맷을 정해주는 것이 중요합니다.<br><strong>그래서 LLM의 답변을 원하는 구조대로 강제하기 위해 출력 파서를 이용하는 것이 좋습니다.</strong></p>\n<p>저는 Pydantic 파싱 방법을 많이 이용했던 것 같습니다.</p>\n<p> </p>\n<h2 id=\"pydanticoutputparser-가장-유용한-내맘대로-파서\" style=\"position:relative;\"><a href=\"#pydanticoutputparser-%EA%B0%80%EC%9E%A5-%EC%9C%A0%EC%9A%A9%ED%95%9C-%EB%82%B4%EB%A7%98%EB%8C%80%EB%A1%9C-%ED%8C%8C%EC%84%9C\" aria-label=\"pydanticoutputparser 가장 유용한 내맘대로 파서 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>PydanticOutputParser: 가장 유용한 내맘대로 파서</h2>\n<hr>\n<p>⭐️ OutputParser에서 가장 중요한 메서드 ⭐️</p>\n<ol>\n<li>\n<p><code class=\"language-text\">get_format_instructions()</code>: 출력 정보의 형식을 정의하는 지침 제공</p>\n</li>\n<li>\n<p><code class=\"language-text\">parse()</code>: 모델의 출력을 특정 스키마에 맞는지 검증, 스키마 구조로 변환</p>\n</li>\n</ol>\n<p>이 메서드들은 파서 객체를 생성하고, <code class=\"language-text\">get_format_instructions()</code> 메서드로 어떻게 출력결과를 파싱하는지 출력하여 확인 가능합니다.</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">from</span> pydantic <span class=\"token keyword\">import</span> BaseModel<span class=\"token punctuation\">,</span> Field\n\n<span class=\"token comment\"># BaseModel: pydantic 라이브러리의 BaseModel 모듈을 상속 받음</span>\n<span class=\"token comment\"># description: 필드에 대한 설명(자세히 작성 필요)</span>\n<span class=\"token keyword\">class</span> <span class=\"token class-name\">EmailSummary</span><span class=\"token punctuation\">(</span>BaseModel<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    person<span class=\"token punctuation\">:</span> <span class=\"token builtin\">str</span> <span class=\"token operator\">=</span> Field<span class=\"token punctuation\">(</span>description<span class=\"token operator\">=</span><span class=\"token string\">\"메일을 보낸 사람\"</span><span class=\"token punctuation\">)</span>\n    email<span class=\"token punctuation\">:</span> <span class=\"token builtin\">str</span> <span class=\"token operator\">=</span> Field<span class=\"token punctuation\">(</span>description<span class=\"token operator\">=</span><span class=\"token string\">\"메일을 보낸 사람의 이메일 주소\"</span><span class=\"token punctuation\">)</span>\n    subject<span class=\"token punctuation\">:</span> <span class=\"token builtin\">str</span> <span class=\"token operator\">=</span> Field<span class=\"token punctuation\">(</span>description<span class=\"token operator\">=</span><span class=\"token string\">\"메일 제목\"</span><span class=\"token punctuation\">)</span>\n    summary<span class=\"token punctuation\">:</span> <span class=\"token builtin\">str</span> <span class=\"token operator\">=</span> Field<span class=\"token punctuation\">(</span>description<span class=\"token operator\">=</span><span class=\"token string\">\"메일 본문을 요약한 텍스트\"</span><span class=\"token punctuation\">)</span>\n    date<span class=\"token punctuation\">:</span> <span class=\"token builtin\">str</span> <span class=\"token operator\">=</span> Field<span class=\"token punctuation\">(</span>description<span class=\"token operator\">=</span><span class=\"token string\">\"메일 본문에 언급된 미팅 날짜와 시간\"</span><span class=\"token punctuation\">)</span>\n\n\n<span class=\"token comment\"># PydanticOutputParser 생성</span>\nparser <span class=\"token operator\">=</span> PydanticOutputParser<span class=\"token punctuation\">(</span>pydantic_object<span class=\"token operator\">=</span>EmailSummary<span class=\"token punctuation\">)</span>\n\nparser<span class=\"token punctuation\">.</span>get_format_instructions<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n<span class=\"token triple-quoted-string string\">\"\"\"출력:\nThe output should be formatted as a JSON instance that conforms to the JSON schema below.\n\nAs an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\nthe object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\n\nHere is the output schema:\n```\n{\"properties\": {\"person\": {\"description\": \"메일을 보낸 사람\", \"title\": \"Person\", \"type\": \"string\"}, \"email\": {\"description\": \"메일을 보낸 사람의 이메일 주소\", \"title\": \"Email\", \"type\": \"string\"}, \"subject\": {\"description\": \"메일 제목\", \"title\": \"Subject\", \"type\": \"string\"}, \"summary\": {\"description\": \"메일 본문을 요약한 텍스트\", \"title\": \"Summary\", \"type\": \"string\"}, \"date\": {\"description\": \"메일 본문에 언급된 미팅 날짜와 시간\", \"title\": \"Date\", \"type\": \"string\"}}, \"required\": [\"person\", \"email\", \"subject\", \"summary\", \"date\"]}\n```\n\"\"\"</span></code></pre></div>\n<p>이렇게 설정이 됩니다.</p>\n<p>이후, <strong><code class=\"language-text\">parser.get_format_instructions()</code>를 프롬프트에 출력 포맷으로 함께 주면 됩니다</strong>.</p>\n<p>그리고, LLM 응답(문자열 형식)을 <strong>parser의 <code class=\"language-text\">parse()</code> 메서드를 이용하여 파싱을 하면 앞서 정의했던 클래스대로 파싱을 하게 됩니다</strong>. (여기서는 앞서 정의한 Pydantic 객체 형식이 됨)</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\">parser<span class=\"token punctuation\">.</span>parse<span class=\"token punctuation\">(</span>output<span class=\"token punctuation\">)</span>\n<span class=\"token triple-quoted-string string\">\"\"\"출력:\nEmailSummary(person='김철수', email='chulsoo.kim@bikecorporation.me', subject='\"ZENESIS\" 자전거 유통 협력 및 미팅 일정 제안', summary='바이크코퍼레이션 김철수 상무가 ZENESIS 자전거의 상세 브로슈어(기술 사양, 배터리 성능, 디자인) 요청과 유통 및 마케팅 협력 논의를 위해 미팅을 제안함.', date='1월 15일 화요일 오전 10시')\n\"\"\"</span></code></pre></div>\n<p>(참고로, <code class=\"language-text\">print()</code>로 출력하면 안의 내용만 출력하게 됩니다.)</p>\n<p> </p>\n<p>또한, <strong>chain에서 LLM 뒤에 parser를 연결해주면<br><code class=\"language-text\">invoke()</code> 메서드의 출력 결과를 자동으로 파싱하여 Pydantic 객체의 응답을 받을 수 있습니다.</strong></p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\">chain <span class=\"token operator\">=</span> prompt <span class=\"token operator\">|</span> llm <span class=\"token operator\">|</span> parser\nchain<span class=\"token punctuation\">.</span>invoke<span class=\"token punctuation\">(</span>\n    <span class=\"token punctuation\">{</span>\n        <span class=\"token string\">\"email_conversation\"</span><span class=\"token punctuation\">:</span> email_conversation<span class=\"token punctuation\">,</span>\n        <span class=\"token string\">\"question\"</span><span class=\"token punctuation\">:</span> <span class=\"token string\">\"이메일 내용중 주요 내용을 추출해 주세요.\"</span><span class=\"token punctuation\">,</span>\n    <span class=\"token punctuation\">}</span>\n<span class=\"token punctuation\">)</span>\n<span class=\"token triple-quoted-string string\">\"\"\"출력:\nEmailSummary(person='김철수', email='chulsoo.kim@bikecorporation.me', subject='\"ZENESIS\" 자전거 유통 협력 및 미팅 일정 제안', summary='바이크코퍼레이션 김철수 상무가 ZENESIS 자전거에 대한 상세 브로슈어 요청(기술 사양, 배터리 성능, 디자인)과 유통 및 마케팅 협력 논의를 위해 미팅을 제안함.', date='1월 15일 화요일 오전 10시')\n\"\"\"</span></code></pre></div>\n<p> </p>\n<p>그런데,</p>\n<blockquote>\n<h3 id=\"깨알-tip\" style=\"position:relative;\"><a href=\"#%EA%B9%A8%EC%95%8C-tip\" aria-label=\"깨알 tip permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>💡깨알 Tip</h3>\n<p>제가 경험한 바로는 <strong>LLM이 애초에 응답해주는 결과가 불안정하면 파서가 제대로 작동되지 않는 경우</strong>가 있습니다.</p>\n<p><strong>즉, 프롬프트에 출력 포맷을 정해주었다고 해서 항상 출력 포맷을 맞추어 답변해주지 않는 경우가 있습니다.</strong></p>\n<p>앞의 예시에서 이러한 출력 결과를 받을 때가 있었습니다.</p>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">AIMessage(content='\njson\\n{\\n  \"person\": \"김철수\",\\n  \"email\": \"chulsoo.kim@bikecorporation.me\",\\n  \"subject\": \"\\\\\"ZENESIS\\\\\" 자전거 유통 협력 및 미팅 일정 제안\",\\n  \"summary\": \"바이크코퍼레이션 김철수 상무가 ZENESIS 자전거에 대한 상세 브로슈어(기술 사양, 배터리 성능, 디자인)를 요청하고, 유통 전략과 마케팅 계획 수립을 위해 협력 가능성을 논의하고자 1월 15일 오전 10시에 미팅을 제안함.\",\\n  \"date\": \"1월 15일 오전 10시\"\\n}\\n\n', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 151, 'prompt_tokens': 601, 'total_tokens': 752, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4.1-mini-2025-04-14', 'system_fingerprint': 'fp_376a7ccef1', 'id': 'chatcmpl-CpTzmI5b3Zm40LzHPuNQnkCzOWMqz', 'finish_reason': 'stop', 'logprobs': None}, id='run-3520fb7f-43a8-44ce-8c80-5c30f61d8ea4-0', usage_metadata={'input_tokens': 601, 'output_tokens': 151, 'total_tokens': 752, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})</code></pre></div>\n<p>여기서 <strong>출력 형식이 <code class=\"language-text\">AIMessage</code> 객체라 함은 파서가 실제로 실행되지 않아 LLM 결과 그대로인 상태</strong>인데<br>content 값이 ````json`로 시작한 것으로 볼 때 이 경우는 <strong>LLM이 응답으로 코드 블록을 내준 것</strong>으로 보입니다.</p>\n<p>=> 이렇게 <strong>파싱이 실패하는 경우, 저는 LLM에게 응답받는 것을 재시도하는 로직</strong>을 함께 넣었었습니다.</p>\n</blockquote>\n<p> </p>\n<p><strong>Chain에 parser을 연결하는 것은 LLM의 응답결과를 받은 ‘후처리’ 방식이기 때문에 안정적인 파싱이 불가</strong>할 수 있습니다.</p>\n<p> </p>\n<p>하지만,</p>\n<p><strong>LLM의 <code class=\"language-text\">.with_structured_output()</code> 메서드를 이용하면<br>애초에 LLM에게 구조화된 응답받을 수 있도록 할 수 있습니다.</strong> ⭐️</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\">llm_with_structered <span class=\"token operator\">=</span> ChatOpenAI<span class=\"token punctuation\">(</span>\n    temperature<span class=\"token operator\">=</span><span class=\"token number\">0</span><span class=\"token punctuation\">,</span> model_name<span class=\"token operator\">=</span><span class=\"token string\">\"gpt-4.1-mini\"</span>\n<span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>with_structured_output<span class=\"token punctuation\">(</span>EmailSummary<span class=\"token punctuation\">)</span>\n\nanswer <span class=\"token operator\">=</span> llm_with_structered<span class=\"token punctuation\">.</span>invoke<span class=\"token punctuation\">(</span>email_conversation<span class=\"token punctuation\">)</span>\nanswer\n<span class=\"token triple-quoted-string string\">\"\"\"출력:\nEmailSummary(person='김철수', email='chulsoo.kim@bikecorporation.me', subject='\"ZENESIS\" 자전거 유통 협력 및 미팅 일정 제안', summary='바이크코퍼레이션의 김철수 상무가 이은채 대리에게 ZENESIS 자전거에 대한 상세 브로슈어 요청과 함께, 기술 사양, 배터리 성능, 디자인 정보가 필요하다고 전달했습니다. 또한, 1월 15일 화요일 오전 10시에 미팅을 제안하며 협력 가능성을 논의하고자 합니다.', date='2024-01-08')\n\"\"\"</span></code></pre></div>\n<p>이처럼 LLM을 <code class=\"language-text\">with_structured_output()</code> 메서드를 붙여 생성하고 <code class=\"language-text\">invoke()</code>를 호출하면</p>\n<p><strong>LLM 응답 형식 <code class=\"language-text\">AIMessage</code>가 아닌<br>여기서 Pydantic 객체인 EmailSummary 객체로 응답이 나오는 것을 볼 수 있습니다.</strong></p>\n<p> </p>\n<p>⚠️ <strong>알아두어야 할 점</strong></p>\n<ol>\n<li>LLM마다 <code class=\"language-text\">with_structured_output()</code> 메서드를 지원하지 않을 수 있으니 찾아보고 사용해야 합니다.</li>\n<li>스트리밍 출력은 불가능합니다. <code class=\"language-text\">invoke()</code> 호출만 가능합니다.</li>\n</ol>\n<p> </p>\n<p> </p>\n<p>출력 파서는 Pydantic 파서 외에 다양한 형식의 파서가 존재합니다.</p>\n<p>이번 글에서는 그 중에 가장 유용한 Pydantic 파서만 다뤄보았는데 다른 것들은 필요시 다루고자 합니다.</p>\n<p>이번 글은 여기서 마무리하겠슴다 🫡</p>\n<div class=\"table-of-contents\">\n<ul>\n<li><a href=\"#pydanticoutputparser-%EA%B0%80%EC%9E%A5-%EC%9C%A0%EC%9A%A9%ED%95%9C-%EB%82%B4%EB%A7%98%EB%8C%80%EB%A1%9C-%ED%8C%8C%EC%84%9C\">PydanticOutputParser: 가장 유용한 내맘대로 파서</a></li>\n</ul>\n</div>","excerpt":"참고 : 테디노트의 RAG 비법노트 (https://fastcampus.co.kr/data_online_teddy)소스코드: https://github.com/teddylee777/langchain-kr위키독스: https://wikidocs.net/book/14314   오늘은 출력 파서에 대해 알아보고자 합니다. 며칠 글이 올라오지 않았던 것은streamlit 활용한 UI에서 사용자가 프롬프트 템플릿을 선택하고 업로드한 PDF를 기반해 질문하면, PDF를 파싱해서 RAG를 구현하는 미니 프로젝트를 했었습니다. RAG 개발 관련한 게시글은 좀 더 깊이 있게 공부한 후에 올리고자 합니다. 고럼 레츠고~!     LLM은 수렴보다 발산을 더 잘하기 떄문에 응답의 포맷을 정해주는 것이 중요합니다.그래서 LLM의 답변을 원하는 구조대로 강제하기 위해 출력 파서를 이용하는 것이 좋습니다. 저는 Pydantic 파싱 방법을 많이 이용했던 것 같습니다.   PydanticOutputParse…","frontmatter":{"date":"December 21, 2025","title":"[LLM] 테디노트의 RAG 비법노트 끄적끄적-5","categories":"LLM","author":"변우중","emoji":"☀️"},"fields":{"slug":"/25-12-21_1/"}},"next":{"id":"fe49cd49-a75e-5770-ae92-ec14391a764a","html":"<p>참고 : 테디노트의 RAG 비법노트 (<a href=\"https://fastcampus.co.kr/data_online_teddy)\">https://fastcampus.co.kr/data_online_teddy)</a><br>소스코드: <a href=\"https://github.com/teddylee777/langchain-kr\">https://github.com/teddylee777/langchain-kr</a><br>위키독스: <a href=\"https://wikidocs.net/book/14314\">https://wikidocs.net/book/14314</a></p>\n<p> </p>\n<p>오늘도 갓 테디노트님 끄적 레츠기릿.</p>\n<p> </p>\n<p>그 전에 잠시!!<br>딕셔너리 키워드 인자 전달하는 파이썬 문법 확인하고 가고자 합니다~</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">from</span> langchain_core<span class=\"token punctuation\">.</span>prompts<span class=\"token punctuation\">.</span>few_shot <span class=\"token keyword\">import</span> FewShotPromptTemplate\n<span class=\"token keyword\">from</span> langchain_core<span class=\"token punctuation\">.</span>prompts <span class=\"token keyword\">import</span> PromptTemplate\n\n\nexamples <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span>\n    <span class=\"token punctuation\">{</span>\n        <span class=\"token string\">\"question\"</span><span class=\"token punctuation\">:</span> <span class=\"token string\">\"스티브 잡스와 아인슈타인 중 누가 더 오래 살았나요?\"</span><span class=\"token punctuation\">,</span>\n        <span class=\"token string\">\"answer\"</span><span class=\"token punctuation\">:</span> <span class=\"token triple-quoted-string string\">\"\"\"이 질문에 추가 질문이 필요한가요: 예.\n추가 질문: 스티브 잡스는 몇 살에 사망했나요?\n중간 답변: 스티브 잡스는 56세에 사망했습니다.\n추가 질문: 아인슈타인은 몇 살에 사망했나요?\n중간 답변: 아인슈타인은 76세에 사망했습니다.\n최종 답변은: 아인슈타인\n\"\"\"</span><span class=\"token punctuation\">,</span>\n    <span class=\"token punctuation\">}</span><span class=\"token punctuation\">,</span>\n    <span class=\"token punctuation\">{</span>\n        <span class=\"token string\">\"question\"</span><span class=\"token punctuation\">:</span> <span class=\"token string\">\"네이버의 창립자는 언제 태어났나요?\"</span><span class=\"token punctuation\">,</span>\n        <span class=\"token string\">\"answer\"</span><span class=\"token punctuation\">:</span> <span class=\"token triple-quoted-string string\">\"\"\"이 질문에 추가 질문이 필요한가요: 예.\n추가 질문: 네이버의 창립자는 누구인가요?\n중간 답변: 네이버는 이해진에 의해 창립되었습니다.\n추가 질문: 이해진은 언제 태어났나요?\n중간 답변: 이해진은 1967년 6월 22일에 태어났습니다.\n최종 답변은: 1967년 6월 22일\n\"\"\"</span><span class=\"token punctuation\">,</span>\n    <span class=\"token punctuation\">}</span>\n<span class=\"token punctuation\">]</span>\n\nexample_prompt <span class=\"token operator\">=</span> PromptTemplate<span class=\"token punctuation\">.</span>from_template<span class=\"token punctuation\">(</span>\n    <span class=\"token comment\"># question, answer 키워드 인자 사용</span>\n    <span class=\"token string\">\"Question:\\n{question}\\nAnswer:\\n{answer}\"</span>\n<span class=\"token punctuation\">)</span>\n\n<span class=\"token comment\"># **examples[0]로 키워드 인자 전달</span>\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span>example_prompt<span class=\"token punctuation\">.</span><span class=\"token builtin\">format</span><span class=\"token punctuation\">(</span><span class=\"token operator\">**</span>examples<span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n<span class=\"token triple-quoted-string string\">\"\"\"출력:\nQuestion:\n스티브 잡스와 아인슈타인 중 누가 더 오래 살았나요?\nAnswer:\n이 질문에 추가 질문이 필요한가요: 예.\n추가 질문: 스티브 잡스는 몇 살에 사망했나요?\n중간 답변: 스티브 잡스는 56세에 사망했습니다.\n추가 질문: 아인슈타인은 몇 살에 사망했나요?\n중간 답변: 아인슈타인은 76세에 사망했습니다.\n최종 답변은: 아인슈타인\n\"\"\"</span></code></pre></div>\n<p>example의 첫번째</p>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">{\n    \"question\": \"스티브 잡스와 아인슈타인 중 누가 더 오래 살았나요?\",\n    \"answer\": \"\"\"이 질문에 추가 질문이 필요한가요: 예.\n추가 질문: 스티브 잡스는 몇 살에 사망했나요?\n중간 답변: 스티브 잡스는 56세에 사망했습니다.\n추가 질문: 아인슈타인은 몇 살에 사망했나요?\n중간 답변: 아인슈타인은 76세에 사망했습니다.\n최종 답변은: 아인슈타인\n\"\"\",\n}</code></pre></div>\n<p>에서 언패킹하는 방법으로 PromptTemplate.from_template에 키워드 인자를 전달하고, 그 키워드를 직접 사용해 프롬프트 템플릿을 만들 수 있습니다.</p>\n<p> </p>\n<p>그럼 진짜 레츠기륏!</p>\n<p> </p>\n<h2 id=\"fewshotprompttemplate\" style=\"position:relative;\"><a href=\"#fewshotprompttemplate\" aria-label=\"fewshotprompttemplate permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>FewShotPromptTemplate</h2>\n<hr>\n<p>LLM에게 예시 몇 가지를 <code class=\"language-text\">FewShotPromptTemplate</code>을 활용해 던져주는 방법을 알아봅시다.</p>\n<p>사실, 프롬프트에 예시를 직접 포함해도 되지만 <br>예시를 선택적으로 삽입하는 모듈과 함께 쓰면 좋기에 활용성이 괜찮습니다.</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\">example_prompt <span class=\"token operator\">=</span> PromptTemplate<span class=\"token punctuation\">.</span>from_template<span class=\"token punctuation\">(</span>\n    <span class=\"token comment\"># question, answer 키워드 인자 사용</span>\n    <span class=\"token string\">\"Question:\\n{question}\\nAnswer:\\n{answer}\"</span>\n<span class=\"token punctuation\">)</span>\n\nprompt <span class=\"token operator\">=</span> FewShotPromptTemplate<span class=\"token punctuation\">(</span>\n    <span class=\"token comment\"># 예시</span>\n    examples<span class=\"token operator\">=</span>examples<span class=\"token punctuation\">,</span>\n    <span class=\"token comment\"># 예시 프롬프트 템플릿</span>\n    example_prompt<span class=\"token operator\">=</span>example_prompt<span class=\"token punctuation\">,</span>\n    suffix<span class=\"token operator\">=</span><span class=\"token string\">\"Question:\\n{question}\\nAnswer:\"</span><span class=\"token punctuation\">,</span>\n    input_variables<span class=\"token operator\">=</span><span class=\"token punctuation\">[</span><span class=\"token string\">\"question\"</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span>\n<span class=\"token punctuation\">)</span>\n\nquestion <span class=\"token operator\">=</span> <span class=\"token string\">\"Google이 창립된 연도에 Bill Gates의 나이는 몇 살인가요?\"</span>\nfinal_prompt <span class=\"token operator\">=</span> prompt<span class=\"token punctuation\">.</span><span class=\"token builtin\">format</span><span class=\"token punctuation\">(</span>question<span class=\"token operator\">=</span>question<span class=\"token punctuation\">)</span>\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span>final_prompt<span class=\"token punctuation\">)</span>\n\n<span class=\"token triple-quoted-string string\">\"\"\"출력:\nQuestion:\n스티브 잡스와 아인슈타인 중 누가 더 오래 살았나요?\nAnswer:\n이 질문에 추가 질문이 필요한가요: 예.\n추가 질문: 스티브 잡스는 몇 살에 사망했나요?\n중간 답변: 스티브 잡스는 56세에 사망했습니다.\n추가 질문: 아인슈타인은 몇 살에 사망했나요?\n중간 답변: 아인슈타인은 76세에 사망했습니다.\n최종 답변은: 아인슈타인\n\n\nQuestion:\n네이버의 창립자는 언제 태어났나요?\nAnswer:\n이 질문에 추가 질문이 필요한가요: 예.\n추가 질문: 네이버의 창립자는 누구인가요?\n중간 답변: 네이버는 이해진에 의해 창립되었습니다.\n추가 질문: 이해진은 언제 태어났나요?\n중간 답변: 이해진은 1967년 6월 22일에 태어났습니다.\n최종 답변은: 1967년 6월 22일\n\n\nQuestion:\nGoogle이 창립된 연도에 Bill Gates의 나이는 몇 살인가요?\nAnswer:\n\"\"\"</span></code></pre></div>\n<p><code class=\"language-text\">prompt</code>에는  예시들을 예시 프롬프트 템플릿에 각 채워 나열한 후에 <br>마지막에 <code class=\"language-text\">suffix</code> 내용을 채워 주게 됩니다.</p>\n<p><code class=\"language-text\">suffix</code>에서 <code class=\"language-text\">question</code>은 <code class=\"language-text\">input_variables</code> 내용과 연결이 되는 부분이며,<br>사용자 입력(질문)을 넣는 부분입니다.</p>\n<p>이렇게 몇가지 예시를 주면, LLM 모델이 답변을 생성할 때 해당 예시를 참고하게 됩니다.</p>\n<p>OK.</p>\n<p> </p>\n<blockquote>\n<h3 id=\"깨알-tip\" style=\"position:relative;\"><a href=\"#%EA%B9%A8%EC%95%8C-tip\" aria-label=\"깨알 tip permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>💡깨알 Tip</h3>\n<p>⭐️ <strong>Example Selector을 이용하여 예시 선택하기</strong> ⭐️</p>\n<p>ExampleSelector 중에서 langchain_core.example_selectors의 <strong>MaxMarginalRelevanceExampleSelector</strong>와 <strong>SemanticSimilarityExampleSelector</strong>을 알아봅시다.</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">from</span> langchain_core<span class=\"token punctuation\">.</span>example_selectors <span class=\"token keyword\">import</span> <span class=\"token punctuation\">(</span>\n    MaxMarginalRelevanceExampleSelector<span class=\"token punctuation\">,</span>\n    SemanticSimilarityExampleSelector<span class=\"token punctuation\">,</span>\n<span class=\"token punctuation\">)</span>\n<span class=\"token keyword\">from</span> langchain_openai <span class=\"token keyword\">import</span> OpenAIEmbeddings\n<span class=\"token keyword\">from</span> langchain_chroma <span class=\"token keyword\">import</span> Chroma\n\nexamples <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span>\n    <span class=\"token punctuation\">{</span>\n        <span class=\"token string\">\"question\"</span><span class=\"token punctuation\">:</span> <span class=\"token string\">\"스티브 잡스와 아인슈타인 중 누가 더 오래 살았나요?\"</span><span class=\"token punctuation\">,</span>\n        <span class=\"token string\">\"answer\"</span><span class=\"token punctuation\">:</span> <span class=\"token triple-quoted-string string\">\"\"\"이 질문에 추가 질문이 필요한가요: 예.\n추가 질문: 스티브 잡스는 몇 살에 사망했나요?\n중간 답변: 스티브 잡스는 56세에 사망했습니다.\n추가 질문: 아인슈타인은 몇 살에 사망했나요?\n중간 답변: 아인슈타인은 76세에 사망했습니다.\n최종 답변은: 아인슈타인\n\"\"\"</span><span class=\"token punctuation\">,</span>\n    <span class=\"token punctuation\">}</span><span class=\"token punctuation\">,</span>\n    <span class=\"token punctuation\">{</span>\n        <span class=\"token string\">\"question\"</span><span class=\"token punctuation\">:</span> <span class=\"token string\">\"네이버의 창립자는 언제 태어났나요?\"</span><span class=\"token punctuation\">,</span>\n        <span class=\"token string\">\"answer\"</span><span class=\"token punctuation\">:</span> <span class=\"token triple-quoted-string string\">\"\"\"이 질문에 추가 질문이 필요한가요: 예.\n추가 질문: 네이버의 창립자는 누구인가요?\n중간 답변: 네이버는 이해진에 의해 창립되었습니다.\n추가 질문: 이해진은 언제 태어났나요?\n중간 답변: 이해진은 1967년 6월 22일에 태어났습니다.\n최종 답변은: 1967년 6월 22일\n\"\"\"</span><span class=\"token punctuation\">,</span>\n    <span class=\"token punctuation\">}</span><span class=\"token punctuation\">,</span>\n    <span class=\"token punctuation\">{</span>\n        <span class=\"token string\">\"question\"</span><span class=\"token punctuation\">:</span> <span class=\"token string\">\"율곡 이이의 어머니가 태어난 해의 통치하던 왕은 누구인가요?\"</span><span class=\"token punctuation\">,</span>\n        <span class=\"token string\">\"answer\"</span><span class=\"token punctuation\">:</span> <span class=\"token triple-quoted-string string\">\"\"\"이 질문에 추가 질문이 필요한가요: 예.\n추가 질문: 율곡 이이의 어머니는 누구인가요?\n중간 답변: 율곡 이이의 어머니는 신사임당입니다.\n추가 질문: 신사임당은 언제 태어났나요?\n중간 답변: 신사임당은 1504년에 태어났습니다.\n추가 질문: 1504년에 조선을 통치한 왕은 누구인가요?\n중간 답변: 1504년에 조선을 통치한 왕은 연산군입니다.\n최종 답변은: 연산군\n\"\"\"</span><span class=\"token punctuation\">,</span>\n    <span class=\"token punctuation\">}</span><span class=\"token punctuation\">,</span>\n    <span class=\"token punctuation\">{</span>\n        <span class=\"token string\">\"question\"</span><span class=\"token punctuation\">:</span> <span class=\"token string\">\"올드보이와 기생충의 감독이 같은 나라 출신인가요?\"</span><span class=\"token punctuation\">,</span>\n        <span class=\"token string\">\"answer\"</span><span class=\"token punctuation\">:</span> <span class=\"token triple-quoted-string string\">\"\"\"이 질문에 추가 질문이 필요한가요: 예.\n추가 질문: 올드보이의 감독은 누구인가요?\n중간 답변: 올드보이의 감독은 박찬욱입니다.\n추가 질문: 박찬욱은 어느 나라 출신인가요?\n중간 답변: 박찬욱은 대한민국 출신입니다.\n추가 질문: 기생충의 감독은 누구인가요?\n중간 답변: 기생충의 감독은 봉준호입니다.\n추가 질문: 봉준호는 어느 나라 출신인가요?\n중간 답변: 봉준호는 대한민국 출신입니다.\n최종 답변은: 예\n\"\"\"</span><span class=\"token punctuation\">,</span>\n    <span class=\"token punctuation\">}</span><span class=\"token punctuation\">,</span>\n<span class=\"token punctuation\">]</span>\n\nexample_selector <span class=\"token operator\">=</span> SemanticSimilarityExampleSelector<span class=\"token punctuation\">.</span>from_examples<span class=\"token punctuation\">(</span>\n    <span class=\"token comment\"># 선택 가능한 예시 목록</span>\n    examples<span class=\"token punctuation\">,</span>\n    <span class=\"token comment\"># 의미적 유사성을 측정하는 데 사용되는 임베딩을 생성하는 임베딩 클래스</span>\n    OpenAIEmbeddings<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n    <span class=\"token comment\"># 임베딩을 저장하고 유사성 검색을 수행하는 데 사용되는 VectorStore 클래스</span>\n    Chroma<span class=\"token punctuation\">,</span>\n    <span class=\"token comment\"># 생성할 예시의 수</span>\n    k<span class=\"token operator\">=</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span>\n<span class=\"token punctuation\">)</span>\n\nquestion <span class=\"token operator\">=</span> <span class=\"token string\">\"Google이 창립된 연도에 Bill Gates의 나이는 몇 살인가요?\"</span>\n\n<span class=\"token comment\"># 입력과 가장 유사한 예시를 선택합니다.</span>\nselected_examples <span class=\"token operator\">=</span> example_selector<span class=\"token punctuation\">.</span>select_examples<span class=\"token punctuation\">(</span><span class=\"token punctuation\">{</span><span class=\"token string\">\"question\"</span><span class=\"token punctuation\">:</span> question<span class=\"token punctuation\">}</span><span class=\"token punctuation\">)</span>\n\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string-interpolation\"><span class=\"token string\">f\"입력에 가장 유사한 예시:\\n</span><span class=\"token interpolation\"><span class=\"token punctuation\">{</span>question<span class=\"token punctuation\">}</span></span><span class=\"token string\">\\n\"</span></span><span class=\"token punctuation\">)</span>\n<span class=\"token keyword\">for</span> example <span class=\"token keyword\">in</span> selected_examples<span class=\"token punctuation\">:</span>\n    <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string-interpolation\"><span class=\"token string\">f'question:\\n</span><span class=\"token interpolation\"><span class=\"token punctuation\">{</span>example<span class=\"token punctuation\">[</span><span class=\"token string\">\"question\"</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">}</span></span><span class=\"token string\">'</span></span><span class=\"token punctuation\">)</span>\n    <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string-interpolation\"><span class=\"token string\">f'answer:\\n</span><span class=\"token interpolation\"><span class=\"token punctuation\">{</span>example<span class=\"token punctuation\">[</span><span class=\"token string\">\"answer\"</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">}</span></span><span class=\"token string\">'</span></span><span class=\"token punctuation\">)</span>\n\n<span class=\"token triple-quoted-string string\">\"\"\"출력:\n입력에 가장 유사한 예시:\nGoogle이 창립된 연도에 Bill Gates의 나이는 몇 살인가요?\n\nquestion:\n네이버의 창립자는 언제 태어났나요?\nanswer:\n이 질문에 추가 질문이 필요한가요: 예.\n추가 질문: 네이버의 창립자는 누구인가요?\n중간 답변: 네이버는 이해진에 의해 창립되었습니다.\n추가 질문: 이해진은 언제 태어났나요?\n중간 답변: 이해진은 1967년 6월 22일에 태어났습니다.\n최종 답변은: 1967년 6월 22일\n\"\"\"</span></code></pre></div>\n<p><strong><code class=\"language-text\">SemanticSimilarityExampleSelector</code>의 <code class=\"language-text\">from_examples()</code> 메서드로 Chroma DB에 <code class=\"language-text\">OpenAIEmbeddings()</code> 임베딩 모델로 예시를 선택하는 객체를 생성할 수 있습니다.</strong></p>\n<p>이후에 그 생성한 <strong>객체의 <code class=\"language-text\">select_examples()</code> 메서드에 딕셔너리 형태의 입력을 넣어주면</strong> <br><strong>예시들 중에서 입력과 유사한 예시 k개를 선택해 줍니다.</strong></p>\n<p>여기서는 <strong>나이를 물어보는 예시를 정확하게 선택</strong>해주고 있습니다.</p>\n</blockquote>\n<p> </p>\n<p>그렇다면,</p>\n<p><strong>example_selector을 실전에서 어떻게 사용하냐?</strong></p>\n<ol>\n<li>예시 프롬프트 <code class=\"language-text\">example_prompt</code> 템플릿 생성하기</li>\n<li>임베딩 모델, 벡터 DB 선정해서 <code class=\"language-text\">example_selector</code> 객체 생성하기</li>\n<li><code class=\"language-text\">FewShotPromptTemplate</code>에서 <code class=\"language-text\">example_selector</code>, <code class=\"language-text\">example_prompt</code>, <code class=\"language-text\">suffix</code>로 프롬프트 완성하기</li>\n<li>chain 생성 후 호출</li>\n</ol>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token comment\"># chain에서 사용해보기</span>\n\n<span class=\"token keyword\">from</span> langchain_core<span class=\"token punctuation\">.</span>example_selectors <span class=\"token keyword\">import</span> <span class=\"token punctuation\">(</span>\n    MaxMarginalRelevanceExampleSelector<span class=\"token punctuation\">,</span>\n    SemanticSimilarityExampleSelector<span class=\"token punctuation\">,</span>\n<span class=\"token punctuation\">)</span>\n<span class=\"token keyword\">from</span> langchain_openai <span class=\"token keyword\">import</span> OpenAIEmbeddings\n<span class=\"token keyword\">from</span> langchain_chroma <span class=\"token keyword\">import</span> Chroma\n<span class=\"token keyword\">from</span> langchain_teddynote<span class=\"token punctuation\">.</span>messages <span class=\"token keyword\">import</span> stream_response\n\n<span class=\"token comment\"># llm, examples 설정 필요</span>\n\nexample_prompt <span class=\"token operator\">=</span> PromptTemplate<span class=\"token punctuation\">.</span>from_template<span class=\"token punctuation\">(</span>\n    <span class=\"token string\">\"Question:\\n{question}\\nAnswer:\\n{answer}\"</span>\n<span class=\"token punctuation\">)</span>\n\nexample_selector <span class=\"token operator\">=</span> SemanticSimilarityExampleSelector<span class=\"token punctuation\">.</span>from_examples<span class=\"token punctuation\">(</span>\n    examples<span class=\"token punctuation\">,</span>\n    OpenAIEmbeddings<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n    Chroma<span class=\"token punctuation\">,</span>\n    k<span class=\"token operator\">=</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span>\n<span class=\"token punctuation\">)</span>\n\nprompt <span class=\"token operator\">=</span> FewShotPromptTemplate<span class=\"token punctuation\">(</span>\n    example_selector<span class=\"token operator\">=</span>example_selector<span class=\"token punctuation\">,</span>\n    example_prompt<span class=\"token operator\">=</span>example_prompt<span class=\"token punctuation\">,</span>\n    suffix<span class=\"token operator\">=</span><span class=\"token string\">\"Question:\\n{question}\\nAnswer:\"</span><span class=\"token punctuation\">,</span>\n    input_variables<span class=\"token operator\">=</span><span class=\"token punctuation\">[</span><span class=\"token string\">\"question\"</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span>\n<span class=\"token punctuation\">)</span>\n\n<span class=\"token comment\"># 체인 생성</span>\nchain <span class=\"token operator\">=</span> prompt <span class=\"token operator\">|</span> llm\n\n<span class=\"token comment\"># 결과 출력</span>\nanswer <span class=\"token operator\">=</span> chain<span class=\"token punctuation\">.</span>stream<span class=\"token punctuation\">(</span>\n    <span class=\"token punctuation\">{</span><span class=\"token string\">\"question\"</span><span class=\"token punctuation\">:</span> <span class=\"token string\">\"Google이 창립된 연도에 Bill Gates의 나이는 몇 살인가요?\"</span><span class=\"token punctuation\">}</span>\n<span class=\"token punctuation\">)</span>\nstream_response<span class=\"token punctuation\">(</span>answer<span class=\"token punctuation\">)</span>\n<span class=\"token triple-quoted-string string\">\"\"\"출력:\n이 질문에 추가 질문이 필요한가요: 예.  \n추가 질문: Google이 창립된 연도는 언제인가요?  \n중간 답변: Google은 1998년에 창립되었습니다.  \n추가 질문: Bill Gates는 언제 태어났나요?  \n중간 답변: Bill Gates는 1955년 10월 28일에 태어났습니다.  \n추가 질문: 1998년에 Bill Gates의 나이는 몇 살인가요?  \n중간 답변: 1998년 - 1955년 = 43년. 10월 28일 이전에는 42세, 이후에는 43세입니다.\n\n최종 답변: 1998년에 Bill Gates의 나이는 42세 또는 43세입니다. (생일인 10월 28일 이전에는 42세, 이후에는 43세입니다.)\n\"\"\"</span></code></pre></div>\n<p>굳.</p>\n<p> </p>\n<p>아, 참고로 <code class=\"language-text\">MaxMarginalRelevanceExampleSelector</code> 사용법은 <code class=\"language-text\">SemanticSimilarityExampleSelector</code>를 <code class=\"language-text\">MaxMarginalRelevanceExampleSelector</code>로 바꾸기만 하면 됩니다.</p>\n<p> </p>\n<p>⭐️ <strong>둘의 차이점 비교</strong> ⭐️</p>\n<table>\n<thead>\n<tr>\n<th>구분</th>\n<th>SemanticSimilarityExampleSelector</th>\n<th>MaxMarginalRelevanceExampleSelector (MMR)</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>핵심 목표</td>\n<td>query와<strong>가장 유사한 예시 선택</strong></td>\n<td>query와 유사하면서<strong>예시 간 중복 최소화</strong></td>\n</tr>\n<tr>\n<td>기본 개념</td>\n<td><strong>관련성(relevance)만 고려</strong></td>\n<td><strong>관련성 + 다양성(diversity)</strong></td>\n</tr>\n<tr>\n<td>선택 기준</td>\n<td><code class=\"language-text\">sim(query, example)</code></td>\n<td><code class=\"language-text\">λ·sim(query, example) − (1−λ)·max(sim(example, selected))</code></td>\n</tr>\n<tr>\n<td>예시 간 중복</td>\n<td>높음 (비슷한 예시가 몰릴 수 있음)</td>\n<td>낮음 (서로 다른 케이스 위주)</td>\n</tr>\n<tr>\n<td>다양성 고려</td>\n<td>❌</td>\n<td>✅</td>\n</tr>\n<tr>\n<td>파라미터</td>\n<td><code class=\"language-text\">k</code></td>\n<td><code class=\"language-text\">k</code>, <code class=\"language-text\">lambda_mult (λ)</code></td>\n</tr>\n<tr>\n<td>lambda 영향</td>\n<td>해당 없음</td>\n<td>λ↑ → 유사도 중심 / λ↓ → 다양성 중심</td>\n</tr>\n<tr>\n<td>계산 비용</td>\n<td>낮음</td>\n<td>중간 (반복 선택)</td>\n</tr>\n<tr>\n<td>프롬프트 정보량</td>\n<td>제한적</td>\n<td>풍부 (케이스 커버리지 ↑)</td>\n</tr>\n<tr>\n<td>Few-shot 안정성</td>\n<td>보통</td>\n<td>높음</td>\n</tr>\n<tr>\n<td>RAG 적합성</td>\n<td>△</td>\n<td>✅</td>\n</tr>\n<tr>\n<td>Tool Calling 적합성</td>\n<td>❌</td>\n<td>✅</td>\n</tr>\n<tr>\n<td>Agent / Reasoning</td>\n<td>❌</td>\n<td>✅</td>\n</tr>\n<tr>\n<td>추천 사용 상황</td>\n<td>단순 Q&#x26;A, 포맷 학습</td>\n<td>API 선택, 복합 추론, edge case 포함</td>\n</tr>\n</tbody>\n</table>\n<p>GPT 선생님이 알려주셨습니다.</p>\n<p><code class=\"language-text\">MaxMarginalRelevanceExampleSelector</code>에서 <br><code class=\"language-text\">λ·sim(query, example) − (1−λ)·max(sim(example, selected))</code> 식을 보았을 때,</p>\n<h5 id=\"code-classlanguage-textsimquery-examplecode-code-classlanguage-textmaxsimexample-selectedcode를-이용하고-있고-그들의-계수가-서로-반비례함을-볼-수-있습니다\" style=\"position:relative;\"><a href=\"#code-classlanguage-textsimquery-examplecode-code-classlanguage-textmaxsimexample-selectedcode%EB%A5%BC-%EC%9D%B4%EC%9A%A9%ED%95%98%EA%B3%A0-%EC%9E%88%EA%B3%A0-%EA%B7%B8%EB%93%A4%EC%9D%98-%EA%B3%84%EC%88%98%EA%B0%80-%EC%84%9C%EB%A1%9C-%EB%B0%98%EB%B9%84%EB%A1%80%ED%95%A8%EC%9D%84-%EB%B3%BC-%EC%88%98-%EC%9E%88%EC%8A%B5%EB%8B%88%EB%8B%A4\" aria-label=\"code classlanguage textsimquery examplecode code classlanguage textmaxsimexample selectedcode를 이용하고 있고 그들의 계수가 서로 반비례함을 볼 수 있습니다 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a><code class=\"language-text\">sim(query, example)</code>, <code class=\"language-text\">max(sim(example, selected)</code>를 이용하고 있고, 그들의 계수가 서로 반비례함을 볼 수 있습니다.</h5>\n<p>즉, <strong>query와 유사성과 선택된 예시와의 유사성을 동시에 고려한다</strong>는 것입니다.<br>**“파라미터 λ가 크다” = “질문과 유사한 것들을 고르지만, 반대로 선택되는 것들 사이에는 유사하지 않도록 한다”**라고 할 수 있습니다.</p>\n<p>(‼️ langchain의 MaxMarginalRelevanceExampleSelector는 <code class=\"language-text\">lambda_mult</code> 설정이 되지 않습니다. 직접 커스텀해서 만들어야 한다고 합니다.)</p>\n<p> </p>\n<p> </p>\n<p><strong>하지만, Example Selector 문제점이 있다고 합니다.</strong></p>\n<p>상황 정의부터 합시다.</p>\n<ol>\n<li>예시에 <code class=\"language-text\">instruction</code>, <code class=\"language-text\">input</code>, <code class=\"language-text\">answer</code>와 같이 여러 변수가 있음</li>\n<li>LLM에게 예시처럼 <code class=\"language-text\">instruction</code>, <code class=\"language-text\">input</code>의 값을 던져주고, <code class=\"language-text\">answer</code> 값을 받아와야 하는데</li>\n<li>그러지 않고 <code class=\"language-text\">instruction</code>만 던져주었을 때 올바른 답변을 해주지 못함</li>\n</ol>\n<p><code class=\"language-text\">instruction</code>, <code class=\"language-text\">input</code>을 함께 고려하여 유사도 계산을 해야하는데<br>그러지 못하여 오류가 난다고 합니다.</p>\n<p> </p>\n<p>그런데,</p>\n<p><strong>갓 테디노트님께서 만드신 CustomExampleSelector() 모듈에서 <code class=\"language-text\">search_key</code> 설정을 통해 직접 유사도를 계산하고자 하는 변수를 설정할 수 있도록 해주었습니다.</strong></p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">from</span> langchain_teddynote<span class=\"token punctuation\">.</span>prompts <span class=\"token keyword\">import</span> CustomExampleSelector\n\n<span class=\"token comment\"># 커스텀 예제 선택기 생성</span>\n<span class=\"token comment\"># examples에서 유사도 계산하는 변수를 instruction로 지정</span>\n<span class=\"token comment\"># search_key의 기본 값은 instruction.</span>\ncustom_selector <span class=\"token operator\">=</span> CustomExampleSelector<span class=\"token punctuation\">(</span>examples<span class=\"token operator\">=</span>examples<span class=\"token punctuation\">,</span> embedding_model<span class=\"token operator\">=</span>OpenAIEmbeddings<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> search_key<span class=\"token operator\">=</span><span class=\"token string\">\"instruction\"</span><span class=\"token punctuation\">)</span>\n\n<span class=\"token comment\"># 커스텀 예제 선택기를 사용했을 때 결과</span>\ncustom_selector<span class=\"token punctuation\">.</span>select_examples<span class=\"token punctuation\">(</span><span class=\"token punctuation\">{</span><span class=\"token string\">\"instruction\"</span><span class=\"token punctuation\">:</span> <span class=\"token string\">\"다음 문장을 회의록 작성해 주세요\"</span><span class=\"token punctuation\">}</span><span class=\"token punctuation\">)</span>\n<span class=\"token triple-quoted-string string\">\"\"\"출력:\n[{'instruction': '당신은 회의록 작성 전문가 입니다. 주어진 정보를 바탕으로 회의록을 작성해 주세요',\n  'input': '2023년 12월 25일, XYZ 회사의 마케팅 전략 회의가 오후 3시에 시작되었다. 회의에는 마케팅 팀장인 김수진, 디지털 마케팅 담당자인 박지민, 소셜 미디어 관리자인 이준호가 참석했다. 회의의 주요 목적은 2024년 상반기 마케팅 전략을 수립하고, 새로운 소셜 미디어 캠페인에 대한 아이디어를 논의하는 것이었다. 팀장인 김수진은 최근 시장 동향에 대한 간략한 개요를 제공했으며, 이어서 각 팀원이 자신의 분야에서의 전략적 아이디어를 발표했다.',\n  'answer': '\\n회의록: XYZ 회사 마케팅 전략 회의\\n일시: 2023년 12월 25일\\n장소: XYZ 회사 회의실\\n참석자: 김수진 (마케팅 팀장), 박지민 (디지털 마케팅 담당자), 이준호 (소셜 미디어 관리자)\\n\\n1. 개회\\n   - 회의는 김수진 팀장의 개회사로 시작됨.\\n   - 회의의 목적은 2024년 상반기 마케팅 전략 수립 및 새로운 소셜 미디어 캠페인 아이디어 논의.\\n\\n2. 시장 동향 개요 (김수진)\\n   - 김수진 팀장은 최근 시장 동향에 대한 분석을 제시.\\n   - 소비자 행동 변화와 경쟁사 전략에 대한 통찰 공유.\\n\\n3. 디지털 마케팅 전략 (박지민)\\n   - 박지민은 디지털 마케팅 전략에 대해 발표.\\n   - 온라인 광고와 SEO 최적화 방안에 중점을 둠.\\n\\n4. 소셜 미디어 캠페인 (이준호)\\n   - 이준호는 새로운 소셜 미디어 캠페인에 대한 아이디어를 제안.\\n   - 인플루언서 마케팅과 콘텐츠 전략에 대한 계획을 설명함.\\n\\n5. 종합 논의\\n   - 팀원들 간의 아이디어 공유 및 토론.\\n   - 각 전략에 대한 예산 및 자원 배분에 대해 논의.\\n\\n6. 마무리\\n   - 다음 회의 날짜 및 시간 확정.\\n   - 회의록 정리 및 배포는 박지민 담당.\\n'}]\n\"\"\"</span></code></pre></div>\n<p>원래는 다른 예시(교정 전문가 관련)가 선택됐었는데 <br>지금은 정확하게 선택됨을 알 수 있습니다.</p>\n<p> </p>\n<p> </p>\n<h2 id=\"langchain-hub\" style=\"position:relative;\"><a href=\"#langchain-hub\" aria-label=\"langchain hub permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>LangChain Hub</h2>\n<hr>\n<p>LangChain Hub에서 프롬프트를 당겨올 수도 있습니다.</p>\n<p>예시 프롬프트: <a href=\"https://smith.langchain.com/hub/rlm/rag-prompt\">https://smith.langchain.com/hub/rlm/rag-prompt</a></p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">from</span> langchain <span class=\"token keyword\">import</span> hub\n\n<span class=\"token comment\"># 가장 최신 버전의 프롬프트를 가져옵니다.</span>\nprompt <span class=\"token operator\">=</span> hub<span class=\"token punctuation\">.</span>pull<span class=\"token punctuation\">(</span><span class=\"token string\">\"rlm/rag-prompt\"</span><span class=\"token punctuation\">)</span>\nprompt\n<span class=\"token comment\"># 출력: input_variables=['context', 'question'] input_types={} partial_variables={} metadata={'lc_hub_owner': 'rlm', 'lc_hub_repo': 'rag-prompt', 'lc_hub_commit_hash': '50442af133e61576e74536c6556cefe1fac147cad032f4377b60c436e6cdcb6e'} messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context', 'question'], input_types={}, partial_variables={}, template=\"You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Use three sentences maximum and keep the answer concise.\\nQuestion: {question} \\nContext: {context} \\nAnswer:\"), additional_kwargs={})]</span></code></pre></div>\n<p>이때, 프롬프트는 수정될 수 있으니 프롬프트 버전 해시를 지정해두는 것이 좋습니다.<br>버전 해시는 해당 프롬프트에서 commit 부분 들어가면 나와 있습니다.</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token comment\"># 특정 버전의 프롬프트를 가져오기 위해 버전 해시 지정</span>\nprompt <span class=\"token operator\">=</span> hub<span class=\"token punctuation\">.</span>pull<span class=\"token punctuation\">(</span><span class=\"token string\">\"rlm/rag-prompt:50442af1\"</span><span class=\"token punctuation\">)</span>\nprompt</code></pre></div>\n<p>프롬프트를 허브에 업로드를 할 수도 있습니다.</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">from</span> langchain <span class=\"token keyword\">import</span> hub\n\n<span class=\"token comment\"># 프롬프트를 허브에 업로드합니다.</span>\nhub<span class=\"token punctuation\">.</span>push<span class=\"token punctuation\">(</span><span class=\"token string\">\"teddynote/simple-summary-korean\"</span><span class=\"token punctuation\">,</span> prompt<span class=\"token punctuation\">)</span></code></pre></div>\n<p>자신의 “ID/레포지토리”를 입력하면 됩니다.</p>\n<p> \n </p>\n<p>여기서 끄읕.</p>\n<p> </p>\n<div class=\"table-of-contents\">\n<ul>\n<li>\n<p><a href=\"#fewshotprompttemplate\">FewShotPromptTemplate</a></p>\n<ul>\n<li>\n<ul>\n<li>\n<ul>\n<li><a href=\"#simquery-example-maxsimexample-selected%EB%A5%BC-%EC%9D%B4%EC%9A%A9%ED%95%98%EA%B3%A0-%EC%9E%88%EA%B3%A0-%EA%B7%B8%EB%93%A4%EC%9D%98-%EA%B3%84%EC%88%98%EA%B0%80-%EC%84%9C%EB%A1%9C-%EB%B0%98%EB%B9%84%EB%A1%80%ED%95%A8%EC%9D%84-%EB%B3%BC-%EC%88%98-%EC%9E%88%EC%8A%B5%EB%8B%88%EB%8B%A4\"><code class=\"language-text\">sim(query, example)</code>, <code class=\"language-text\">max(sim(example, selected)</code>를 이용하고 있고, 그들의 계수가 서로 반비례함을 볼 수 있습니다.</a></li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>\n<p><a href=\"#langchain-hub\">LangChain Hub</a></p>\n</li>\n</ul>\n</div>","frontmatter":{"date":"December 14, 2025","title":"[LLM] 테디노트의 RAG 비법노트 끄적끄적-4","categories":"LLM","author":"변우중","emoji":"☀️"},"fields":{"slug":"/25-12-14_1/"}},"prev":{"id":"bdf921ea-25f0-5e43-8d59-d6039447df3e","html":"<p>참고 : 테디노트의 RAG 비법노트 (<a href=\"https://fastcampus.co.kr/data_online_teddy)\">https://fastcampus.co.kr/data_online_teddy)</a><br>소스코드: <a href=\"https://github.com/teddylee777/langchain-kr\">https://github.com/teddylee777/langchain-kr</a><br>위키독스: <a href=\"https://wikidocs.net/book/14314\">https://wikidocs.net/book/14314</a></p>\n<p> </p>\n<p>지난 번에 OutputParser는 필요 시 다루고자 했는데<br>제 성격상 바로 또 남겨놔야해서.. 오늘은 나머지 OutputParser 끄적이고 가겠습니다..</p>\n<p>레츠고오!!</p>\n<p> </p>\n<h2 id=\"이외의-outputparser\" style=\"position:relative;\"><a href=\"#%EC%9D%B4%EC%99%B8%EC%9D%98-outputparser\" aria-label=\"이외의 outputparser permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>이외의 OutputParser</h2>\n<hr>\n<p>요약해서 적어두고자 합니다.</p>\n<ol>\n<li><code class=\"language-text\">CommaSeparatedListOutputParser</code>를 chain에 달아 스트리밍 출력할 때는 각 응답 1개씩을 리스트로 변환하는 경우가 있다. (모든 응답을 묶어서 리스트로 반환하지 않음)</li>\n</ol>\n<p> </p>\n<ol start=\"2\">\n<li><code class=\"language-text\">StructuredOutputParser</code>는 <code class=\"language-text\">ResponseSchema</code> 클래스를 이용해 정의하고 <code class=\"language-text\">from_response_schemas()</code> 메서드를 이용해 파서 초기화를 해준다. 로컬과 덜 강력한 모델에 유용한 파서라고 한다.</li>\n</ol>\n<p> </p>\n<ol start=\"3\">\n<li><code class=\"language-text\">JsonOutputParser</code>는 Pydantic 파서에서 했던 방식과 같이 데이터 구조를 클래스를 이용해 정의해주고 <code class=\"language-text\">pydantic_object</code> 파라미터 값에 해당 클래스명 값을 전달해주어, 파서로 정의하여 사용한다.<br>이때, chain을 구성하여 <code class=\"language-text\">invoke()</code> 메서드를 호출하면 답변을 <strong>딕셔너리 형태로 파싱되어 값을 받을 수 있다.</strong></li>\n</ol>\n<p> </p>\n<ol start=\"4\">\n<li>\n<p><strong><code class=\"language-text\">PandasDataFrameOutputParser</code>는 LLM이 Pandas 데이터프레임에서 질문에 맞는 조회하는 쿼리문(예: <code class=\"language-text\">column:Age</code>, <code class=\"language-text\">mean:Age[0..4]</code>)을 응답으로 내놓은 것을 바탕으로 그 문자열을 파싱하여 실제로 데이터프레임에서 조회하여 딕셔너리 형태로 결과를 출력한다.</strong></p>\n<ul>\n<li>\n<p>즉, <strong><code class=\"language-text\">parser=PandasDataFrameOutputParser(dataframe=df)</code>로 정의했을 때</strong></p>\n</li>\n<li>\n<p><strong><code class=\"language-text\">parser.get_instructions()</code>로 데이터프레임의 컬럼 구조 등 정보를 LLM에게 주고 LLM이 정보를 조회하는 명령 문자열을 답변으로 내놓으면</strong><br>(LLM에게는 실제 데이터가 아닌 컬럼 구조에 대한 정보만 주는 것임)</p>\n</li>\n<li>\n<p><strong>parser가 그 명령 문자열을 파싱하여 dataframe에 전달한 ‘실제 df의 데이터에서 읽고’ 답변을 내놓는다</strong>.</p>\n</li>\n<li>\n<p>⭐️ <strong>장점: 모든 데이터를 LLM에게 전달하지 않고, 데이터 구조를 조회하는 방법만 받아와 파서로 데이터를 조회할 수 있다.</strong> ⭐️</p>\n</li>\n</ul>\n</li>\n</ol>\n<p> </p>\n<ol start=\"5\">\n<li><code class=\"language-text\">DateTimeOutputParser</code>는 <code class=\"language-text\">format()</code> 메서드를 이용해 파싱하고자 하는 datetime 형식을 정해주어 그 형식의 답변을 받는다. 최종 응답을 <code class=\"language-text\">strftime()</code> 메서드를 이용해 datetime 형식을 문자열 형식으로 바꾸어 이용할 수 있다.\n<ul>\n<li><code class=\"language-text\">datetime.datetime(1998, 9, 4, 0, 0)</code> -> <code class=\"language-text\">.strftime(\"%Y-%m-%d\")</code>을 이용해 <code class=\"language-text\">'1998-09-04'</code> 이렇게 바꾸어 활용 가능합니다.</li>\n</ul>\n</li>\n</ol>\n<p> </p>\n<ol start=\"6\">\n<li>\n<p><code class=\"language-text\">EnumOutputParser</code>는 enum 라이브러리의 Enum 모듈을 상속모델로 하여 클래스 정의를 한 후, 해당 파서의 enum 파라미터에 해당 클래스를 전달함으로써 파서 객체를 생성할 수 있다. <strong>chain에서 최종 응답 형식은 Enum 멤버 객체이다.</strong></p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">from</span> enum <span class=\"token keyword\">import</span> Enum\n<span class=\"token keyword\">from</span> langchain_core<span class=\"token punctuation\">.</span>prompts <span class=\"token keyword\">import</span> PromptTemplate\n<span class=\"token keyword\">from</span> langchain_openai <span class=\"token keyword\">import</span> ChatOpenAI\n\n<span class=\"token keyword\">class</span> <span class=\"token class-name\">Colors</span><span class=\"token punctuation\">(</span>Enum<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    RED <span class=\"token operator\">=</span> <span class=\"token string\">\"빨간색\"</span>\n    GREEN <span class=\"token operator\">=</span> <span class=\"token string\">\"초록색\"</span>\n    BLUE <span class=\"token operator\">=</span> <span class=\"token string\">\"파란색\"</span>\n\nparser <span class=\"token operator\">=</span> EnumOutputParser<span class=\"token punctuation\">(</span>enum<span class=\"token operator\">=</span>Colors<span class=\"token punctuation\">)</span>\nparser<span class=\"token punctuation\">.</span>get_format_instructions<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n<span class=\"token triple-quoted-string string\">\"\"\"⭐️ 출력 ⭐️:\n'Select one of the following options: 빨간색, 초록색, 파란색'\n\"\"\"</span></code></pre></div>\n<ul>\n<li><strong><code class=\"language-text\">get_format_instructions()</code> 메서드로 출력해보면 <code class=\"language-text\">Colors</code> 클래스 안에 정의된 값들(<code class=\"language-text\">RED</code>, <code class=\"language-text\">GREEN</code>, <code class=\"language-text\">BLUE</code>)의 Value(<code class=\"language-text\">빨간색</code>, <code class=\"language-text\">초록색</code>, <code class=\"language-text\">파란색</code>)를 읽어온다. (즉, Enum 멤버가 아닌 Enum 값을 가져옴)</strong></li>\n</ul>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\">prompt <span class=\"token operator\">=</span> PromptTemplate<span class=\"token punctuation\">.</span>from_template<span class=\"token punctuation\">(</span>\n    <span class=\"token triple-quoted-string string\">\"\"\"다음의 물체는 어떤 색깔인가요?\n\nObject: {object}\n\nInstructions: {instructions}\"\"\"</span>\n<span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>partial<span class=\"token punctuation\">(</span>instructions<span class=\"token operator\">=</span>parser<span class=\"token punctuation\">.</span>get_format_instructions<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n\nchain <span class=\"token operator\">=</span> prompt <span class=\"token operator\">|</span> ChatOpenAI<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">|</span> parser\nresponse <span class=\"token operator\">=</span> chain<span class=\"token punctuation\">.</span>invoke<span class=\"token punctuation\">(</span><span class=\"token punctuation\">{</span><span class=\"token string\">\"object\"</span><span class=\"token punctuation\">:</span> <span class=\"token string\">\"하늘\"</span><span class=\"token punctuation\">}</span><span class=\"token punctuation\">)</span>\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span>response<span class=\"token punctuation\">)</span>\n<span class=\"token triple-quoted-string string\">\"\"\"⭐️ 출력 ⭐️:\nColors.BLUE\n\"\"\"</span></code></pre></div>\n<ul>\n<li>\n<p>⭐️ 하지만, <strong>chain에서 <code class=\"language-text\">parser</code>를 통해 응답받은 결과는 Enum 멤버 객체이다.</strong><br><strong>즉, LLM의 텍스트 응답을 Python Enum 타입으로 변환해주어 Color.BLUE 멤버 객체로 바꾸어 출력을 해준다.</strong> ⭐️</p>\n</li>\n<li>\n<p>⭐️ <strong>이렇게 멤버 객체로 바꾸어주기 때문에<br><code class=\"language-text\">response.value</code>로 접근해서 우리가 원하는 값으로 매핑하여 볼 수 있습니다.</strong> ⭐️</p>\n</li>\n</ul>\n</li>\n</ol>\n<p> </p>\n<p>추가로,</p>\n<p>이전 글(<a href=\"https://byeonwoojung.github.io/25-12-13_1/)%EC%97%90\">https://byeonwoojung.github.io/25-12-13_1/)에</a> 적었던 내용인데,</p>\n<ul>\n<li>\n<p><strong><code class=\"language-text\">OutputFixingParser</code>를 이용해서 다시 고쳐달라는 요청을 보낼 수 있고, <code class=\"language-text\">RetryOutputParser</code>을 이용해서 처음 보냈던 프롬프트와 잘못된 답변을 모두 함께 주어 재시도를 수행할 수도 있습니다.</strong></p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">from</span> langchain<span class=\"token punctuation\">.</span>output_parsers <span class=\"token keyword\">import</span> OutputFixingParser\n\n<span class=\"token comment\"># 기존 parser를 감싸서 정의</span>\nfixing_parser <span class=\"token operator\">=</span> OutputFixingParser<span class=\"token punctuation\">.</span>from_llm<span class=\"token punctuation\">(</span>parser<span class=\"token operator\">=</span>parser<span class=\"token punctuation\">,</span> llm<span class=\"token operator\">=</span>ChatOpenAI<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n\n<span class=\"token comment\"># 이제 체인에서 에러가 나면 스스로 수정 요청을 보냅니다.</span>\nchain <span class=\"token operator\">=</span> prompt <span class=\"token operator\">|</span> model <span class=\"token operator\">|</span> fixing_parser</code></pre></div>\n</li>\n<li>\n<p><strong>또는, <code class=\"language-text\">with_fallbacks</code>을 이용해서 플랜 B 체인을 준비해둘 수도 있습니다.</strong></p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\">chain <span class=\"token operator\">=</span> <span class=\"token punctuation\">(</span>prompt <span class=\"token operator\">|</span> model <span class=\"token operator\">|</span> parser<span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>with_fallbacks<span class=\"token punctuation\">(</span><span class=\"token punctuation\">[</span>backup_chain<span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span></code></pre></div>\n</li>\n</ul>\n<p>이들을 chain에 함께 두면 좋을 듯 합니다.</p>\n<p> </p>\n<p> </p>\n<p>여기까지 끊고 갑니다~</p>\n<div class=\"table-of-contents\">\n<ul>\n<li><a href=\"#%EC%9D%B4%EC%99%B8%EC%9D%98-outputparser\">이외의 OutputParser</a></li>\n</ul>\n</div>","frontmatter":{"date":"December 22, 2025","title":"[LLM] 테디노트의 RAG 비법노트 끄적끄적-6","categories":"LLM","author":"변우중","emoji":"☀️"},"fields":{"slug":"/25-12-22_1/"}},"site":{"siteMetadata":{"siteUrl":"https://www.zoomkoding.com","comments":{"utterances":{"repo":"https://github.com/byeonwoojung/byeonwoojung.github.io"}}}}},"pageContext":{"slug":"/25-12-21_1/","nextSlug":"/25-12-14_1/","prevSlug":"/25-12-22_1/"}},"staticQueryHashes":["1073350324","1956554647","2938748437"]}