{"componentChunkName":"component---src-templates-category-template-js","path":"/posts/NLP","result":{"pageContext":{"currentCategory":"NLP","categories":["All","NLP","LLM","ASAC","Paper","Reflections(ML/DL)","Algorithm"],"edges":[{"node":{"id":"fe49cd49-a75e-5770-ae92-ec14391a764a","excerpt":"참고 : 테디노트의 RAG 비법노트 소스코드: https://github.com/teddylee777/langchain-kr   오늘도 갓 테디노트님 끄적 레츠기릿.   그 전에 잠시!!딕셔너리 키워드 인자 전달하는 파이썬 문법 확인하고 갑니다~ example의 첫번째 에서 언패킹하는 방법으로 PromptTemplate.from_template에 키워드 인자를 전달하고, 그 키워드를 직접 사용해 프롬프트 템플릿을 만들 수 있습니다.   그럼 진짜 레츠기륏!   FewShotPromptTemplate LLM에게 예시 몇 가지를 을 활용해 던져주는 방법을 알아봅시다. 사실, 프롬프트에 예시를 직접 포함해도 되지만 예시를 선택적으로 삽입하는 모듈과 함께 쓰면 좋기에 활용성이 괜찮습니다. 에는  예시들을 예시 프롬프트 템플릿에 각 채워 나열한 후에 마지막에  내용을 채워 주게 됩니다. 에서 은  내용과 연결이 되는 부분이며,사용자 입력(질문)을 넣는 부분입니다. 이렇게 몇가지 예시를 주면…","fields":{"slug":"/25-12-14_1/"},"frontmatter":{"categories":"NLP LLM","title":"[LLM] 테디노트의 RAG 비법노트 끄적끄적-4","date":"December 14, 2025"}},"next":{"fields":{"slug":"/25-12-13_1/"}},"previous":null},{"node":{"id":"d023c61d-c7ed-5cce-a75f-62754442ed31","excerpt":"참고 : 테디노트의 RAG 비법노트 소스코드: https://github.com/teddylee777/langchain-kr   오늘도 작성하는데 Pydantic 파싱 따로 공부한 것 좀 끄적이고 가겠습니다. 레츠기릿!   PydanticOutputParser BaseModel/Field, partial_variables, 결과 포맷 지시사항, parser 등을 알아야 합니다. 예시로 바로 봅시다. 1)  / 는 무엇인가? : “출력 데이터는 반드시 이 구조여야 한다”를 정의하는 스키마(계약서) 필드 누락, 타입 불일치, 구조 깨진다? → 즉시 에러 발생하도록 합니다. : 각 필드의 의미/제약(설명, 기본값 등)을 붙이는 메타데이터 LLM에게 “이 필드는 이런 의미”라고 알려줘서 출력 품질을 올려줄 수 있습니다. 2) 를 넣으면 항상 형식이 맞나? 아닙니다. 프롬프트에 지침 문자열을 미리 채워 넣어주는 기능이라, LLM이 지침을 따를 확률만 높여줄 뿐입니다. ⭐️ 진짜 강제는 par…","fields":{"slug":"/25-12-13_1/"},"frontmatter":{"categories":"NLP LLM","title":"[LLM] 테디노트의 RAG 비법노트 끄적끄적-3","date":"December 13, 2025"}},"next":{"fields":{"slug":"/25-12-12_1/"}},"previous":{"fields":{"slug":"/25-12-14_1/"}}},{"node":{"id":"16028044-feb8-52fb-8dfc-47bb74183808","excerpt":"참고 : 테디노트의 RAG 비법노트 소스코드: https://github.com/teddylee777/langchain-kr   오늘도 가즈아..!!!!\n새로운 걸 알아가는 건 정말 즐겁다~ 다만 알게된 것을 {정리}하는 것은 별개일 뿐… O—< 거두절미. 레츠고~!   LCEL 인터페이스 지난 글에서는 invoke(), stream() 메서드를 살펴봤는데\n사실 batch() 메서드도 있다. batch(): 배치 처리 리스트에 input_variables의 값들을 갖는 딕셔너리를 모아서 각각 배치로 chain에 던진다.\nmodel을 거치고 파싱을 거치면서 각 배치 결과의 content들을 리스트에 묶어서 저장된다. 참고로 config 딕셔너리에서 max_concurrency 키의 값을 설정하여 동시 처리할 수 있는 최대 작업 수를 정해줄 수 있다. 즉, 한번에 배치를 여러 개 처리를 할 수 있고 결과는 똑같이 모든 배치를 묶어서 정리되어 있다.   비동기 메소드 어떤 작업을 기다리…","fields":{"slug":"/25-12-12_1/"},"frontmatter":{"categories":"NLP LLM","title":"[LLM] 테디노트의 RAG 비법노트 끄적끄적-2","date":"December 12, 2025"}},"next":{"fields":{"slug":"/25-12-11_1/"}},"previous":{"fields":{"slug":"/25-12-13_1/"}}},{"node":{"id":"66d916a8-fe23-5bc2-a843-b9c1486dac94","excerpt":"참고 : 테디노트의 RAG 비법노트 소스코드: https://github.com/teddylee777/langchain-kr   지난 번 토큰화 관련해서 공부하고 블로그도 썼지만, 관련 내용 이해와 내면화 사이의 괴리가 있었다.\n그런데, 갓 테디노트님 강의 들으면서 그 괴리를 좁혀나갈 수 있었던 것 같다^^< 굳👍🏻 (오늘 게시글은 진짜 두서없이 깨알 Tip 넣을 것임다… 너무 뜬금 없어도 이해부탁…)   서브워드 기반 토큰화 왜 하는 것인가? 문자 기반 토큰화(한국어는 자모 단위로 토큰화)는 너무 쪼개니까 편집거리를 이용해 검색어 추천, 오타 교정 정도에 활용할 수 있는데, 텍스트 문장 생성에서는 너무 많이 분절해놓으니 이렇게 쪼갠 것을 모델이 학습하고 또 생성해내기가 어려워진다.(모델이 생성해야하는 묶음이 더 많아짐!!)\n(우리한테 자모음들을 막 뿌려 주고, 텍스트 문장 만들라고 시켜보면 얼마나 힘든가…) 단어 기반 토큰화는 텍스트 문장 생성에 효과적일 수 있다지만,지난 블로그 …","fields":{"slug":"/25-12-11_1/"},"frontmatter":{"categories":"NLP LLM","title":"[LLM] 테디노트의 RAG 비법노트 끄적끄적-1","date":"December 11, 2025"}},"next":{"fields":{"slug":"/25-09-09_1/"}},"previous":{"fields":{"slug":"/25-12-12_1/"}}},{"node":{"id":"510447e4-7933-5a0e-b6aa-8ea9e7284203","excerpt":"참고 : 윤대희 외. (2023). 파이토치 트랜스포머를 활용한 자연어 처리와 컴퓨터비전 심층학습. 위키북스. 소스코드: https://github.com/wikibook/pytorchtrf 위의 교재와 소스코드를 참고하였으며, 대부분의 내용은 직접 찾아보며 학습하였습니다.   자연어 처리에서 토큰화하는 것에 대해 알아보자. 토큰을 나누는 기준은 공백 분할, 정규표현식 사용, 어휘사전 적용, 머신러닝 활용하는 방법이 있다. 어휘 사전을 구축할 때, 너무 크게 구축하면 차원의 저주에 빠지고, 너무 작게 구축하면 OOV(Out of Vocab) 존재 가능성이 있으므로 그 크기를 적절히 정해야 하며, 출현빈도는 고려되지만 순서관계는 표현하지 못한다는 점을 기억하자.   토큰화 라이브러리 jamo 라이브러리 h2j (Hangul to Jamo): 한글 → 자모(자음과 모음 / 한글 글자를 초성,중성,종성 단위로 쪼갬) 변환한다.\n자모 단위로 쪼개었을 때 → 음운단위 학습 가능해져, 희귀단…","fields":{"slug":"/25-09-09_1/"},"frontmatter":{"categories":"NLP","title":"[NLP] 파이토치 트랜스포머를 활용한 자연어 처리와 컴퓨터비전 심층학습 -토큰화","date":"September 09, 2025"}},"next":{"fields":{"slug":"/25-07-04_1/"}},"previous":{"fields":{"slug":"/25-12-11_1/"}}}]}},"staticQueryHashes":["1073350324","1956554647","2938748437"]}