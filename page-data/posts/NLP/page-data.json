{"componentChunkName":"component---src-templates-category-template-js","path":"/posts/NLP","result":{"pageContext":{"currentCategory":"NLP","categories":["All","NLP","LLM","ASAC","Paper","Reflections(ML/DL)","Algorithm"],"edges":[{"node":{"id":"d023c61d-c7ed-5cce-a75f-62754442ed31","excerpt":"참고 : 테디노트의 RAG 비법노트 소스코드: https://github.com/teddylee777/langchain-kr   오늘도 작성하는데 Pydantic 파싱 따로 공부한 것 좀 끄적이고 가겠습니다. 레츠기릿!   PydanticOutputParser BaseModel/Field, partial_variables, 결과 포맷 지시사항, parser 등을 알아야 합니다. 예시로 바로 봅시다. 1)  / 는 무엇인가? : “출력 데이터는 반드시 이 구조여야 한다”를 정의하는 스키마(계약서) 필드 누락, 타입 불일치, 구조 깨진다? → 즉시 에러 발생하도록 합니다. : 각 필드의 의미/제약(설명, 기본값 등)을 붙이는 메타데이터 LLM에게 “이 필드는 이런 의미”라고 알려줘서 출력 품질을 올려줄 수 있습니다. 2) 를 넣으면 항상 형식이 맞나? 아닙니다. 프롬프트에 지침 문자열을 미리 채워 넣어주는 기능이라, LLM이 지침을 따를 확률만 높여줄 뿐입니다. ⭐️ 진짜 강제는 par…","fields":{"slug":"/25-12-13_1/"},"frontmatter":{"categories":"NLP LLM","title":"[LLM] 테디노트의 RAG 비법노트 끄적끄적-3","date":"December 13, 2025"}},"next":{"fields":{"slug":"/25-12-12_1/"}},"previous":null},{"node":{"id":"16028044-feb8-52fb-8dfc-47bb74183808","excerpt":"참고 : 테디노트의 RAG 비법노트 소스코드: https://github.com/teddylee777/langchain-kr   오늘도 가즈아..!!!!\n새로운 걸 알아가는 건 정말 즐겁다~ 다만 알게된 것을 {정리}하는 것은 별개일 뿐… O—< 거두절미. 레츠고~!   LCEL 인터페이스 지난 글에서는 invoke(), stream() 메서드를 살펴봤는데\n사실 batch() 메서드도 있다. batch(): 배치 처리 리스트에 input_variables의 값들을 갖는 딕셔너리를 모아서 각각 배치로 chain에 던진다.\nmodel을 거치고 파싱을 거치면서 각 배치 결과의 content들을 리스트에 묶어서 저장된다. 참고로 config 딕셔너리에서 max_concurrency 키의 값을 설정하여 동시 처리할 수 있는 최대 작업 수를 정해줄 수 있다. 즉, 한번에 배치를 여러 개 처리를 할 수 있고 결과는 똑같이 모든 배치를 묶어서 정리되어 있다.   비동기 메소드 어떤 작업을 기다리…","fields":{"slug":"/25-12-12_1/"},"frontmatter":{"categories":"NLP LLM","title":"[LLM] 테디노트의 RAG 비법노트 끄적끄적-2","date":"December 12, 2025"}},"next":{"fields":{"slug":"/25-12-11_1/"}},"previous":{"fields":{"slug":"/25-12-13_1/"}}},{"node":{"id":"66d916a8-fe23-5bc2-a843-b9c1486dac94","excerpt":"참고 : 테디노트의 RAG 비법노트 소스코드: https://github.com/teddylee777/langchain-kr   지난 번 토큰화 관련해서 공부하고 블로그도 썼지만, 관련 내용 이해와 내면화 사이의 괴리가 있었다.\n그런데, 갓 테디노트님 강의 들으면서 그 괴리를 좁혀나갈 수 있었던 것 같다^^< 굳👍🏻 (오늘 게시글은 진짜 두서없이 깨알 Tip 넣을 것임다… 너무 뜬금 없어도 이해부탁…)   서브워드 기반 토큰화 왜 하는 것인가? 문자 기반 토큰화(한국어는 자모 단위로 토큰화)는 너무 쪼개니까 편집거리를 이용해 검색어 추천, 오타 교정 정도에 활용할 수 있는데, 텍스트 문장 생성에서는 너무 많이 분절해놓으니, 이렇게 쪼갠 것을 모델이 학습하고 이걸 생성해내기가 어려워진다.(모델이 생성해야하는 묶음이 더 많아짐!!)\n(우리한테 자모음들을 막 뿌려 주고, 텍스트 문장 만들라고 시켜보면 얼마나 힘든가…) 단어 기반 토큰화는 텍스트 문장 생성에 효과적일 수 있다지만, 지난 블…","fields":{"slug":"/25-12-11_1/"},"frontmatter":{"categories":"NLP LLM","title":"[LLM] 테디노트의 RAG 비법노트 끄적끄적-1","date":"December 11, 2025"}},"next":{"fields":{"slug":"/25-09-09_1/"}},"previous":{"fields":{"slug":"/25-12-12_1/"}}},{"node":{"id":"510447e4-7933-5a0e-b6aa-8ea9e7284203","excerpt":"참고 : 윤대희 외. (2023). 파이토치 트랜스포머를 활용한 자연어 처리와 컴퓨터비전 심층학습. 위키북스. 소스코드: https://github.com/wikibook/pytorchtrf 위의 교재와 소스코드를 참고하였으며, 대부분의 내용은 직접 찾아보며 학습하였습니다.   자연어 처리에서 토큰화하는 것에 대해 알아보자. 토큰을 나누는 기준은 공백 분할, 정규표현식 사용, 어휘사전 적용, 머신러닝 활용하는 방법이 있다. 어휘 사전을 구축할 때, 너무 크게 구축하면 차원의 저주에 빠지고, 너무 작게 구축하면 OOV(Out of Vocab) 존재 가능성이 있으므로 그 크기를 적절히 정해야 하며, 출현빈도는 고려되지만 순서관계는 표현하지 못한다는 점을 기억하자.   토큰화 라이브러리 jamo 라이브러리 h2j (Hangul to Jamo): 한글 → 자모(자음과 모음 / 한글 글자를 초성,중성,종성 단위로 쪼갬) 변환한다.\n자모 단위로 쪼개었을 때 → 음운단위 학습 가능해져, 희귀단…","fields":{"slug":"/25-09-09_1/"},"frontmatter":{"categories":"NLP","title":"[NLP] 파이토치 트랜스포머를 활용한 자연어 처리와 컴퓨터비전 심층학습 -토큰화","date":"September 09, 2025"}},"next":{"fields":{"slug":"/25-07-04_1/"}},"previous":{"fields":{"slug":"/25-12-11_1/"}}}]}},"staticQueryHashes":["1073350324","1956554647","2938748437"]}