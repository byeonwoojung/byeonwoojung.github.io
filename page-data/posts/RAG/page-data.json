{"componentChunkName":"component---src-templates-category-template-js","path":"/posts/RAG","result":{"pageContext":{"currentCategory":"RAG","categories":["All","LLM","RAG","NLP","ASAC","Paper","Reflections(ML/DL)","Algorithm"],"edges":[{"node":{"id":"43e4eb72-86c7-5bf4-b823-9d74506fda6f","excerpt":"오늘은 제가 진행하고 있는 프로젝트에서RAG 성능 평가를 진행했던 부분을 다루고자 합니다.   우선 저는, 유튜브 콘텐츠의 자동 생성 자막 등을 이용한Agent 프로젝트 (자세한 건 아직 비밀 🤫)를 진행 중에 있습니다. 이 데이터를 벡터 임베딩을 통해 RAG 개발을 하고 있는데,개발하면서 했던 여러 고민들을 정리해보고자 합니다.   첫번째 고민: ASR 오류 어떻게 해결하지? 유튜브 콘텐츠 자동 생성 자막은 ASR(Automatic Speech Recognition, 자동 음성 인식)을 통해 만들어지기 때문에 오류가 있습니다. 이는 주변 배경음이나 발화자의 발음, STT 모델의 성능 등의 이유로 발생하는 오류인데이를 곧바로 RAG 개발에 이용하면 문제가 차암 많아지겠죠. 그래서 LLM을 이용해 데이터 전처리를 해보자 마음을 먹었습니다. Phase 1. 자막 교정 시도해보자. ASR 오류에서 ”문자의 형태학적 오류로 인한 의미적 차이를 분명하게 차이가 있었을 때” 문제가 생깁니다.…","fields":{"slug":"/26-01-30_1/"},"frontmatter":{"categories":"LLM RAG","title":"[LLM] Contextual Retrieval과 RAG 평가 💡 (feat. RAGAS, 쯔동 프로젝트)","date":"January 30, 2026"}},"next":{"fields":{"slug":"/26-01-17_1/"}},"previous":null},{"node":{"id":"9873a81c-6667-5bd3-856c-57c33af2f27a","excerpt":"참고 : 테디노트의 RAG 비법노트 (https://fastcampus.co.kr/data_online_teddy)소스코드: https://github.com/teddylee777/langchain-kr위키독스: https://wikidocs.net/book/14314   글이 자주 올라오지 않는 것은RAG와 Agent의 내용들은 프로젝트에 녹여서 끄적이고자 그렇습니다,, 오늘은 아아아주 정말 메모장st 느낌의 글입니다. 다소 짧고 구조적이지 않습니다. 레츠기릿,,   create_sql_query_chain DB에서 특정 값을 조회하기 위한 SQL 쿼리를 생성하고, 쿼리를 실행하는 방법에 대해 정리하고자 합니다. 간단합니다. SQL 쿼리를 생성하는 chain 생성 (DB를 연결하고, 쿼리 생성하는 LLM 선정) 쿼리를 실행하는 도구 생성 두 체인 연결 create_query_chain의 결과가 execute_query의 query 변수에 들어가서 db에 조회합니다.     추가 …","fields":{"slug":"/26-01-17_1/"},"frontmatter":{"categories":"LLM RAG","title":"[LLM] 테디노트의 RAG 비법노트 끄적끄적-14","date":"January 17, 2026"}},"next":{"fields":{"slug":"/26-01-13_1/"}},"previous":{"fields":{"slug":"/26-01-30_1/"}}},{"node":{"id":"34d120bf-0552-506b-8640-779280088570","excerpt":"참고 : 테디노트의 RAG 비법노트 (https://fastcampus.co.kr/data_online_teddy)소스코드: https://github.com/teddylee777/langchain-kr위키독스: https://wikidocs.net/book/14314   오늘은 정말 뜬금없이 갖가지 내용들을 끄적이고자 합니다..@chain 데코레이터, Configurable, Route 등에 대해 정리하고자 합니다. 레츠기릿   @chain 데코레이터 으로 가져와서 데코레이터를 이용해 함수를 으로 변환하도록 합시다. 즉, 은  객체이기 때문에 LCEL 인터페이스에 따라  메서드 등을 활용할 수 있습니다. chain.get_graph().print_ascii()로 체인의 그래프 출력 가능( 그래프 그리는 라이브러리 설치해야 함) 로 체인의 프롬프트 확인 가능 Helper 함수와 Wrapper 함수 Configurable 에 로 전달하는 딕셔너리()에서 주로 쓰는 약속된 키가 몇 가…","fields":{"slug":"/26-01-13_1/"},"frontmatter":{"categories":"LLM RAG","title":"[LLM] 테디노트의 RAG 비법노트 끄적끄적-13","date":"January 13, 2026"}},"next":{"fields":{"slug":"/26-01-11_1/"}},"previous":{"fields":{"slug":"/26-01-17_1/"}}},{"node":{"id":"73d60c32-da40-5d8c-adea-c9b7352ed91c","excerpt":"참고 : 테디노트의 RAG 비법노트 (https://fastcampus.co.kr/data_online_teddy)소스코드: https://github.com/teddylee777/langchain-kr위키독스: https://wikidocs.net/book/14314   오랜만에 왔습니다!! (열심히 공부하고 왔습니다 🫡) Text Embedding와 Vectorstore, Retriver, Reranker는 워낙 모델이 많아서 모두 각각 정리하는 것보다는RAG 개발 시 각 단계별로 고려할 점들을 정리해보는 것이 좋지 않을까 해서 가져왔습니다. 고럼,, 레츠기릿~!   RAG 개발 단계별 고려할 점 각 단계에서 고려할 점들을 제 생각대로 정리해보았습니다. 떠오르는 부분들만 적어두었는데, 추가적으로 고려할 점들이 있다면 알려주시면 감사하겠습니다 😊 1. 데이터 로드 데이터에 따라 로드 방식 설정 PDF 등의 이미지의 문서의 경우 텍스트 OCR 모델 선정   2. 텍스트 데이터 임베…","fields":{"slug":"/26-01-11_1/"},"frontmatter":{"categories":"LLM RAG","title":"[LLM] 테디노트의 RAG 비법노트 끄적끄적-12 (RAG 개발 고려할 점)","date":"January 11, 2026"}},"next":{"fields":{"slug":"/26-01-01_1/"}},"previous":{"fields":{"slug":"/26-01-13_1/"}}},{"node":{"id":"69725161-4cf6-5273-b75f-c77780d8edb4","excerpt":"참고 : 테디노트의 RAG 비법노트 (https://fastcampus.co.kr/data_online_teddy)소스코드: https://github.com/teddylee777/langchain-kr위키독스: https://wikidocs.net/book/14314   오늘도 와쓰요~오늘은 문서 로드 방식과 청킹에 대해 정리해보고자 합니다. 바로 레츠기릿~!   문서 로더 (Loader) 문서 로드 방식을 간단하게 정리하고자 합니다. Document 생성 문서 로드  메서드  메서드: 를 설정해 줌  메서드: 각 문서를 generator 방식으로 읽으면서 버림(문서의 양이 많을 때 유용함)  메서드: 비동기 방식으로 문서를 로드함   문서 로드 방식은 파일 형식이 어떠하든 그 방식이 비슷합니다. 파일 형식에 맞게 loader 설정 후,,  등의 메서드를 이용하여 로드하면 됩니다.     청킹 (Chunking) RAG에서 텍스트를 청킹하는 것은 중요합니다. 아. 청킹은 문서 내…","fields":{"slug":"/26-01-01_1/"},"frontmatter":{"categories":"LLM RAG","title":"[LLM] 테디노트의 RAG 비법노트 끄적끄적-11","date":"January 01, 2026"}},"next":{"fields":{"slug":"/25-12-31_1/"}},"previous":{"fields":{"slug":"/26-01-11_1/"}}},{"node":{"id":"e502e6d7-98be-5c28-a38e-553cae829030","excerpt":"참고 : 테디노트의 RAG 비법노트 (https://fastcampus.co.kr/data_online_teddy)소스코드: https://github.com/teddylee777/langchain-kr위키독스: https://wikidocs.net/book/14314   오늘은 대화 메모리를 저장하는 방법에 대해 끄적끄적 하고자 하는데몇 가지만 다루고자 합니다.   그 전에, chain에서 retriever에 커스텀 함수 연결도 가능하다는 적어두고 가겠습니다. 💡깨알 Tip chain에서 retriever에 커스텀 함수 연결도 가능합니다. 이때 함수에 전달하는 인자는 1개여야 하는데,인자가 여러 개일 때는 wrapper 함수를 통해 전달 가능합니다. 이런 식으로  결과를 커스텀 함수 에 연결해줄 수 있습니다. 이때 전달하는 인자는   1개만 있기 때문에 연결이 가능합니다.   그럼, 본격적으로 레츠기릿~!     ConversationKGMemory: 지식 그래프 형태 기억 우선…","fields":{"slug":"/25-12-30_1/"},"frontmatter":{"categories":"LLM RAG","title":"[LLM] 테디노트의 RAG 비법노트 끄적끄적-9","date":"December 30, 2025"}},"next":{"fields":{"slug":"/25-12-25_1/"}},"previous":{"fields":{"slug":"/25-12-31_1/"}}},{"node":{"id":"0a5507c6-4f1e-5505-b7fb-c556a92f5d07","excerpt":"오늘은 Dense Retriever와 Sparse Retriever에 대해 정리해보고자 합니다. 레츠기릿~!     Dense Retriever vs Sparse Retriever 임베딩(Embedding) Dense Retriever는 텍스트를 고차원 공간의 **밀집 벡터(Dense Vector)**로 변환합니다. Sparse Vector: 단어 사전 전체 크기의 벡터 중 대부분이 0인 형태 (단어 중복 위주) Dense Vector: 보통 768차원이나 1024차원의 고정된 크기 안에 모든 숫자가 의미 있는 수치로 채워진 형태 구분 Sparse Retriever (BM25 등) Dense Retriever (DPR 등) 매칭 방식 키워드 중심 (Exact Match) 문맥 및 의미 중심 (Semantic Match) 특징 “사과”가 포함된 문서를 잘 찾음 “애플”이나 “과일”이라는 단어도 문맥상 이해 장점 빠르고, 도메인 지식 없이도 안정적 동의어 처리와 추상적인 질문 답변에 …","fields":{"slug":"/25-12-23_1/"},"frontmatter":{"categories":"LLM RAG","title":"Dense Retriever와 Sparse Retriever","date":"December 23, 2025"}},"next":{"fields":{"slug":"/25-12-22_1/"}},"previous":{"fields":{"slug":"/25-12-24_1/"}}}]}},"staticQueryHashes":["1073350324","1956554647","2938748437"]}