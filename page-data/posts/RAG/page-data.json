{"componentChunkName":"component---src-templates-category-template-js","path":"/posts/RAG","result":{"pageContext":{"currentCategory":"RAG","categories":["All","LLM","RAG","NLP","ASAC","Paper","Reflections(ML/DL)","Algorithm"],"edges":[{"node":{"id":"0a5507c6-4f1e-5505-b7fb-c556a92f5d07","excerpt":"오늘은 Dense Retriever와 Sparse Retriever에 대해 정리해보고자 합니다. 레츠기릿~!     Dense Retriever vs Sparse Retriever 임베딩(Embedding) Dense Retriever는 텍스트를 고차원 공간의 **밀집 벡터(Dense Vector)**로 변환합니다. Sparse Vector: 단어 사전 전체 크기의 벡터 중 대부분이 0인 형태 (단어 중복 위주) Dense Vector: 보통 768차원이나 1024차원의 고정된 크기 안에 모든 숫자가 의미 있는 수치로 채워진 형태 구분 Sparse Retriever (BM25 등) Dense Retriever (DPR 등) 매칭 방식 키워드 중심 (Exact Match) 문맥 및 의미 중심 (Semantic Match) 특징 “사과”가 포함된 문서를 잘 찾음 “애플”이나 “과일”이라는 단어도 문맥상 이해 장점 빠르고, 도메인 지식 없이도 안정적 동의어 처리와 추상적인 질문 답변에 …","fields":{"slug":"/25-12-23_1/"},"frontmatter":{"categories":"LLM RAG","title":"Dense Retriever와 Sparse Retriever","date":"December 23, 2025"}},"next":{"fields":{"slug":"/25-12-22_1/"}},"previous":{"fields":{"slug":"/25-12-24_1/"}}}]}},"staticQueryHashes":["1073350324","1956554647","2938748437"]}