{"componentChunkName":"component---src-templates-blog-template-js","path":"/25-09-09_1/","result":{"data":{"cur":{"id":"510447e4-7933-5a0e-b6aa-8ea9e7284203","html":"<p>참고 : 윤대희 외. (2023). <em>파이토치 트랜스포머를 활용한 자연어 처리와 컴퓨터비전 심층학습</em>. 위키북스.</p>\n<p>소스코드: <a href=\"https://github.com/wikibook/pytorchtrf\">https://github.com/wikibook/pytorchtrf</a></p>\n<p>위의 교재와 소스코드를 참고하였으며, 대부분의 내용은 직접 찾아보며 학습하였습니다.</p>\n<p> </p>\n<p>자연어 처리에서 토큰화하는 것에 대해 알아보자.</p>\n<p>토큰을 나누는 기준은 공백 분할, 정규표현식 사용, 어휘사전 적용, 머신러닝 활용하는 방법이 있다. <strong>어휘 사전</strong>을 구축할 때, 너무 크게 구축하면 차원의 저주에 빠지고, 너무 작게 구축하면 OOV(Out of Vocab) 존재 가능성이 있으므로 그 크기를 적절히 정해야 하며, <strong>출현빈도는 고려되지만 순서관계는 표현하지 못한다는 점</strong>을 기억하자.</p>\n<p> </p>\n<h2 id=\"토큰화-라이브러리\" style=\"position:relative;\"><a href=\"#%ED%86%A0%ED%81%B0%ED%99%94-%EB%9D%BC%EC%9D%B4%EB%B8%8C%EB%9F%AC%EB%A6%AC\" aria-label=\"토큰화 라이브러리 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>토큰화 라이브러리</h2>\n<hr>\n<h3 id=\"jamo-라이브러리\" style=\"position:relative;\"><a href=\"#jamo-%EB%9D%BC%EC%9D%B4%EB%B8%8C%EB%9F%AC%EB%A6%AC\" aria-label=\"jamo 라이브러리 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>jamo 라이브러리</h3>\n<ul>\n<li>\n<p>h2j (Hangul to Jamo): 한글 → 자모(자음과 모음 / 한글 글자를 초성,중성,종성 단위로 쪼갬) 변환한다.\n자모 단위로 쪼개었을 때 → 음운단위 학습 가능해져, <strong>희귀단어</strong>나 <strong>신조어 처리</strong>에 유리하다.</p>\n</li>\n<li>\n<p>j2hcj (Jamo to Hangul ConJoining): 자모 → 한글 변환한다. (초성+중성+(종성) 다시 합쳐 완전한 한글글자 만듦)</p>\n</li>\n</ul>\n<p> </p>\n<h3 id=\"konlpy-라이브러리\" style=\"position:relative;\"><a href=\"#konlpy-%EB%9D%BC%EC%9D%B4%EB%B8%8C%EB%9F%AC%EB%A6%AC\" aria-label=\"konlpy 라이브러리 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>KoNLPy 라이브러리</h3>\n<ul>\n<li>KoNLPy: 한국어 형태소 분석 라이브러리</li>\n<li>Okt: “Open Korean Text” 형태소 분석기</li>\n</ul>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">from</span> konlpy<span class=\"token punctuation\">.</span>tag <span class=\"token keyword\">import</span> Okt\n\nokt <span class=\"token operator\">=</span> Okt<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n\ntext <span class=\"token operator\">=</span> <span class=\"token string\">\"한글 자연어 처리를 공부해봅시다.\"</span>\n\n<span class=\"token comment\"># 형태소 분석</span>\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span>okt<span class=\"token punctuation\">.</span>morphs<span class=\"token punctuation\">(</span>text<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n<span class=\"token comment\"># ['한글', '자연어', '처리', '를', '공부', '해봅시다', '.']</span>\n\n<span class=\"token comment\"># 형태소 + 품사 태깅</span>\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span>okt<span class=\"token punctuation\">.</span>pos<span class=\"token punctuation\">(</span>text<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n<span class=\"token comment\"># [('한글', 'Noun'), ('자연어', 'Noun'), ('처리', 'Noun'),</span>\n<span class=\"token comment\">#  ('를', 'Josa'), ('공부', 'Noun'), ('해봅시다', 'Verb'), ('.', 'Punctuation')]</span>\n\n<span class=\"token comment\"># 명사 추출</span>\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span>okt<span class=\"token punctuation\">.</span>nouns<span class=\"token punctuation\">(</span>text<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n<span class=\"token comment\"># ['한글', '자연어', '처리', '공부']</span>\n\n<span class=\"token comment\"># 구 추출 - 연속된 명사 묶음을 그대로 반환</span>\n<span class=\"token keyword\">print</span> <span class=\"token punctuation\">(</span>okt<span class=\"token punctuation\">.</span>phrases<span class=\"token punctuation\">(</span>text<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n<span class=\"token comment\"># ['한글', '한글 자연어', '한글 자연어 처리', '공부', '자연어', '처리']</span></code></pre></div>\n<ul>\n<li>Kkma (꼬꼬마): 서울대학교 IDS(Intelligent Data Systems) 연구실에서 개발한 한국어 형태소/구문 분석기\n<ul>\n<li>꼬꼬마는 <code class=\"language-text\">Okt</code>보다 <strong>세밀한 품사 태깅</strong>이 가능하다. (예: 구체적인 조사 구분)</li>\n<li>문장 분리(splitting) 기능이 기본 제공된다.</li>\n<li>속도는 Okt보다 느린 편이지만, 정확성은 높다.</li>\n</ul>\n</li>\n</ul>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">from</span> konlpy<span class=\"token punctuation\">.</span>tag <span class=\"token keyword\">import</span> Kkma\n\nkkma <span class=\"token operator\">=</span> Kkma<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n\ntext <span class=\"token operator\">=</span> <span class=\"token string\">\"한글 자연어 처리를 공부해봅시다.\"</span>\n\n<span class=\"token comment\"># 형태소 분석</span>\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span>kkma<span class=\"token punctuation\">.</span>morphs<span class=\"token punctuation\">(</span>text<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n<span class=\"token comment\"># ['한글', '자연어', '처리', '를', '공부', '해보', 'ㅂ시다', '.'] -> ㅂ시다!!!</span>\n\n<span class=\"token comment\"># 형태소 + 품사 태깅</span>\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span>kkma<span class=\"token punctuation\">.</span>pos<span class=\"token punctuation\">(</span>text<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n<span class=\"token comment\"># [('한글', 'NNG'), ('자연어', 'NNG'), ('처리', 'NNG'), ('를', 'JKO'),</span>\n<span class=\"token comment\"># ('공부', 'NNG'), ('해보', 'VV'), ('ㅂ시다', 'EFA'), ('.', 'SF')]</span>\n\n\n<span class=\"token comment\"># 명사 추출</span>\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span>kkma<span class=\"token punctuation\">.</span>nouns<span class=\"token punctuation\">(</span>text<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n<span class=\"token comment\"># ['한글', '자연어', '처리', '공부']</span>\n\n<span class=\"token comment\"># 문장 추출</span>\n<span class=\"token keyword\">print</span> <span class=\"token punctuation\">(</span>kkma<span class=\"token punctuation\">.</span>sentences<span class=\"token punctuation\">(</span>text<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n<span class=\"token comment\"># ['한글 자연어 처리를 공부 해봅시다.']</span></code></pre></div>\n<p> </p>\n<h3 id=\"nltknatural-language-toolkit-라이브러리\" style=\"position:relative;\"><a href=\"#nltknatural-language-toolkit-%EB%9D%BC%EC%9D%B4%EB%B8%8C%EB%9F%AC%EB%A6%AC\" aria-label=\"nltknatural language toolkit 라이브러리 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>NLTK(Natural Language Toolkit) 라이브러리</h3>\n<ul>\n<li>NLTK 라이브러리는 토큰화(tokenization), 품사 태깅, 파싱, 텍스트 분류, 코퍼스 제공 등 다양한 기능을 지원한다.</li>\n<li>영어 기반이라 한국어 토큰화는 잘 안 된다!! → 한국어는 <code class=\"language-text\">KoNLPy</code>의 <code class=\"language-text\">Okt</code>, <code class=\"language-text\">Kkma</code>, <code class=\"language-text\">Mecab</code> 같은 형태소 분석기 이용하는 것이 더 좋음</li>\n<li>tokenize:</li>\n</ul>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">from</span> nltk<span class=\"token punctuation\">.</span>tokenize <span class=\"token keyword\">import</span> sent_tokenize\n<span class=\"token keyword\">from</span> nltk<span class=\"token punctuation\">.</span>tokenize <span class=\"token keyword\">import</span> word_tokenize\n<span class=\"token keyword\">from</span> nltk<span class=\"token punctuation\">.</span>tokenize <span class=\"token keyword\">import</span> RegexpTokenizer\n\ntext <span class=\"token operator\">=</span> <span class=\"token string\">\"Hello world. This is NLTK. Let's learn tokenization! 123 test.\"</span>\n\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span>sent_tokenize<span class=\"token punctuation\">(</span>text<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n<span class=\"token comment\"># ['Hello world.', 'This is NLTK.', \"Let's learn tokenization!\", '123 test.']</span>\n\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span>word_tokenize<span class=\"token punctuation\">(</span>text<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n<span class=\"token comment\"># ['Hello', 'world', '.', 'This', 'is', 'NLTK', '.',</span>\n<span class=\"token comment\">#  'Let', \"'s\", 'learn', 'tokenization', '!', '123', 'test', '.']</span>\n\n\ntokenizer <span class=\"token operator\">=</span> RegexpTokenizer<span class=\"token punctuation\">(</span><span class=\"token string\">r'\\w+'</span><span class=\"token punctuation\">)</span>  <span class=\"token comment\"># 알파벳 대소문자(a-z, A-Z), 숫자(0-9), 아래밑줄(_) 1개이상 포함 정규화</span>\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span>tokenizer<span class=\"token punctuation\">.</span>tokenize<span class=\"token punctuation\">(</span>text<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n<span class=\"token comment\"># ['Hello', 'world', 'This', 'is', 'NLTK', 'Let', </span>\n<span class=\"token comment\"># 's', 'learn', 'tokenization', '123', 'test']</span></code></pre></div>\n<p> </p>\n<h3 id=\"spacy-라이브러리\" style=\"position:relative;\"><a href=\"#spacy-%EB%9D%BC%EC%9D%B4%EB%B8%8C%EB%9F%AC%EB%A6%AC\" aria-label=\"spacy 라이브러리 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>spaCy 라이브러리</h3>\n<ul>\n<li>\n<p>사이썬(Cython) 기반으로 개발된 오픈소스 라이브러리</p>\n</li>\n<li>\n<p>NLTK보다 빠른 속도, 높은 정확도를 가짐</p>\n</li>\n<li>\n<p>spaCy는 <code class=\"language-text\">spacy.load(\"en_core_web_sm\")</code>로 모델을 불러와서 모델에 문장을 입력값으로 넣으면, 객체 지향적으로 처리된 결과를 속성값으로 접근할 수 있다.</p>\n</li>\n<li>\n<p><code class=\"language-text\">doc</code> : 전체 문서 객체 (<code class=\"language-text\">spacy.tokens.doc.Doc</code>)</p>\n<p><code class=\"language-text\">token</code> : 문서의 토큰 단위 (<code class=\"language-text\">spacy.tokens.token.Token</code>)</p>\n<p><code class=\"language-text\">span</code> : 특정 구간 (문장, 구 등) (<code class=\"language-text\">spacy.tokens.span.Span</code>)</p>\n<p>→ 각 객체에서 속성들을 접근할 수 있는데, 너무 많으니 생략!!</p>\n</li>\n</ul>\n<p> </p>\n<p> </p>\n<h2 id=\"하위-단어-토큰화-subword-tokenization\" style=\"position:relative;\"><a href=\"#%ED%95%98%EC%9C%84-%EB%8B%A8%EC%96%B4-%ED%86%A0%ED%81%B0%ED%99%94-subword-tokenization\" aria-label=\"하위 단어 토큰화 subword tokenization permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>하위 단어 토큰화 (Subword Tokenization)</h2>\n<hr>\n<p>하위 단어 토큰화는 단어(word)를 더 작은 단위인 subword(하위 단어)로 나누는 방법이다. 완전한 형태소 분석보다는 <strong>빈도 기반 분리</strong>에 가깝다. <strong>OOV(Out-Of-Vocabulary, 사전에 없는 단어) 문제를 해결</strong>하기 위해 고안된 것!!</p>\n<p>희귀 단어 처리</p>\n<ul>\n<li>‘돈쭐내다’라는 단어가 사전에 없으면? → 전통적인 토큰화에서는 ‘돈’+‘쭐’+‘내다’로 쪼개서 처리함\n<ul>\n<li>하위단어 토큰화를 적용한다면, 원래 있는 토큰 ‘돈’과 하위단어 ‘쭐’, ‘내’, ‘다’로 쪼개고</li>\n<li>‘돈’+‘쭐내다(subword 패턴 조합)‘로 신조어 패턴을 학습할 수 있음</li>\n</ul>\n</li>\n<li>신조어, 오탈자도 subword로 분리하면 어느 정도 의미 유지 가능하다.</li>\n</ul>\n<p>단어 집합 크기 줄이기</p>\n<ul>\n<li>모든 단어를 사전에 등록하면 수십만~수백만 단어 필요 → 메모리, 연산량 ↑</li>\n<li>subword로 쪼개면 수만 단위의 작은 사전으로 충분해진다.</li>\n</ul>\n<p> </p>\n<h3 id=\"바이트-페어-인코딩-bpe\" style=\"position:relative;\"><a href=\"#%EB%B0%94%EC%9D%B4%ED%8A%B8-%ED%8E%98%EC%96%B4-%EC%9D%B8%EC%BD%94%EB%94%A9-bpe\" aria-label=\"바이트 페어 인코딩 bpe permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>바이트 페어 인코딩 (BPE)</h3>\n<ul>\n<li>\n<p>어휘 사전 추가 방법</p>\n<ul>\n<li><strong>병합 점수 = 특정 쌍이 코퍼스(여러 문장)에서 함께 등장한 횟수(빈도)</strong></li>\n<li>가장 빈도가 높은 쌍을 합친 새로운 subword를 사전에 추가한다. (ex. (‘돈’,‘쭐’) 쌍이 가장 많이 등장한 쌍이면 ‘돈쭐’을 어휘 사전에 추가함)</li>\n<li>이 과정을 vocab_size가 될 때까지 반복한다. (ex. subword로 연결된 ‘돈쭐’과 ‘내’ 쌍이 가장 많이 등장하면 ‘돈쭐내’를 어휘 사전에 추가함)</li>\n</ul>\n</li>\n<li>\n<p>sentencepiece 라이브러리</p>\n<ul>\n<li>\n<p>구글이 만든 언어 독립적인 서브워드 토크나이저</p>\n</li>\n<li>\n<p>BPE(Byte Pair Encoding), Unigram LM 방식을 지원한다.</p>\n</li>\n<li>\n<p>띄어쓰기 기반이 아니라 <strong>문자 단위 입력</strong>을 사용하기 때문에, 한국어·중국어·일본어 등 띄어쓰기가 애매한 언어에도 잘 동작한다.</p>\n</li>\n<li>\n<p>SentencePieceTrainer 모듈</p>\n<ul>\n<li>\n<p>토크나이저 학습 모듈 불러옴 → <strong>새로운 subword 토큰화 모델을 학습</strong>할 때 사용함</p>\n</li>\n<li>\n<p>실행 결과\n<code class=\"language-text\">spm.model</code> → 학습된 토크나이저 모델 파일</p>\n<p><code class=\"language-text\">spm.vocab</code> → 서브워드 사전 (토큰과 점수)</p>\n</li>\n<li>\n<p>주요 파라미터\n<code class=\"language-text\">--input</code> : 학습할 텍스트 파일</p>\n<p><code class=\"language-text\">--model_prefix</code> : 출력 모델/사전 파일 이름 prefix</p>\n<p><code class=\"language-text\">--vocab_size</code> : 어휘 크기 (예: 8000, 32000)</p>\n<p><code class=\"language-text\">--model_type</code> : <code class=\"language-text\">unigram</code>(기본), <code class=\"language-text\">bpe</code>, <code class=\"language-text\">char</code>, <code class=\"language-text\">word</code></p>\n<p><code class=\"language-text\">--character_coverage</code> : 문자 커버율 (예: 한국어는 1.0, 일본어/중국어는 0.9995)</p>\n<p><code class=\"language-text\">--input_sentence_size</code> : 학습에 사용할 문장 샘플 크기</p>\n</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>\n<p>sentencepiece 라이브러리의 SentencePieceTrainer 모듈로 BPE 모델 학습 &#x26; 적용</p>\n</li>\n</ul>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">from</span> sentencepiece <span class=\"token keyword\">import</span> SentencePieceTrainer\n\n<span class=\"token comment\"># bpe 모델 학습</span>\n<span class=\"token comment\"># input.txt: 학습할 말뭉치 (한 줄 = 하나의 문장)</span>\n<span class=\"token comment\"># character_coverage=1.0: 학습 코퍼스에 등장하는 모든 문자를 vocab에 포함(한국어/한자/이모지 다룰 것)</span>\n<span class=\"token comment\"># unk_id: 어휘 사전에 없는 OOV를 의미하는 unk 토큰의 id (기본값: 0)</span>\n<span class=\"token comment\"># bos_id: 문장이 시작되는 지점을 의미하는 bos 토큰의 id (기본값: 1)</span>\n<span class=\"token comment\"># eos_id: 문장이 끝나는 지점을 의미하는 eos 토큰의 id (기본값: 2)</span>\nSentencePieceTrainer<span class=\"token punctuation\">.</span>Train<span class=\"token punctuation\">(</span>\n    \"<span class=\"token operator\">-</span><span class=\"token operator\">-</span><span class=\"token builtin\">input</span><span class=\"token operator\">=</span><span class=\"token builtin\">input</span><span class=\"token punctuation\">.</span>txt\\\n    <span class=\"token operator\">-</span><span class=\"token operator\">-</span>model_prefix<span class=\"token operator\">=</span>spm\\\n    <span class=\"token operator\">-</span><span class=\"token operator\">-</span>vocab_size<span class=\"token operator\">=</span><span class=\"token number\">8000</span>\\\n    <span class=\"token operator\">-</span><span class=\"token operator\">-</span>model_type<span class=\"token operator\">=</span>bpe\\\n    <span class=\"token operator\">-</span><span class=\"token operator\">-</span>character_coverage<span class=\"token operator\">=</span><span class=\"token number\">1.0</span>\"\n<span class=\"token punctuation\">)</span></code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">from</span> sentencepiece <span class=\"token keyword\">import</span> SentencePieceProcessor\n\n<span class=\"token comment\"># 1. 학습된 모델 로드</span>\nsp <span class=\"token operator\">=</span> SentencePieceProcessor<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\nsp<span class=\"token punctuation\">.</span>load<span class=\"token punctuation\">(</span><span class=\"token string\">\"spm.model\"</span><span class=\"token punctuation\">)</span>   <span class=\"token comment\"># Trainer가 만든 모델 파일</span>\n\n<span class=\"token comment\"># 2. 문장을 subword 단위로 토큰화</span>\ntext <span class=\"token operator\">=</span> <span class=\"token string\">\"돈쭐내다라는 신조어를 SentencePiece로 실험해봅시다.\"</span>\n\n<span class=\"token comment\"># 서브워드 단위로 분리 (문장 -> 서브워드)</span>\npieces <span class=\"token operator\">=</span> sp<span class=\"token punctuation\">.</span>encode_as_pieces<span class=\"token punctuation\">(</span>text<span class=\"token punctuation\">)</span>\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"Pieces:\"</span><span class=\"token punctuation\">,</span> pieces<span class=\"token punctuation\">)</span>\n<span class=\"token comment\"># Pieces: ['▁돈', '쭐', '내', '다', '라는', '▁신', '조', '어',</span>\n<span class=\"token comment\"># '를', '▁', 'S', 'e', 'n', 't', 'e', 'n', 'c', 'e',</span>\n<span class=\"token comment\"># 'P', 'i', 'e', 'c', 'e', '로', '▁실', '험', '해', '봅', '시다', '.']</span>\n\n\n<span class=\"token comment\"># 토큰 id로 변환 (문장 -> 정수 인코딩)</span>\nids <span class=\"token operator\">=</span> sp<span class=\"token punctuation\">.</span>encode_as_ids<span class=\"token punctuation\">(</span>text<span class=\"token punctuation\">)</span>\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"IDs:\"</span><span class=\"token punctuation\">,</span> ids<span class=\"token punctuation\">)</span>\n<span class=\"token comment\"># IDs: [189, 3427, 1718, 1622, 165, 111, 1706,</span>\n<span class=\"token comment\"># 1647, 1644, 1620, 2099, 1958, 1997, 1928, 1958,</span>\n<span class=\"token comment\"># 1997, 2047, 1958, 2232, 2009, 1958, 2047, 1958, 1635,</span>\n<span class=\"token comment\"># 136, 1875, 1639, 2029, 743, 1623]</span>\n\n\n<span class=\"token comment\"># 다시 문장으로 복원 (정수 인코딩 -> 문장)</span>\ndecoded_ids <span class=\"token operator\">=</span> sp<span class=\"token punctuation\">.</span>decode_ids<span class=\"token punctuation\">(</span>ids<span class=\"token punctuation\">)</span>\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"Decoded_ids:\"</span><span class=\"token punctuation\">,</span> decoded_ids<span class=\"token punctuation\">)</span>\n<span class=\"token comment\"># Decoded_ids: 돈쭐내다라는 신조어를 SentencePiece로 실험해봅시다.</span>\n\n\n<span class=\"token comment\"># 다시 문장으로 복원 (서브워드 -> 문장)</span>\ndecoded_pieces <span class=\"token operator\">=</span> sp<span class=\"token punctuation\">.</span>decode_pieces<span class=\"token punctuation\">(</span>text<span class=\"token punctuation\">)</span>\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"Decoded_pieces:\"</span><span class=\"token punctuation\">,</span> decoded_pieces<span class=\"token punctuation\">)</span>\n<span class=\"token comment\"># Decoded_pieces: 돈쭐내다라는 신조어를 SentencePiece로 실험해봅시다.</span></code></pre></div>\n<ul>\n<li>학습된 어휘사전 확인</li>\n</ul>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">from</span> sentencepiece <span class=\"token keyword\">import</span> SentencePieceProcessor\n\ntokenizer <span class=\"token operator\">=</span> SentencePieceProcessor<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\ntokenizer<span class=\"token punctuation\">.</span>load<span class=\"token punctuation\">(</span><span class=\"token string\">\"spm.model\"</span><span class=\"token punctuation\">)</span>\n\nvocab <span class=\"token operator\">=</span> <span class=\"token punctuation\">{</span>idx<span class=\"token punctuation\">:</span> tokenizer<span class=\"token punctuation\">.</span>id_to_piece<span class=\"token punctuation\">(</span>idx<span class=\"token punctuation\">)</span> <span class=\"token keyword\">for</span> idx <span class=\"token keyword\">in</span> <span class=\"token builtin\">range</span><span class=\"token punctuation\">(</span>tokenizer<span class=\"token punctuation\">.</span>get_piece_size<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">}</span>\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token builtin\">list</span><span class=\"token punctuation\">(</span>vocab<span class=\"token punctuation\">.</span>items<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">[</span><span class=\"token punctuation\">:</span><span class=\"token number\">100</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>  <span class=\"token comment\"># 100개 확인</span>\n<span class=\"token comment\"># [(0, '&lt;unk>'), (1, '&lt;s>'), (2, '&lt;/s>'), (3, '니다'), (4, '▁이'), (5, '▁있'), (6, '습니다'), (7, '▁하'), (8, '▁그'), (9, '▁사'), (10, '▁대'), (11, '으로'), (12, '▁아'), (13, '▁국'), (14, '▁정'), (15, '합니다'), (16, '▁지'), (17, '에서'), (18, '▁수'), (19, '하는'), (20, '▁가'), (21, '하고'), (22, '입니다'), (23, '▁보'), (24, '..'), (25, '▁일'), (26, '▁한'), (27, '▁없'), (28, '▁해'), (29, '▁제'), (30, '▁부'), (31, '▁생'), (32, '▁자'), (33, '▁것'), (34, '▁나'), (35, '▁주'), (36, '▁국민'), (37, '▁안'), (38, '▁다'), (39, '들이'), (40, '▁시'), (41, '▁어'), (42, '▁기'), (43, '▁1'), (44, '▁저'), (45, '다고'), (46, '▁않'), (47, '▁공'), (48, '▁인'), (49, '▁전'), (50, '▁위'), (51, '▁경'), (52, '▁생각'), (53, '▁되'), (54, '▁모'), (55, '▁있는'), (56, '▁2'), (57, '▁청'), (58, '세요'), (59, '▁우'), (60, '▁여'), (61, '▁무'), (62, '지만'), (63, '▁문'), (64, '▁많'), (65, '니까'), (66, '▁사람'), (67, '▁바'), (68, '▁말'), (69, '▁조'), (70, '▁있습니다'), (71, '▁내'), (72, '▁대한'), (73, '에게'), (74, '이라'), (75, '▁고'), (76, '다는'), (77, '▁받'), (78, '▁의'), (79, '▁상'), (80, '들은'), (81, '▁현'), (82, '▁만'), (83, '▁소'), (84, '▁중'), (85, '는데'), (86, '▁더'), (87, '▁불'), (88, '▁합니다'), (89, '하여'), (90, '▁못'), (91, '해서'), (92, '▁우리'), (93, '▁개'), (94, '▁세'), (95, '▁비'), (96, '하게'), (97, '▁미'), (98, '▁법'), (99, '▁도')]</span>\n<span class=\"token comment\"># vocab size : 8000</span></code></pre></div>\n<p> </p>\n<h3 id=\"워드피스-wordpiece\" style=\"position:relative;\"><a href=\"#%EC%9B%8C%EB%93%9C%ED%94%BC%EC%8A%A4-wordpiece\" aria-label=\"워드피스 wordpiece permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>워드피스 (Wordpiece)</h3>\n<ul>\n<li>\n<p>구글 번역(Google Neural Machine Translation)에서 제안됨</p>\n</li>\n<li>\n<p>어휘 사전 추가 방법</p>\n<ul>\n<li>\n<p><strong>병합 점수 = 글자쌍의 등장횟수 / 각 글자의 등장 횟수의 곱</strong></p>\n</li>\n<li>\n<p><strong>초기 상태</strong>: 어휘 사전(vocab)을 문자 단위로 시작 (예: <code class=\"language-text\">['ㄷ', 'ㅗ', 'ㄴ', '쭐', '내', '다']</code>)</p>\n</li>\n<li>\n<p><strong>병합 과정</strong>: 코퍼스에서 가장 자주 등장하는 <strong>subword 쌍</strong>을 합쳐 새로운 토큰으로 추가</p>\n<ul>\n<li><code class=\"language-text\">'ㄷ'</code>,<code class=\"language-text\">'ㅗ'</code>,<code class=\"language-text\">'ㄴ'</code> 의 등장 횟수 대비 <code class=\"language-text\">\"돈\"</code>이 자주 나오면 `‘ㄷ’+‘ㅗ’+‘ㄴ’ → ‘돈’“</li>\n</ul>\n</li>\n<li>\n<p><strong>사전 확장</strong>: 원하는 vocab_size (예: 30k)까지 반복</p>\n<ul>\n<li>많이 쓰이는 건 그대로 하나의 토큰, 드물게 쓰이는 건 작은 subword 단위로 쪼개짐</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>\n<p>허깅페이스 Tokenizer 라이브러리</p>\n</li>\n</ul>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">from</span> tokenizers <span class=\"token keyword\">import</span> Tokenizer\n<span class=\"token keyword\">from</span> tokenizers<span class=\"token punctuation\">.</span>models <span class=\"token keyword\">import</span> WordPiece\n<span class=\"token keyword\">from</span> tokenizers<span class=\"token punctuation\">.</span>normalizers <span class=\"token keyword\">import</span> Sequence<span class=\"token punctuation\">,</span> NFD<span class=\"token punctuation\">,</span> Lowercase\n<span class=\"token keyword\">from</span> tokenizers<span class=\"token punctuation\">.</span>pre_tokenizers <span class=\"token keyword\">import</span> Whitespace\n\n<span class=\"token comment\"># 1. WordPiece 모델 정의</span>\n<span class=\"token comment\"># - WordPiece 알고리즘을 기반으로 토크나이저를 생성</span>\n<span class=\"token comment\"># - unk_token=\"[UNK]\" : 사전에 없는 토큰(OOV)을 처리할 때 사용되는 특별 토큰</span>\ntokenizer <span class=\"token operator\">=</span> Tokenizer<span class=\"token punctuation\">(</span>WordPiece<span class=\"token punctuation\">(</span>unk_token<span class=\"token operator\">=</span><span class=\"token string\">\"[UNK]\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n\n<span class=\"token comment\"># 2. 정규화기(Normalizer) 설정</span>\n<span class=\"token comment\"># - 입력 텍스트를 표준화하는 과정</span>\n<span class=\"token comment\"># - NFD() : 유니코드 정규화 클래스 (예: é -> e + ´)</span>\n<span class=\"token comment\"># - Lowercase() : 모든 문자를 소문자로 변환하는 정규화 클래스</span>\n<span class=\"token comment\"># - 정규화 클래스는 NFKD, NFC, NFKC, strip 등이 더 존재함</span>\n<span class=\"token comment\"># - Sequence([...]) : 여러 정규화기를 순서대로 적용</span>\ntokenizer<span class=\"token punctuation\">.</span>normalizer <span class=\"token operator\">=</span> Sequence<span class=\"token punctuation\">(</span><span class=\"token punctuation\">[</span>NFD<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> Lowercase<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\n\n<span class=\"token comment\"># 3. PreTokenizer 설정 (사전 토큰화 클래스)</span>\n<span class=\"token comment\"># - 본격적인 subword 학습 전에 단어 단위로 먼저 나누는 과정</span>\n<span class=\"token comment\"># - Whitespace() : 공백 단위로 먼저 토큰 분리하는 클래스</span>\n<span class=\"token comment\"># - 사전 토큰화 클래스는 Sequence(), CharDelimiterSplit(), Digits() 등이 더 존재함</span>\ntokenizer<span class=\"token punctuation\">.</span>pre_tokenizer <span class=\"token operator\">=</span> Whitespace<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n\n<span class=\"token comment\"># 4. WordPiece 토크나이저 학습</span>\n<span class=\"token comment\"># - \"../datasets/corpus.txt\" : 학습에 사용할 말뭉치 파일</span>\n<span class=\"token comment\"># - 파일 안의 텍스트를 기반으로 WordPiece subword 사전을 학습</span>\ntokenizer<span class=\"token punctuation\">.</span>train<span class=\"token punctuation\">(</span><span class=\"token punctuation\">[</span><span class=\"token string\">\"../datasets/corpus.txt\"</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\n\n<span class=\"token comment\"># 5. 학습된 토크나이저 저장</span>\n<span class=\"token comment\"># - \"../models/petition_wordpiece.json\" : 토크나이저 설정 및 vocab이 포함된 JSON 파일</span>\n<span class=\"token comment\"># - 나중에 이 파일을 불러와서 같은 토크나이저를 재사용 가능</span>\ntokenizer<span class=\"token punctuation\">.</span>save<span class=\"token punctuation\">(</span><span class=\"token string\">\"../models/petition_wordpiece.json\"</span><span class=\"token punctuation\">)</span>\n</code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">from</span> tokenizers <span class=\"token keyword\">import</span> Tokenizer\n<span class=\"token keyword\">from</span> tokenizers<span class=\"token punctuation\">.</span>decoders <span class=\"token keyword\">import</span> WordPiece <span class=\"token keyword\">as</span> WordPieceDecoder\n\n<span class=\"token comment\"># 1. 학습된 모델 로드</span>\ntokenizer <span class=\"token operator\">=</span> Tokenizer<span class=\"token punctuation\">.</span>from_file<span class=\"token punctuation\">(</span><span class=\"token string\">\"../models/petition_wordpiece.json\"</span><span class=\"token punctuation\">)</span>\ntokenizer<span class=\"token punctuation\">.</span>decoder <span class=\"token operator\">=</span> WordPieceDecoder<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n\n<span class=\"token comment\"># 2. 문장을 subword 단위로 토큰화</span>\ntext <span class=\"token operator\">=</span> <span class=\"token string\">\"돈쭐내다라는 신조어를 SentencePiece로 실험해봅시다.\"</span>\n\n<span class=\"token comment\"># 인코딩</span>\nencoded <span class=\"token operator\">=</span> tokenizer<span class=\"token punctuation\">.</span>encode<span class=\"token punctuation\">(</span>text<span class=\"token punctuation\">)</span>\n\n<span class=\"token comment\"># 인코딩 타입</span>\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"encoded_type:\"</span><span class=\"token punctuation\">,</span> <span class=\"token builtin\">type</span><span class=\"token punctuation\">(</span>encoded<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n<span class=\"token comment\"># encoded_type: &lt;class 'tokenizers.Encoding'></span>\n\n<span class=\"token comment\"># 문장 토큰화</span>\ntokens <span class=\"token operator\">=</span> encoded<span class=\"token punctuation\">.</span>tokens\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"tokens:\"</span><span class=\"token punctuation\">,</span> tokens<span class=\"token punctuation\">)</span>\n<span class=\"token comment\"># tokens: ['돈', '##ᄍ', '##ᅮᆯ', '##내', '##다', '##라는', '신',</span>\n<span class=\"token comment\"># '##조', '##어를', 'se', '##nt', '##en', '##ce', '##p', '##i'</span>\n<span class=\"token comment\">#  '##ec', '##e', '##로', '실험', '##해보', '##ᆸ시다', '.']</span>\n\n<span class=\"token comment\"># 정수 인코딩</span>\nids <span class=\"token operator\">=</span> encoded<span class=\"token punctuation\">.</span>ids\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"ids:\"</span><span class=\"token punctuation\">,</span> ids<span class=\"token punctuation\">)</span>\n<span class=\"token comment\"># ids: [7917, 4280, 7521, 7731, 7478, 7906,</span>\n<span class=\"token comment\"># 7755, 7649, 11207, 26328, 23624, 10456, 21575,</span>\n<span class=\"token comment\"># 4295, 4263, 10611, 4288, 7495, 12904, 9150, 9008, 13]</span>\n\n<span class=\"token comment\"># 디코딩 (정수 인코딩 -> 문장 변환)</span>\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"decoded:\"</span><span class=\"token punctuation\">,</span> tokenizer<span class=\"token punctuation\">.</span>decode<span class=\"token punctuation\">(</span>ids<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n<span class=\"token comment\"># decoded: 돈쭐내다라는 신조어를 sentencepiece로 실험해봅시다.</span></code></pre></div>\n<p> </p>\n<p>토큰화하는 방법은 여러가지 존재한다.</p>\n<p>번역/챗봇에서는 subword 방식(WordPiece, SentencePiece), 한국어 문법 분석에서는 형태소 기반(Okt, Kkma, Mecab), 소셜미디어 신조어 처리에서는 subword + 자모 단위 보완하도록 토큰화를 진행할 수 있다. 또한, 어떤 단어/서브워드를 어휘 사전에 포함시킬지에 따라 모델 성능이 크게 달라진다.</p>\n<p>결국, <strong>프로젝트 목적에 맞는 토큰화 선택이 중요하고, 어휘사전 구축이 핵심이다.</strong></p>\n<div class=\"table-of-contents\">\n<ul>\n<li>\n<p><a href=\"#%ED%86%A0%ED%81%B0%ED%99%94-%EB%9D%BC%EC%9D%B4%EB%B8%8C%EB%9F%AC%EB%A6%AC\">토큰화 라이브러리</a></p>\n<ul>\n<li><a href=\"#jamo-%EB%9D%BC%EC%9D%B4%EB%B8%8C%EB%9F%AC%EB%A6%AC\">jamo 라이브러리</a></li>\n<li><a href=\"#konlpy-%EB%9D%BC%EC%9D%B4%EB%B8%8C%EB%9F%AC%EB%A6%AC\">KoNLPy 라이브러리</a></li>\n<li><a href=\"#nltknatural-language-toolkit-%EB%9D%BC%EC%9D%B4%EB%B8%8C%EB%9F%AC%EB%A6%AC\">NLTK(Natural Language Toolkit) 라이브러리</a></li>\n<li><a href=\"#spacy-%EB%9D%BC%EC%9D%B4%EB%B8%8C%EB%9F%AC%EB%A6%AC\">spaCy 라이브러리</a></li>\n</ul>\n</li>\n<li>\n<p><a href=\"#%ED%95%98%EC%9C%84-%EB%8B%A8%EC%96%B4-%ED%86%A0%ED%81%B0%ED%99%94-subword-tokenization\">하위 단어 토큰화 (Subword Tokenization)</a></p>\n<ul>\n<li><a href=\"#%EB%B0%94%EC%9D%B4%ED%8A%B8-%ED%8E%98%EC%96%B4-%EC%9D%B8%EC%BD%94%EB%94%A9-bpe\">바이트 페어 인코딩 (BPE)</a></li>\n<li><a href=\"#%EC%9B%8C%EB%93%9C%ED%94%BC%EC%8A%A4-wordpiece\">워드피스 (Wordpiece)</a></li>\n</ul>\n</li>\n</ul>\n</div>","excerpt":"참고 : 윤대희 외. (2023). 파이토치 트랜스포머를 활용한 자연어 처리와 컴퓨터비전 심층학습. 위키북스. 소스코드: https://github.com/wikibook/pytorchtrf 위의 교재와 소스코드를 참고하였으며, 대부분의 내용은 직접 찾아보며 학습하였습니다.   자연어 처리에서 토큰화하는 것에 대해 알아보자. 토큰을 나누는 기준은 공백 분할, 정규표현식 사용, 어휘사전 적용, 머신러닝 활용하는 방법이 있다. 어휘 사전을 구축할 때, 너무 크게 구축하면 차원의 저주에 빠지고, 너무 작게 구축하면 OOV(Out of Vocab) 존재 가능성이 있으므로 그 크기를 적절히 정해야 하며, 출현빈도는 고려되지만 순서관계는 표현하지 못한다는 점을 기억하자.   토큰화 라이브러리 jamo 라이브러리 h2j (Hangul to Jamo): 한글 → 자모(자음과 모음 / 한글 글자를 초성,중성,종성 단위로 쪼갬) 변환한다.\n자모 단위로 쪼개었을 때 → 음운단위 학습 가능해져, 희귀단…","frontmatter":{"date":"September 09, 2025","title":"[NLP] 파이토치 트랜스포머를 활용한 자연어 처리와 컴퓨터비전 심층학습 -토큰화","categories":"NLP","author":"변우중","emoji":"☀️"},"fields":{"slug":"/25-09-09_1/"}},"next":{"id":"e7fe0ccc-c7d8-5340-a138-7745c28d065c","html":"<p>이번 주에는 많은 일들이 있었다(매주 많을 것 같지만..?).</p>\n<p>그동안 파이썬 알고리즘 문제를 풀면서 그 문법들을 익혔고, 이번 주부터는 <strong>파이썬 알고리즘</strong>을 마무리한 후 <strong>MySQL</strong>에서 원하는 데이터를 읽어보는 방법을 학습했다.</p>\n<p>그런데 MySQL까지 진도를 다 나갔고… 무려 금요일에 <strong>Python 알고리즘과 MySQL 데이터로 결과값 찾는 테스트</strong>까지 봤다!!! (미친 속도🔥)</p>\n<p>이번 주부터 나의 주도로 만든 <strong>Python 알고리즘 스터디</strong>도 시작되었다. 스터디는 일주일에 2번 진행됐고 스터디 내에서 선정한 알고리즘 문제를 자신의 난이도에 맞게 선택하여 풀어오는 방식으로 진행되었다.</p>\n<p>몇몇 분들과 함께 <strong>공공데이터를 활용한 데이터 분석 및 AI 관련 공모전</strong>도 나가기로 해서 관련 회의와 데이터 서칭을 했다.</p>\n<p>정신 없는 일주일. 회고를 시작해보자.</p>\n<p> </p>\n<h2 id=\"시점에-대한-정의로-알고리즘-문제해결\" style=\"position:relative;\"><a href=\"#%EC%8B%9C%EC%A0%90%EC%97%90-%EB%8C%80%ED%95%9C-%EC%A0%95%EC%9D%98%EB%A1%9C-%EC%95%8C%EA%B3%A0%EB%A6%AC%EC%A6%98-%EB%AC%B8%EC%A0%9C%ED%95%B4%EA%B2%B0\" aria-label=\"시점에 대한 정의로 알고리즘 문제해결 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>‘시점’에 대한 정의로 알고리즘 문제해결</h2>\n<hr>\n<p>그동안 구현과 그리디, DFS/BFS 위주로 알고리즘 문제를 풀고 학습했다.</p>\n<p>먼저 문제에 대한 이해를 완벽히 한 후, <strong>어떻게 코드화할지 깊이 고민하는 연습</strong>을 했다.</p>\n<p>지금까지 풀었던 문제들은 대개(아직 문제풀이 경험은 적지만..) <strong>내가 필요한 정보를 어떠한 방식으로 저장해둘지</strong>가 관건이었다.</p>\n<ol>\n<li>먼저, <strong>어떤 노드</strong>에 대한 <strong>같은 시점</strong>의 관련 정보가 <strong>무엇이 있을지</strong> 생각해야 한다. (⭐️)</li>\n</ol>\n<ul>\n<li>지난 회고에 올렸던 [카카오 블라인드 채용 기출문제 ‘양과 늑대’]에서도 <strong>어떤 node</strong>에 대해 <strong>연결된 노드</strong>와 <strong>현재 시점의 양의 수와 늑대의 수</strong>를 같이 묶어서 저장했다.</li>\n<li>(<a href=\"https://school.programmers.co.kr/learn/courses/30/lessons/92343\">https://school.programmers.co.kr/learn/courses/30/lessons/92343</a>)</li>\n</ul>\n<p> </p>\n<ol start=\"2\">\n<li>다음으로, 어떤 노드에 대한 <strong>같은 시점의 정보</strong>를 <strong>어떠한 방식으로 저장</strong>할지 고민해야 한다.</li>\n</ol>\n<ul>\n<li>\n<p>노드 간의 연결성 정보를 저장하기 위해서 <strong>딕셔너리 형태</strong>로 해당 노드 번호를 Key로 하고, Value에 해당 노드에 관련된 정보들을 리스트로 넣을 수 있다.</p>\n</li>\n<li>\n<p>다른 방법으로는, <strong>해당 노드 번호를 리스트 인덱스 위치</strong>로 하여 <strong>그 노드에 관한 정보만 리스트 인덱스에 맞게 저장</strong>하는 것이다.</p>\n</li>\n</ul>\n<p> </p>\n<p>처음에는 문제를 풀 때 어떤 정보가 필요할지 단순히 나열하다보니 해결되지 않는 경우가 많았는데, <strong>‘시점’에 대한 정의로 문제 풀이 계획을 깔끔하게 할 수 있음을 알게 되었다</strong>.</p>\n<p>(우선순위 큐를 이용한 다익스트라 알고리즘 문제 풀이를 올리려고 했는데, Algorithm 카테고리에 따로 분석해서 올리겠습니다!!)</p>\n<p> </p>\n<h2 id=\"mysql-보고-싶은-부분을-최대한-구체화하여-코드화하자\" style=\"position:relative;\"><a href=\"#mysql-%EB%B3%B4%EA%B3%A0-%EC%8B%B6%EC%9D%80-%EB%B6%80%EB%B6%84%EC%9D%84-%EC%B5%9C%EB%8C%80%ED%95%9C-%EA%B5%AC%EC%B2%B4%ED%99%94%ED%95%98%EC%97%AC-%EC%BD%94%EB%93%9C%ED%99%94%ED%95%98%EC%9E%90\" aria-label=\"mysql 보고 싶은 부분을 최대한 구체화하여 코드화하자 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>MySQL: 보고 싶은 부분을 최대한 구체화하여 코드화하자.</h2>\n<hr>\n<p>문법적으로는 기본적인 SELECT 문, DELIMITER 구분자와 BEGIN과 END, JOIN의 다양한 방법, 서브쿼리 활용 방법(비연관 서브쿼리 중심으로), CONCAT 함수, VIEW, INDEX에 대해 학습했다.</p>\n<p>항상 그랬듯이 <strong>문법을 아는 것과 문제해결은 다른 것</strong>이다. 일상어로 이루어진 요구사항 또는 내가 필요한 정보를 뽑아내기 위해서는 ’<strong>코드 구현을 위한 구체화</strong>‘의 작업이 필요하다.</p>\n<p>어떤 커머스 회사가 <strong>신규 유입자들이 이탈하지 않도록 하고 싶다</strong>고 하자.</p>\n<p>의사결정을 내리기 전에 정보를 탐색해봐야 한다.</p>\n<ol>\n<li>신규 유입자들의 order 정보를 봐야할 것이다.</li>\n<li>더 깊이 들여다 보면, 신규 유입자의 이탈은 첫 주문 이후 얼마나 이탈되었는지와 관련있어 보인다.</li>\n<li>첫 주문 이후 두번째 주문이 없는 유저의 비율을 살펴보는 것이 좋아 보인다.</li>\n</ol>\n<p>이정도 구체화하고, 코드화하면서 더 구체화해보자.</p>\n<div class=\"gatsby-highlight\" data-language=\"mysql\"><pre class=\"language-mysql\"><code class=\"language-mysql\">SELECT * FROM orders LIMIT 5;</code></pre></div>\n<p>먼저 orders 테이블의 데이터 내용들을 살펴본다.</p>\n<p> </p>\n<p>다음으로, CustomerID 별로 구매횟수를 살펴보자. (바로 구매횟수가 1번인 사람들을 볼 수 있지만 하나씩 탐색해 나가는 것이 결과물을 찾는 방향이 꼬이지 않는다.)</p>\n<div class=\"gatsby-highlight\" data-language=\"mysql\"><pre class=\"language-mysql\"><code class=\"language-mysql\">SELECT CustomerID, COUNT(DISTINCT InvoiceDate) `구매 횟수`\nFROM orders\nGROUP BY CustomerID</code></pre></div>\n<p>CustomerID 별로 구매횟수를 살펴보기 위해 COUNT() 함수를 이용하는데, <strong>DISTINCT InvoiceDate</strong>를 이용했다. (InvoiceDate는 주문 날짜) 나는 <strong>같은 날의 주문들은 모두 같은 구매로 취급</strong>했다. <strong>오늘 주문하고 이탈하는 고객들을 보고 싶었다</strong>.</p>\n<p>코드화 과정에서 이러한 구체성을 갖고 분석할 수 있다.</p>\n<p> </p>\n<p>다음으로, <strong>구매횟수가 1인 고객들이 몇 명</strong>인지 보자.</p>\n<div class=\"gatsby-highlight\" data-language=\"mysql\"><pre class=\"language-mysql\"><code class=\"language-mysql\">SELECT COUNT(CustomerID) `첫 구매 후 이탈 고객의 수`\nFROM (\n\tSELECT CustomerID, COUNT(DISTINCT InvoiceDate) `구매 횟수`\n\tFROM orders\n\tGROUP BY CustomerID\n)A\nWHERE `구매 횟수` = 1;</code></pre></div>\n<p>구매 횟수가 1인 행 데이터만 필터링하여 CustomerID의 개수를 파악하면 된다.</p>\n<p>그런데 ’<strong>첫 구매 후 이탈 고객 비율</strong>‘을 어떻게 구할까…?</p>\n<p>-> <strong>전체 고객의 수가 필요하다</strong>. (첫 구매 후 이탈 고객의 수)/(전체 고객의 수) 계산을 해야 하는데, WHERE 절에서 필터링을 거쳤다.</p>\n<p>-> 그러면, <strong>WHERE 절에서 필터링을 하지 않으면서 전체 고객의 수를 가져오는 대신에, 필터링을 SELECT 절에서 하는 것이 좋을 듯</strong>하다.</p>\n<p> </p>\n<div class=\"gatsby-highlight\" data-language=\"mysql\"><pre class=\"language-mysql\"><code class=\"language-mysql\">SELECT SUM(CASE WHEN `구매 횟수`=1 THEN 1 ELSE 0 END)/COUNT(*) `첫 구매 후 이탈 고객 비율`\nFROM (\n\tSELECT CustomerID, COUNT(DISTINCT InvoiceDate) `구매 횟수`\n\tFROM orders\n\tGROUP BY CustomerID\n)A;</code></pre></div>\n<p>SUM() 함수와 CASE WHEN을 이용해서 필터링하면 해결할 수 있다.</p>\n<p>이렇게 첫 구매 후 이탈 고객의 비율을 확인할 수 있는데, 이뿐만 아니라 구매 횟수별로 이탈 고객의 비율을 확인하거나 구매 날짜 등을 확인하면서 고객에게 푸시 알람, 프로모션 등에 대한 계획을 할 수 있을 것이다.</p>\n<p>의사결정을 하기 전의 하나의 정보를 탐색하기 위해 해야하는 생각의 흐름을 깊이 돌아봤다. 문법은 찾으면 된다. 중요한 것은 <strong>내가 의사결정을 위해 어떠한 정보를 탐색할 것인지와 그 정보를 살피기 위해 보고 싶은 부분을 최대한 구체화하여 코드화해야 하는 것</strong>이다.</p>\n<p> </p>\n<h2 id=\"python-mysql-테스트\" style=\"position:relative;\"><a href=\"#python-mysql-%ED%85%8C%EC%8A%A4%ED%8A%B8\" aria-label=\"python mysql 테스트 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Python, MySQL 테스트</h2>\n<hr>\n<p>3주차 금요일에 Python, MySQL 테스트를 약 4시간 동안 보았다. 지난 수업에서 다뤘던 것들과 새로운 문제들을 섞어서 출제됐는데.. 결론은 반성 좀 하자.. 정신 없이 2~3주를 보냈던 것도 맞고, 잠을 많이 줄여 최악의 컨디션이었던 것도 맞지만, 다 핑계다.</p>\n<p>어렵거나 헷갈리는 문제를 건너띄지 않고 시간을 할애해 어떻게든 풀고자 하는 습관은 좋은 점도 있지만 테스트에서는 독이 될 수 있다. 집에 가서 푹 자고 난 후, 주말에 다시 풀어보았는데 금방 다 풀 수 있던 문제들…^^</p>\n<p><strong>[개선할 점]</strong></p>\n<ol>\n<li>\n<p><strong>문제를 읽고 문제 정의를 제대로 하자</strong>.</p>\n<ul>\n<li>SQL 문제에서 묻는 것을 정확히 문제 정의하자.</li>\n<li>문제 정의에서 필요한 것은 <strong>필요한 컬럼 정리</strong>와 <strong>구조화</strong>이다.\n<ul>\n<li>우선 필요한 컬럼을 하나씩 다 써보자.</li>\n<li>JOIN, FROM절에 서브쿼리, SELECT절에 서브쿼리, CASE WHEN, SUM() 함수 등을 이용해 해당 컬럼들을 어떻게 넣어볼지 생각하자.</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>\n<p><strong>Python 알고리즘 방식을 제대로 뜯어보면서 이해하자</strong>.</p>\n<ul>\n<li>\n<p>양과 늑대 문제… DFS를 이용하여 왔던 길도 다시 방문하는 방식을 이해하고 그 방식도 알고 있었지만, 그 세밀한 부분에서 이해가 좀 부족했던 것 같다.</p>\n</li>\n<li>\n<p>queue.append([node, move_nodes[:i] + move_nodes[i+1:] + node_tree[node], num_sheep + 1, num_wolf]) 에서 move_nodes 리스트와 node_tree 리스트는 다른 것이다. (1-2주차 회고에서 소스코드를 올렸던 부분이다.)</p>\n</li>\n<li>\n<p>for문으로 롤링하고 있는 리스트에 대해 현재 노드 전에 롤링으로 방문했던 곳과 앞으로 롤링으로 방문해야 할 곳이 move_nodes[:i], move_nodes[i+1:]이고, for문에서 롤링으로 현재 방문한 노드에 대해 연결된 노드들이 node_tree[node]이다. 헷갈리지 말자.</p>\n</li>\n</ul>\n</li>\n</ol>\n<p> </p>\n<h2 id=\"python-알고리즘-코딩테스트-스터디\" style=\"position:relative;\"><a href=\"#python-%EC%95%8C%EA%B3%A0%EB%A6%AC%EC%A6%98-%EC%BD%94%EB%94%A9%ED%85%8C%EC%8A%A4%ED%8A%B8-%EC%8A%A4%ED%84%B0%EB%94%94\" aria-label=\"python 알고리즘 코딩테스트 스터디 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Python 알고리즘 코딩테스트 스터디</h2>\n<hr>\n<p>Python 알고리즘 코딩테스트 스터디를 이번 주 2번 진행했다.</p>\n<p>프로그래머스 Level 1, Level 2 위주의 문제를 선정해서 자신의 수준에 맞는 (약간의 도전감 있는) 문제를 선택해서 풀어오면 된다. 물론 풀어오지 못한 문제가 있을 수 있다.</p>\n<p>스터디의 목적은 함께 공유하고 도와주면서 알고리즘 실력 향상에 있다. 자신이 선택한 문제를 풀지 못하더라도 고민을 충분히 하고, 자신의 고민에 대한 나눔을 진행했다. <strong>고민에 대한 피드백 제공</strong>과 <strong>같은 문제의 여러가지 풀이 방법 이해</strong>에 초점을 맞추어 스터디를 진행했다.</p>\n<p>이번 주 스터디에서 2가지가 기억난다.</p>\n<ol>\n<li>\n<p><strong>나의 잘못된 설명을 스터디원이 바르게 고쳐줬던 것</strong></p>\n<p>문제 상황은 “for문에서 리스트(a_list)를 롤링하는데, 리스트의 정보를 수정했을 때(ex. a_list.pop()을 진행) 반영이 되어 롤링이 진행될 것인가?” 이다.</p>\n<span class=\"gatsby-resp-image-wrapper\" style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 720px; \">\n      <span class=\"gatsby-resp-image-background-image\" style=\"padding-bottom: 71.66666666666667%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAOCAYAAAAvxDzwAAAACXBIWXMAABYlAAAWJQFJUiTwAAAB0klEQVQ4y6WTW3PaMBCF9U4wmBmwjK+6y7IMCSQEEsok7f//TacjkxBa6KSTPHyj3fOgWe05IkxKmK6DMA24NWBag2kFpiS4c2DGghmDsihQluWnkLb1uH/YQAkD3Sgoq2G8hXYGQkkwIcCFAGPsvyC84TDewN02eNw9Y3m3QlWWqKvqT+r6UnvXzyBFWWK9XuPn6wvun1/wdHiFtRZcKUhjIJsGQuse6VzfS2uPtbW9HibjnB8nDO8OF3jv0ToHwTmKokCa55gXxYk0yzAvyw8t1Hne65TSE0RrjcViAa0UptMpBoMBomiIaHiFmxtEUXQk9G/1aDQ6QbKiAJMCNJtjRlPQ+RyzhCKhKRJKkaQpaJ6DhkmyDLMk+WA2u4BY1+LuYQPTeNhlB921MIsWdun7HYZdqraFeNvbpy7b1qJbdn00XGPQNAbaagjBwa45+5erFy5XsoK/9djuH7E9/MJmt4fRCnXNwIJz13if6IpO8izHarXCYf8Dq80O26d973r4HbL14OHZIUYhIiEq3aLXwo8KvQixCqdzvU6klAhOm3BJXWE0ihDHE0zi+MjkrD7nHzoRQqDrOmRZhvF4jHEcH88vQowxfZCHwyHiOP42vwG8m3uhvgBxNgAAAABJRU5ErkJggg=='); background-size: cover; display: block;\"></span>\n  <img class=\"gatsby-resp-image-image\" alt=\"img_01\" title=\"img_01\" src=\"/static/f5497d365cdbddcd4b0a93c285310dc5/37523/img_01.png\" srcset=\"/static/f5497d365cdbddcd4b0a93c285310dc5/e9ff0/img_01.png 180w,\n/static/f5497d365cdbddcd4b0a93c285310dc5/f21e7/img_01.png 360w,\n/static/f5497d365cdbddcd4b0a93c285310dc5/37523/img_01.png 720w,\n/static/f5497d365cdbddcd4b0a93c285310dc5/d9217/img_01.png 904w\" sizes=\"(max-width: 720px) 100vw, 720px\" style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\" loading=\"lazy\" decoding=\"async\">\n    </span>\n<ul>\n<li><strong>결론</strong>은 <strong>for문에서 리스트의 정보를 수정하면 그 수정사항을 반영하여 for문이 돌아간다</strong>.</li>\n<li>그렇다면 <strong>for문에서만큼은 그 리스트가 수정사항을 반영하지 않으면서 롤링하고, for문이 끝난 후에 수정사항이 반영된 리스트를 사용할 수 있을까?</strong>\n<ul>\n<li>리스트의 복사본(깊은 복사)을 롤링하면 된다.</li>\n<li>**for element in a_list[:]:**을 이용하면 a_list의 깊은 복사인 a_list[:]를 롤링하고, a_list를 수정하면 된다.</li>\n</ul>\n</li>\n</ul>\n</li>\n</ol>\n<p> </p>\n<ol start=\"2\">\n<li>\n<p><strong>스택&#x26;큐 문제 중에서 시간 복잡도를 확 줄인 풀이 방법</strong></p>\n<ul>\n<li>\n<p>문제 출처 : <a href=\"https://school.programmers.co.kr/learn/courses/30/lessons/42584\">https://school.programmers.co.kr/learn/courses/30/lessons/42584</a></p>\n</li>\n<li>\n<p>다들 2중 for문으로 시간 복잡도가 <span class=\"math math-inline\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>O</mi><mo stretchy=\"false\">(</mo><msup><mi>n</mi><mn>2</mn></msup><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">O(n^{2})</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1.0641em;vertical-align:-0.25em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.02778em;\">O</span><span class=\"mopen\">(</span><span class=\"mord\"><span class=\"mord mathnormal\">n</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8141em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\">2</span></span></span></span></span></span></span></span></span><span class=\"mclose\">)</span></span></span></span></span>가 되도록 문제풀이를 했는데… 굉장히 효율적인 방식을 배웠다.</p>\n</li>\n<li>\n<p>문제 설명</p>\n<ul>\n<li>초 단위로 기록된 주식가격 prices 리스트가 있는데 가격이 떨어지지 않은 기간은 몇 초인지를 기록하는 것이다.</li>\n<li>prices = [1, 2, 3, 2, 5] 이라 하자.</li>\n<li>리스트의 인덱스 기준으로 순번(0번째, 1번째, 2번째 …)을 본다고 하자. 0번째의 1은 끝까지 주식가격이 떨어지지 않으므로 4초로 기록되고, 1번째의 2도 끝까지 주식가격이 떨어지지 않으므로 3초로 기록되고, 2번째의 3은 1초 뒤에 2로 떨어지므로 1초로 기록된다. 3번째의 2는 끝까지 주식가격이 떨어지지 않으므로 1로 기록되고, 4번째의 5는 마지막이므로 0초로 기록된다.</li>\n<li>최종 결과는 [4, 3, 1, 1, 0]으로 출력된다.</li>\n</ul>\n</li>\n<li>\n<p>시간 복잡도 <span class=\"math math-inline\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>O</mi><mo stretchy=\"false\">(</mo><msup><mi>n</mi><mn>2</mn></msup><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">O(n^{2})</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1.0641em;vertical-align:-0.25em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.02778em;\">O</span><span class=\"mopen\">(</span><span class=\"mord\"><span class=\"mord mathnormal\">n</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8141em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\">2</span></span></span></span></span></span></span></span></span><span class=\"mclose\">)</span></span></span></span></span> 인 2중 for문 방법의 풀이</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token comment\"># 프로그래머스 lv2 주식가격</span>\n<span class=\"token keyword\">def</span> <span class=\"token function\">solution</span><span class=\"token punctuation\">(</span>prices<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    answer <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span><span class=\"token punctuation\">]</span>\n\n    <span class=\"token comment\"># 각 price마다 위치(i)도 같이 가져옴</span>\n    <span class=\"token keyword\">for</span> i<span class=\"token punctuation\">,</span> price <span class=\"token keyword\">in</span> <span class=\"token builtin\">enumerate</span><span class=\"token punctuation\">(</span>prices<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        <span class=\"token comment\"># 마지막 위치에서는 0을 추가하고 종료</span>\n        <span class=\"token keyword\">if</span> i <span class=\"token operator\">==</span> <span class=\"token builtin\">len</span><span class=\"token punctuation\">(</span>prices<span class=\"token punctuation\">)</span> <span class=\"token operator\">-</span> <span class=\"token number\">1</span><span class=\"token punctuation\">:</span>\n            answer<span class=\"token punctuation\">.</span>append<span class=\"token punctuation\">(</span><span class=\"token number\">0</span><span class=\"token punctuation\">)</span>\n            <span class=\"token keyword\">break</span>\n        \n        <span class=\"token comment\"># 각 price에서 그 이후부터 확인</span>\n        <span class=\"token keyword\">for</span> j <span class=\"token keyword\">in</span> <span class=\"token builtin\">range</span><span class=\"token punctuation\">(</span>i<span class=\"token operator\">+</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span> <span class=\"token builtin\">len</span><span class=\"token punctuation\">(</span>prices<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n            <span class=\"token comment\"># 중간에 자신의 price 보다 더 작아지면 앞으로 더 걸린 시간 만큼 저장함</span>\n            <span class=\"token keyword\">if</span> price <span class=\"token operator\">></span> prices<span class=\"token punctuation\">[</span>j<span class=\"token punctuation\">]</span><span class=\"token punctuation\">:</span>\n                answer<span class=\"token punctuation\">.</span>append<span class=\"token punctuation\">(</span>j<span class=\"token operator\">-</span>i<span class=\"token punctuation\">)</span>\n                <span class=\"token keyword\">break</span>\n            \n            <span class=\"token comment\"># 끝까지 가면</span>\n            <span class=\"token keyword\">if</span> j <span class=\"token operator\">==</span> <span class=\"token builtin\">len</span><span class=\"token punctuation\">(</span>prices<span class=\"token punctuation\">)</span><span class=\"token operator\">-</span><span class=\"token number\">1</span><span class=\"token punctuation\">:</span>\n                answer<span class=\"token punctuation\">.</span>append<span class=\"token punctuation\">(</span>j<span class=\"token operator\">-</span>i<span class=\"token punctuation\">)</span>\n\n    \n    <span class=\"token keyword\">return</span> answer\n</code></pre></div>\n</li>\n<li>\n<p>시간 복잡도 <span class=\"math math-inline\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>O</mi><mo stretchy=\"false\">(</mo><mi>n</mi><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">O(n)</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.02778em;\">O</span><span class=\"mopen\">(</span><span class=\"mord mathnormal\">n</span><span class=\"mclose\">)</span></span></span></span></span>인 풀이</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">def</span> <span class=\"token function\">solution</span><span class=\"token punctuation\">(</span>prices<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    answer <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">*</span> <span class=\"token builtin\">len</span><span class=\"token punctuation\">(</span>prices<span class=\"token punctuation\">)</span>  <span class=\"token comment\"># 결과 리스트 초기화</span>\n    stack <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span><span class=\"token punctuation\">]</span>  <span class=\"token comment\"># 가격과 인덱스를 저장할 스택</span>\n\n    i <span class=\"token operator\">=</span> <span class=\"token number\">0</span>\n    <span class=\"token keyword\">while</span> i <span class=\"token operator\">&lt;</span> <span class=\"token builtin\">len</span><span class=\"token punctuation\">(</span>prices<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>  \n        <span class=\"token comment\"># 가격이 떨어졌다면 스택에서 pop()하여 처리</span>\n        <span class=\"token keyword\">while</span> stack <span class=\"token keyword\">and</span> prices<span class=\"token punctuation\">[</span>i<span class=\"token punctuation\">]</span> <span class=\"token operator\">&lt;</span> stack<span class=\"token punctuation\">[</span><span class=\"token operator\">-</span><span class=\"token number\">1</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">:</span>  \n            _<span class=\"token punctuation\">,</span> index <span class=\"token operator\">=</span> stack<span class=\"token punctuation\">.</span>pop<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n            answer<span class=\"token punctuation\">[</span>index<span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> i <span class=\"token operator\">-</span> index  <span class=\"token comment\"># 가격 유지 시간 계산</span>\n\n        stack<span class=\"token punctuation\">.</span>append<span class=\"token punctuation\">(</span><span class=\"token punctuation\">[</span>prices<span class=\"token punctuation\">[</span>i<span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> i<span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>  <span class=\"token comment\"># 현재 가격과 인덱스 추가</span>\n        i <span class=\"token operator\">+=</span> <span class=\"token number\">1</span>\n\n    <span class=\"token comment\"># 끝까지 가격이 유지된 경우 처리</span>\n    <span class=\"token keyword\">while</span> stack<span class=\"token punctuation\">:</span>\n        _<span class=\"token punctuation\">,</span> index <span class=\"token operator\">=</span> stack<span class=\"token punctuation\">.</span>pop<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n        answer<span class=\"token punctuation\">[</span>index<span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> <span class=\"token builtin\">len</span><span class=\"token punctuation\">(</span>prices<span class=\"token punctuation\">)</span> <span class=\"token operator\">-</span> <span class=\"token number\">1</span> <span class=\"token operator\">-</span> index \n    \n    <span class=\"token keyword\">return</span> answer</code></pre></div>\n<ul>\n<li>prices에서 하나씩 꺼내면서 1초가 지난다. 그러면 각 가격에 대해 [현재 가격, 현재 지난 시간(초)]를 함께 stack에 추가할 수 있을 것이다.</li>\n<li>그런데, stack에 추가하기 전에 <strong>현재 가격</strong>이 <strong>가장 마지막에 추가된 가격보다 작아지면</strong> <strong>그 마지막에 추가된 가격을 stack에서 제거</strong>하고, <strong>시간(현재 시간-그 가격이 추가된 시간)을 계산</strong>하여 answer에서 그 가격에 맞는 인덱스에 맞게 저장한다.</li>\n<li>이때, 앞에서 마지막에 추가된 가격이 stack에서 제거되면 <strong>그 현재 가격으로 다음 마지막에 추가된 가격도 계속 비교해서 제거한다</strong>. 더이상 비교할 것이 없으면 그 현재 가격과 현재 지난 시간을 함께 stack에 추가한다.</li>\n<li>결국, 이 방식은 <strong>리스트 한 바퀴만(n번 연산) 돌리는데 조건에 맞는 것들만 한 번씩 pop하여(모든 값이 최종적으로 pop이 되므로 n번 연산) 결과를 추가한다</strong>. <strong>2n번 연산만 진행되므로 시간 복잡도는 O(n)이다</strong>.</li>\n</ul>\n</li>\n</ul>\n</li>\n</ol>\n<p>리스트를 인덱스 i를 이용해 접근하여 현재 가격과 지나가는 시간을 자연스럽게 저장하면서 조건에 맞는 것만 pop하는 방식이다.</p>\n<p>찾아보니 <strong>스택을 사용해서 과거 가격들만 스택에 쌓아두고, 떨어지면 pop하는 방식이 ‘모노토닉 스택 패턴’이라고 한다</strong>고 한다. 잊지 말자…!!!!!!!!</p>\n<p> </p>\n<h2 id=\"공모전-도전\" style=\"position:relative;\"><a href=\"#%EA%B3%B5%EB%AA%A8%EC%A0%84-%EB%8F%84%EC%A0%84\" aria-label=\"공모전 도전 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>공모전 도전</h2>\n<hr>\n<p>열심히 공부하는 모습을 보면서 어떤 분이 함께 공모전을 나가자는 제안을 해주셨다.</p>\n<p>마침 관심이 있던 주제이기도 하여 함께 준비하기로 했다. ‘청소년’이라는 주제로 공공데이터 분석, AI 관련 공모전을 준비하고자 한다. 현재는 첫 회의한 후에 여러 데이터셋을 수집하는 과정에 있다.</p>\n<p>파이리이이잉💪🏻</p>\n<div class=\"table-of-contents\">\n<ul>\n<li><a href=\"#%EC%8B%9C%EC%A0%90%EC%97%90-%EB%8C%80%ED%95%9C-%EC%A0%95%EC%9D%98%EB%A1%9C-%EC%95%8C%EA%B3%A0%EB%A6%AC%EC%A6%98-%EB%AC%B8%EC%A0%9C%ED%95%B4%EA%B2%B0\">‘시점’에 대한 정의로 알고리즘 문제해결</a></li>\n<li><a href=\"#mysql-%EB%B3%B4%EA%B3%A0-%EC%8B%B6%EC%9D%80-%EB%B6%80%EB%B6%84%EC%9D%84-%EC%B5%9C%EB%8C%80%ED%95%9C-%EA%B5%AC%EC%B2%B4%ED%99%94%ED%95%98%EC%97%AC-%EC%BD%94%EB%93%9C%ED%99%94%ED%95%98%EC%9E%90\">MySQL: 보고 싶은 부분을 최대한 구체화하여 코드화하자.</a></li>\n<li><a href=\"#python-mysql-%ED%85%8C%EC%8A%A4%ED%8A%B8\">Python, MySQL 테스트</a></li>\n<li><a href=\"#python-%EC%95%8C%EA%B3%A0%EB%A6%AC%EC%A6%98-%EC%BD%94%EB%94%A9%ED%85%8C%EC%8A%A4%ED%8A%B8-%EC%8A%A4%ED%84%B0%EB%94%94\">Python 알고리즘 코딩테스트 스터디</a></li>\n<li><a href=\"#%EA%B3%B5%EB%AA%A8%EC%A0%84-%EB%8F%84%EC%A0%84\">공모전 도전</a></li>\n</ul>\n</div>","frontmatter":{"date":"April 06, 2025","title":"[ASAC 회고] 3주차: 도전","categories":"ASAC","author":"변우중","emoji":"🌤️"},"fields":{"slug":"/25-04-06_1/"}},"prev":null,"site":{"siteMetadata":{"siteUrl":"https://www.zoomkoding.com","comments":{"utterances":{"repo":""}}}}},"pageContext":{"slug":"/25-09-09_1/","nextSlug":"/25-04-06_1/","prevSlug":""}},"staticQueryHashes":["1073350324","1956554647","2938748437"]}