---
emoji: â˜€ï¸
title: "[LLM] í…Œë””ë…¸íŠ¸ì˜ RAG ë¹„ë²•ë…¸íŠ¸ ë„ì ë„ì -13"
date: '2026-01-13 00:00:00'
author: ë³€ìš°ì¤‘
tags: LLM í”„ë¡¬í”„íŠ¸ RAG LangChain ë­ì²´ì¸ Retriver ë¦¬íŠ¸ë¦¬ë²„ Reranker ë¦¬ë­ì»¤ Vectorstore ë²¡í„°ìŠ¤í† ì–´
categories: LLM RAG
---

ì°¸ê³  : í…Œë””ë…¸íŠ¸ì˜ RAG ë¹„ë²•ë…¸íŠ¸ (https://fastcampus.co.kr/data_online_teddy)<br>ì†ŒìŠ¤ì½”ë“œ: https://github.com/teddylee777/langchain-kr<br>ìœ„í‚¤ë…ìŠ¤: https://wikidocs.net/book/14314

&nbsp;

ì˜¤ëŠ˜ì€ ì •ë§ ëœ¬ê¸ˆì—†ì´ ê°–ê°€ì§€ ë‚´ìš©ë“¤ì„ ë„ì ì´ê³ ì í•©ë‹ˆë‹¤..<br>**@chain ë°ì½”ë ˆì´í„°**, **Configurable**, **Route** ë“±ì— ëŒ€í•´ ì •ë¦¬í•˜ê³ ì í•©ë‹ˆë‹¤.

ë ˆì¸ ê¸°ë¦¿



## @chain ë°ì½”ë ˆì´í„°

---

`from langchain_core.runnables import chain`ìœ¼ë¡œ ê°€ì ¸ì™€ì„œ<br>`@chain` ë°ì½”ë ˆì´í„°ë¥¼ ì´ìš©í•´ **í•¨ìˆ˜ë¥¼ `chain`ìœ¼ë¡œ ë³€í™˜**í•˜ë„ë¡ í•©ì‹œë‹¤.

ì¦‰, `chain`ì€ `Runnable` ê°ì²´ì´ê¸° ë•Œë¬¸ì— LCEL ì¸í„°í˜ì´ìŠ¤ì— ë”°ë¼ `invoke()` ë©”ì„œë“œ ë“±ì„ í™œìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.



chain.get_graph().print_ascii()ë¡œ ì²´ì¸ì˜ ê·¸ë˜í”„ ì¶œë ¥ ê°€ëŠ¥<br>(`!pip install -qU grandalf` ê·¸ë˜í”„ ê·¸ë¦¬ëŠ” ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜í•´ì•¼ í•¨)

`chain.get_prompts()`ë¡œ ì²´ì¸ì˜ í”„ë¡¬í”„íŠ¸ í™•ì¸ ê°€ëŠ¥





## Helper í•¨ìˆ˜ì™€ Wrapper í•¨ìˆ˜

---

```python
"""
Helper í•¨ìˆ˜: Wrapper í•¨ìˆ˜ë¥¼ í†µí•´ì„œë§Œ ì‚¬ìš©ëœë‹¤ëŠ” ì˜ë¯¸ë¡œ _ë¥¼ ë¶™ì„
- ì‹¤ì œ ë¡œì§ì´ ì‹¤í–‰ë˜ëŠ” í•¨ìˆ˜
"""
def _multiple_length_function(text1, text2):  # ë‘ í…ìŠ¤íŠ¸ì˜ ê¸¸ì´ë¥¼ ê³±í•˜ëŠ” í•¨ìˆ˜
    return len(text1) * len(text2)

"""
Wrapper í•¨ìˆ˜: 2ê°œ ì¸ìë¥¼ ë°›ëŠ” í•¨ìˆ˜ë¡œ ì—°ê²°í•˜ëŠ” í•¨ìˆ˜
- Helper í•¨ìˆ˜ì—ì„œ ì‹¤ì œ ë¡œì§ì´ ì‹¤í–‰ë˜ê¸° ìœ„í•´, í˜•ì‹ì„ ë§ì¶°ì£¼ëŠ” í•¨ìˆ˜
- RunnableLambdaì—ì„œ ì¸ìëŠ” 1ê°œë¡œ ë°›ì•„ì•¼ í•˜ë¯€ë¡œ, ë”•ì…”ë„ˆë¦¬ í™œìš©
- ì´ í•¨ìˆ˜ì—ì„œë§Œ ì‚¬ìš©í•œë‹¤ëŠ” ì˜ë¯¸ì™€ dict ê¸°ë³¸ ëª…ë ¹ì–´ ê²¹ì¹˜ì§€ ì•Šê¸° ìœ„í•´ _dictë¼ëŠ” ì´ë¦„ì„ ì‚¬ìš©
"""
def multiple_length_function(
    _dict,
):  # ë”•ì…”ë„ˆë¦¬ì—ì„œ "text1"ê³¼ "text2"ì˜ ê¸¸ì´ë¥¼ ê³±í•˜ëŠ” í•¨ìˆ˜
    return _multiple_length_function(_dict["text1"], _dict["text2"])
```



## Configurable

---

`chain`ì— `config`ë¡œ ì „ë‹¬í•˜ëŠ” ë”•ì…”ë„ˆë¦¬(`RunnableConfig`)ì—ì„œ ì£¼ë¡œ ì“°ëŠ” ì•½ì†ëœ í‚¤ê°€ ëª‡ ê°€ì§€ ì¡´ì¬í•©ë‹ˆë‹¤. `chain.invoke(ì…ë ¥ê°’, config)`ë¡œ config ì„¤ì • ê°€ëŠ¥í•©ë‹ˆë‹¤. ì‚¬ìš©í•˜ëŠ” ë°©ë²•ì€ `Configurable`ì— ì±•í„°ì—ì„œ ìì„¸íˆ ë³´ê³ ì í•©ë‹ˆë‹¤.

1. `callbacks` (ê°€ì¥ ì¤‘ìš” â­)

   - **ì—­í• **: ì‹¤í–‰ ê³¼ì •ì„ ì§€ì¼œë³´ëŠ” ê°ì‹œì(í•¸ë“¤ëŸ¬)ë¥¼ ë“±ë¡í•©ë‹ˆë‹¤.


   - **ìš©ë„**: Log ì¶œë ¥, LangSmith ì¶”ì , ìŠ¤íŠ¸ë¦¬ë° ì²˜ë¦¬ ë“±.


   - **ì˜ˆì‹œ**: 

     ```
     {"callbacks": [ConsoleCallbackHandler()]}
     ```

2. `tags`

   - **ì—­í• **: ì´ ì‹¤í–‰ì— íƒœê·¸(ê¼¬ë¦¬í‘œ)ë¥¼ ë¶™ì…ë‹ˆë‹¤.


   - **ìš©ë„**: ë‚˜ì¤‘ì— ë¡œê·¸ë‚˜ LangSmithì—ì„œ "ì´ íƒœê·¸ ë‹¬ë¦° ê²ƒë§Œ ë³´ì—¬ì¤˜" í•˜ê³  í•„í„°ë§í•  ë•Œ ì”ë‹ˆë‹¤.


   - **ì˜ˆì‹œ**: 

     ```
     {"tags": ["my-tag", "experiment-1"]}
     ```


3. `metadata`

   - **ì—­í• **: ì¶”ê°€ì ì¸ ì •ë³´ë¥¼ ë”•ì…”ë„ˆë¦¬ë¡œ ì €ì¥í•©ë‹ˆë‹¤.


   - **ìš©ë„**: ì‚¬ìš©ì ID, ì„¸ì…˜ ID ì²˜ëŸ¼ ì‹¤í–‰ ë¡œì§ì—ëŠ” ì˜í–¥ì´ ì—†ì§€ë§Œ ê¸°ë¡í•´ë‘ê³  ì‹¶ì€ ì •ë³´ë“¤.


   - **ì˜ˆì‹œ**: 

     ```
     {"metadata": {"user_id": "123", "session_id": "abc"}}
     ```

4. `run_name`

   - **ì—­í• **: ì´ ì‹¤í–‰(Run)ì˜ ì´ë¦„ì„ ê°•ì œë¡œ ì§€ì •í•©ë‹ˆë‹¤.


   - **ìš©ë„**: LangSmith íŠ¸ë ˆì´ìŠ¤ í™”ë©´ì—ì„œ "RunnableLambda" ëŒ€ì‹  "ë‚´ ìˆ˜ì • í•¨ìˆ˜" ì²˜ëŸ¼ ì˜ˆìœ ì´ë¦„ìœ¼ë¡œ ë³´ê³  ì‹¶ì„ ë•Œ.


   - **ì˜ˆì‹œ**: 

     ```
     {"run_name": "MyCustomParsingJob"}
     ```

5. `recursion_limit`

   - **ì—­í• **: ì²´ì¸ì´ ë„ˆë¬´ ê¹Šê²Œ ëº‘ëº‘ì´ ë„ëŠ” ê²ƒì„ ë§‰ìŠµë‹ˆë‹¤. (ê¸°ë³¸ê°’ 25)


   - **ìš©ë„**: ë¬´í•œ ë£¨í”„ ë°©ì§€.


   - **ì˜ˆì‹œ**: 

     ```
     {"recursion_limit": 10}
     ```


&nbsp;

ì´ì™¸ì—ë„ `configurable_field()` ë©”ì„œë“œë¥¼ ì´ìš©í•´ LLM ëª¨ë¸ì„ ìƒì„±í•œ í›„<br>**`config`ì—ì„œ `configurable`í‚¤ë¥¼ ì„¤ì •í•´ LLM ëª¨ë¸ì˜ í•„ë“œ(íŒŒë¼ë¯¸í„°)ë¥¼ ë™ì ìœ¼ë¡œ ë°”ê¿€ ìˆ˜ ìˆìŠµë‹ˆë‹¤.**

&nbsp;

&nbsp;

ì•ì„œ ì–˜ê¸°í•œ **configurable**ì— ëŒ€í•´ ë” êµ¬ì²´ì ì´ê³  ëª…í™•í•˜ê²Œ ì •ë¦¬í•˜ê³ ì í•©ë‹ˆë‹¤.

### ë™ì  ë³€ê²½ì„ í—ˆìš©í•  'ì†ì„±/Runnable ëŒ€ì•ˆ' ì •ì˜í•˜ëŠ” ë°©ë²•

1. `.configurable_fields()`: ë™ì  ë³€ê²½ ê°€ëŠ¥í•œ ì†ì„±(í•„ë“œ)ì„ ì •ì˜í•˜ëŠ” ë©”ì„œë“œ

   [ë™ì  ë³€ê²½í•  ChatOpenAIì˜ model_name ì†ì„± ì •ì˜]

   ```python
   from langchain.prompts import PromptTemplate
   from langchain_core.runnables import ConfigurableField
   from langchain_openai import ChatOpenAI
   
   # model_name: ë™ì  ì„¤ì • ê°€ëŠ¥ (default:gpt-4o)
   model = ChatOpenAI(temperature=0, model_name="gpt-4o").configurable_fields(
   	# ChatOpenAIì˜ í•„ë“œ model_nameì„ ë™ì ìœ¼ë¡œ ë³€ê²½í•  ê²ƒì„ì„ ì„¤ì •
       model_name=ConfigurableField(
           id="gpt_version",  # model_nameì˜ id ì„¤ì •
           name="Version of GPT",  # model_nameì˜ ì´ë¦„ ì„¤ì •
           # model_nameì˜ ì„¤ëª… ì„¤ì •
           description="Official model name of GPTs. ex) gpt-4o, gpt-4o-mini",
       )
   )
   ```

   * `ChatOpenAI`ì— `configurable_fields()` ë©”ì„œë“œë¥¼ ì´ìš©í•´ ì†ì„± `model_name`ì„ ë™ì  ë³€ê²½ ê°€ëŠ¥í•œ ì†ì„±ìœ¼ë¡œ ì •ì˜í•¨
   * ì†ì„± `model_name`ì— `ConfigurableField`ì„ ì´ìš©í•´ ì •ì˜í•¨
   * ì†ì„± ë³€ê²½ ì‹œ, `model_name`ì˜ `id` ê°’ì¸ `gpt_version`ì— ë³€ê²½í•  ê°’ì„ ì£¼ë©´ ë¨

   &nbsp;

   [HubRunnableì„ ì´ìš©í•œ ë­ì²´ì¸ í—ˆë¸Œ í”„ë¡¬í”„íŠ¸ ë™ì  ë³€ê²½ ì •ì˜]

   ```python
   from langchain.runnables.hub import HubRunnable
   
   prompt = HubRunnable("teddynote/rag-prompt-korean").configurable_fields(
       # ì†Œìœ ì ì €ì¥ì†Œ ì»¤ë°‹ì„ ì„¤ì •í•˜ëŠ” ConfigurableField
       owner_repo_commit=ConfigurableField(  # â­ï¸ owner_repo_commitëŠ” "teddynote/rag-prompt-korean" ë¶€ë¶„ì„ ë§í•˜ëŠ” ê²ƒ â­ï¸
           # í•„ë“œì˜ ID
           id="hub_commit",
           # í•„ë“œì˜ ì´ë¦„
           name="Hub Commit",
           # í•„ë“œì— ëŒ€í•œ ì„¤ëª…
           description="Korean RAG prompt by teddynote",
       )
   )
   prompt
   ```

   * `HubRunnable`ì— `configurable_fields()` ë©”ì„œë“œë¥¼ ì´ìš©í•´ ì†ì„± `owner_repo_commit`ì„ ë™ì  ë³€ê²½ ê°€ëŠ¥í•œ ì†ì„±ìœ¼ë¡œ ì •ì˜í•¨
     * **ì •í™•íˆ ë§í•˜ìë©´, LangChain Hubì—ì„œ í”„ë¡¬í”„íŠ¸ ë¶ˆëŸ¬ì˜¤ëŠ” repo ì†ì„±ì„ ë³€ê²½í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤!!!**
   * ì†ì„± `owner_repo_commit`ì— `ConfigurableField`ì„ ì´ìš©í•´ ì •ì˜í•¨
   * ì†ì„± ë³€ê²½ ì‹œ, `owner_repo_commit`ì˜ `id` ê°’ì¸ `hub_commit`ì— ë³€ê²½í•  ê°’ì„ ì£¼ë©´ ë¨



2. `.configurable_alternatives()`: Runnable ê°ì²´ ëŒ€ì•ˆì„ ì •ì˜í•˜ëŠ” ë©”ì„œë“œ

   [LLMì˜ ê°ì²´ ëŒ€ì•ˆ ì •ì˜]

   ```python
   from langchain.prompts import PromptTemplate
   from langchain_anthropic import ChatAnthropic
   from langchain_core.runnables import ConfigurableField
   from langchain_openai import ChatOpenAI
   
   # â­ï¸ configurable_alternatives: Runnable ê°ì²´ ìì²´ë¥¼ ë°”ê¿ˆ â­ï¸
   
   llm = ChatAnthropic(
       temperature=0, model="claude-3-5-sonnet-20240620"
   ).configurable_alternatives(
       # ì´ í•„ë“œì— idë¥¼ ë¶€ì—¬í•©ë‹ˆë‹¤.
       # ìµœì¢… ì‹¤í–‰ ê°€ëŠ¥í•œ ê°ì²´ë¥¼ êµ¬ì„±í•  ë•Œ, ì´ idë¥¼ ì‚¬ìš©í•˜ì—¬ ì´ í•„ë“œë¥¼ êµ¬ì„±í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
       ConfigurableField(id="llm"),
       # ê¸°ë³¸ í‚¤ë¥¼ ì„¤ì •í•©ë‹ˆë‹¤.
       # â­ï¸ configurableì—ì„œ llmì— ì´ í‚¤ë¥¼ ì§€ì •í•˜ë©´ ìœ„ì—ì„œ ì´ˆê¸°í™”ëœ ê¸°ë³¸ LLM(ChatAnthropic(temperature=0, model="claude-3-5-sonnet-20240620"))ì´ ì‚¬ìš©ë©ë‹ˆë‹¤. â­ï¸
       default_key="anthropic",
       # 'openai'ë¼ëŠ” ì´ë¦„ì˜ ìƒˆ ì˜µì…˜ì„ ì¶”ê°€í•˜ë©°, ì´ëŠ” `ChatOpenAI()`ì™€ ë™ì¼í•©ë‹ˆë‹¤.
       openai=ChatOpenAI(model="gpt-4o-mini"),
       # 'gpt4'ë¼ëŠ” ì´ë¦„ì˜ ìƒˆ ì˜µì…˜ì„ ì¶”ê°€í•˜ë©°, ì´ëŠ” `ChatOpenAI(model="gpt-4")`ì™€ ë™ì¼í•©ë‹ˆë‹¤.
       gpt4o=ChatOpenAI(model="gpt-4o"),
       # ì—¬ê¸°ì— ë” ë§ì€ êµ¬ì„± ì˜µì…˜ì„ ì¶”ê°€í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
   )
   prompt = PromptTemplate.from_template("{topic} ì— ëŒ€í•´ ê°„ë‹¨íˆ ì„¤ëª…í•´ì£¼ì„¸ìš”.")
   chain = prompt | llm
   ```

   * `ChatAnthropic`ì— `configurable_alternatives()` ë©”ì„œë“œë¥¼ ì´ìš©í•´ LLM ëª¨ë¸ ìì²´ë¥¼ ë³€ê²½ ê°€ëŠ¥í•˜ë„ë¡ ì •ì˜í•¨<br>(ì†ì„± ë³€ê²½ì´ ì•„ë‹ˆë¯€ë¡œ ë©”ì„œë“œì— í•„ë“œëª… ì—†ì´ ë°”ë¡œ `ConfigurableField` ë„£ìŒ)

   * LLM ëª¨ë¸ ë³€ê²½ ì‹œ

     * `id` ê°’ì¸ `llm`ì— ë³€ê²½í•  ê°’ì„ ì£¼ë©´ ë¨

     * `id`ì— ì¤„ ìˆ˜ ìˆëŠ” ë³€ê²½ ê°€ëŠ¥í•œ ê°’

       * `anthropic`: `default_key`ë¡œ ì„¤ì •í•œ ì›ë˜ ëª¨ë¸ ì„¤ì •<br>(`ChatAnthropic(temperature=0, model="claude-3-5-sonnet-20240620")`)ì„ ì´ìš©í•  ë•Œ, `id`ì— ì¤„ ê°’
       *  `openai`: `ChatOpenAI(model="gpt-4o-mini")`ë¡œ ì„¤ì •
       * `gpt4o`: `ChatOpenAI(model="gpt-4o")`ë¡œ ì„¤ì •

     * ëª¨ë¸ ë³€ê²½ ë°©ë²• ì˜ˆì‹œ

       ```python
       chain.with_config(configurable={"llm": "openai"}).invoke({"topic": "ë‰´ì§„ìŠ¤"})
       ```

   [í”„ë¡¬í”„íŠ¸ ê°ì²´ ëŒ€ì•ˆ ì •ì˜]

   ```python
   # ì–¸ì–´ ëª¨ë¸ì„ ì´ˆê¸°í™”í•˜ê³  temperatureë¥¼ 0ìœ¼ë¡œ ì„¤ì •í•©ë‹ˆë‹¤.
   llm = ChatOpenAI(temperature=0)
   
   prompt = PromptTemplate.from_template(
       "{country} ì˜ ìˆ˜ë„ëŠ” ì–´ë””ì•¼?"  # ê¸°ë³¸ í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿
   ).configurable_alternatives(
       # ì´ í•„ë“œì— idë¥¼ ë¶€ì—¬í•©ë‹ˆë‹¤. (â­ï¸ ë³€ê²½í•  ê°’ì„ prompt ë³€ìˆ˜ëª…ì— ë„£ìœ¼ë©´ ë¨ â­ï¸)
       ConfigurableField(id="prompt"),
       # ê¸°ë³¸ í‚¤ë¥¼ ì„¤ì •í•©ë‹ˆë‹¤. -> â­ï¸ configurableì—ì„œ promptì— capitalë¡œ ë„£ìœ¼ë©´ ì›ë˜ í”„ë¡¬í”„íŠ¸ "{country} ì˜ ìˆ˜ë„ëŠ” ì–´ë””ì•¼?"ë¡œ ì„¤ì •ë¨ â­ï¸
       default_key="capital",
       # 'area'ì´ë¼ëŠ” ìƒˆë¡œìš´ ì˜µì…˜ì„ ì¶”ê°€í•©ë‹ˆë‹¤.
       area=PromptTemplate.from_template("{country} ì˜ ë©´ì ì€ ì–¼ë§ˆì•¼?"),
       # 'population'ì´ë¼ëŠ” ìƒˆë¡œìš´ ì˜µì…˜ì„ ì¶”ê°€í•©ë‹ˆë‹¤.
       population=PromptTemplate.from_template("{country} ì˜ ì¸êµ¬ëŠ” ì–¼ë§ˆì•¼?"),
       # 'eng'ì´ë¼ëŠ” ìƒˆë¡œìš´ ì˜µì…˜ì„ ì¶”ê°€í•©ë‹ˆë‹¤.
       eng=PromptTemplate.from_template("{input} ì„ ì˜ì–´ë¡œ ë²ˆì—­í•´ì£¼ì„¸ìš”."),
       # ì—¬ê¸°ì— ë” ë§ì€ êµ¬ì„± ì˜µì…˜ì„ ì¶”ê°€í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
   )
   
   # í”„ë¡¬í”„íŠ¸ì™€ ì–¸ì–´ ëª¨ë¸ì„ ì—°ê²°í•˜ì—¬ ì²´ì¸ì„ ìƒì„±í•©ë‹ˆë‹¤.
   chain = prompt | llm
   ```

   LLM ê°ì²´ ëŒ€ì•ˆ ì„¤ì •ê³¼ ë¹„ìŠ·í•©ë‹ˆë‹¤ !!



3. `ConfigurableField()`: ë™ì ìœ¼ë¡œ ë³€ê²½í•  í•„ë“œ ì •ì˜

   * `id` : ë™ì ìœ¼ë¡œ ë³€ê²½í•  í•„ë“œëª…ì„ ëŒ€ì‹ í•  ë³€ìˆ˜ëª…(í•„ìˆ˜ë¡œ ì§€ì •)<br>ex ChatOpenAIì˜ model_name í•„ë“œëª…ì„ gpt_versionìœ¼ë¡œ ëŒ€ì‹ í•¨ -> ë‚˜ì¤‘ì— gpt_versionì— ì†ì„±ê°’ì„ ì§€ì •í•¨

   * `name`: idì— ëŒ€í•œ ì´ë¦„
     * ë™ì ìœ¼ë¡œ ë³€ê²½í•˜ëŠ” í•„ë“œëª…ì´ ë¬´ì—‡ì¸ì§€ ì´ë¦„ì„ ì •í•¨

   * `description`: í•´ë‹¹ í•„ë“œì— ëŒ€í•œ ì„¤ëª…

&nbsp;

### ì†ì„±ì„ ë³€ê²½í•˜ëŠ” ë°©ë²•

1. `.invoke(config={"configurable": {id: ë°”ê¾¸ê³ ì í•˜ëŠ” ê°’}})`: chainì—ì„œ `invoke()` í˜¸ì¶œ ì‹œ config ì„¤ì •ìœ¼ë¡œ ì†ì„±ì„ ë™ì ìœ¼ë¡œ ë³€ê²½í•©ë‹ˆë‹¤.

   ```python
   # gpt_version(model_nameì˜ ConfigurableFieldì—ì„œ id)ì„ gpt-3.5-turboë¡œ ë™ì  ì„¤ì •
   model.invoke(
       "ëŒ€í•œë¯¼êµ­ì˜ ìˆ˜ë„ëŠ” ì–´ë””ì•¼?",
       config={"configurable": {"gpt_version": "gpt-3.5-turbo"}},
   )
   ```

2. `.with_config(configurable={id: ë°”ê¾¸ê³ ìí•˜ëŠ” ê°’})`: ì†ì„± ë˜ëŠ” ê°ì²´ë¥¼ ë™ì  ë³€ê²½ì„ ìœ„í•œ Runnableì˜ ë©”ì„œë“œ<br>(`configurable` ê°’ì— ë°”ê¿€ ê°’ì„ ì „ë‹¬í•©ë‹ˆë‹¤.)

   ```python
   chain.with_config(configurable={"llm": "openai"}).invoke({"topic": "ë‰´ì§„ìŠ¤"})
   ```

ì°¨ì´ì : `invoke`ì—ì„œ config ì„¤ì •ì€ **"ì´ë²ˆ í•œ ë²ˆë§Œ ì‹¤í–‰í•  ë•Œ ì ìš©"**í•˜ëŠ” ëŠë‚Œì´ê³ , `.with_config()`ëŠ” "ì„¤ì •ì´ ì ìš©ëœ ìƒˆë¡œìš´ ì²´ì¸ ê°ì²´ë¥¼ ì•„ì˜ˆ ë§Œë“¤ì–´ë‚´ëŠ”" ëŠë‚Œì…ë‹ˆë‹¤. (ê·¸ë˜ì„œ ë³€ìˆ˜ì— ì €ì¥í•´ì„œ ì¬ì‚¬ìš© ê°€ëŠ¥)

&nbsp;

&nbsp;

## Route

---

ë¼ìš°íŒ…ì€ ì´ì „ ë‹¨ê³„ì˜ ì¶œë ¥ì´ ê²½ë¡œë¥¼ ì •í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤.<br>**ê°„ë‹¨í•œ ì§ˆë¬¸ ë¶„ë¥˜**ë‚˜ **ì£¼ì œ ë¶„ë¥˜** ë“±ì— ìœ ìš©í•œ ë°©ì‹ì´ì£ .

ìœ ì €ì˜ ì§ˆë¬¸ì´ ë“¤ì–´ì™”ì„ ë•Œ ë¼ìš°íŒ…ì„ í•˜ëŠ” ë°©ë²•ì€<br>`RunnableLambda`, `RunnableBranch` 2ê°€ì§€ê°€ ì¡´ì¬í•©ë‹ˆë‹¤.

&nbsp;

### `RunnableLambda`ì—ì„œ Routing

`route`ë¥¼ ì •í•´ì£¼ëŠ” `route_chain` ìƒì„±

```python
from langchain_openai import ChatOpenAI
from langchain_core.output_parsers import StrOutputParser
from langchain_core.prompts import PromptTemplate

route_prompt = PromptTemplate.from_template(
    """ì£¼ì–´ì§„ ì‚¬ìš©ì ì§ˆë¬¸ì„ `ìˆ˜í•™`, `ê³¼í•™`, ë˜ëŠ” `ê¸°íƒ€` ì¤‘ í•˜ë‚˜ë¡œ ë¶„ë¥˜í•˜ì„¸ìš”. í•œ ë‹¨ì–´ ì´ìƒìœ¼ë¡œ ì‘ë‹µí•˜ì§€ ë§ˆì„¸ìš”.

<question>
{question}
</question>

Classification:"""
)

# ì²´ì¸ ìƒì„±
route_chain = (
    route_prompt
    | ChatOpenAI(model="gpt-4o-mini")
    | StrOutputParser()
)
```

&nbsp;

`route`ë³„ ìˆ˜í–‰í•´ì•¼ í•  `chain` ìƒì„±

```python
math_chain = (
    PromptTemplate.from_template(
        """You are an expert in math. \
Always answer questions starting with "ê¹¨ë´‰ì„ ìƒë‹˜ê»˜ì„œ ë§ì”€í•˜ì‹œê¸°ë¥¼..". \
Respond to the following question:

Question: {question}
Answer:"""
    )
    | ChatOpenAI(model="gpt-4o-mini")
)

science_chain = (
    PromptTemplate.from_template(
        """You are an expert in science. \
Always answer questions starting with "ì•„ì´ì‘ ë‰´í„´ ì„ ìƒë‹˜ê»˜ì„œ ë§ì”€í•˜ì‹œê¸°ë¥¼..". \
Respond to the following question:

Question: {question}
Answer:"""
    )
    | ChatOpenAI(model="gpt-4o-mini")
)

general_chain = (
    PromptTemplate.from_template(
        """Respond to the following question concisely:

Question: {question}
Answer:"""
    )
    | ChatOpenAI(model="gpt-4o-mini")
)
```

&nbsp;

ì •í•´ì§„ `route`ì— ë”°ë¼ `chain`ìœ¼ë¡œ ì•ˆë‚´í•˜ëŠ” êµì°¨ë¡œ ì—­í• ì˜ í•¨ìˆ˜ ì •ì˜

```python
# RunnableLambdaë¡œ ì‹¤í–‰ë˜ëŠ” í•¨ìˆ˜ì´ë¯€ë¡œ, ì¸ìëŠ” 1ê°œë¥¼ ë°›ì•„ì™€ì•¼ í•¨
# info = {"topic": route_chain ê²°ê³¼, "question": ì‚¬ìš©ì ì…ë ¥}
def route(info):
    # ì£¼ì œì— "ìˆ˜í•™"ì´ í¬í•¨ë˜ì–´ ìˆëŠ” ê²½ìš°
    if "ìˆ˜í•™" in info["topic"].lower():
        # datascience_chainì„ ë°˜í™˜
        return math_chain
    # ì£¼ì œì— "ê³¼í•™"ì´ í¬í•¨ë˜ì–´ ìˆëŠ” ê²½ìš°
    elif "ê³¼í•™" in info["topic"].lower():
        # art_chainì„ ë°˜í™˜
        return science_chain
    # ê·¸ ì™¸ì˜ ê²½ìš°
    else:
        # general_chainì„ ë°˜í™˜
        return general_chain
```

&nbsp;

ì´ë“¤ì„ ëª¨ë‘ ì—®ì–´ì£¼ëŠ” ë©”ì¸ chain

```python
from operator import itemgetter
from langchain_core.runnables import RunnableLambda

full_chain = (
    {"topic": route_chain, "question": itemgetter("question")}
    | RunnableLambda(
        # ê²½ë¡œë¥¼ ì§€ì •í•˜ëŠ” í•¨ìˆ˜ë¥¼ ì¸ìë¡œ ì „ë‹¬í•©ë‹ˆë‹¤.
        route
    )
    | StrOutputParser()
)
```

`{"topic": route_chain, "question": itemgetter("question")}`ë¶€í„° ì´í•´ê°€ ì•ˆ ê°ˆ ìˆ˜ ìˆì§€ë§Œ

1ê°€ì§€ ê¸°ì–µí•©ì‹œë‹¤.

> **"chainì—ëŠ” ë”•ì…”ë„ˆë¦¬ í˜•íƒœë¡œ ê³„ì† ë¬´ì–¸ê°€ê°€ ì „ë‹¬ëœë‹¤."**

ì¦‰,

**ì „ë‹¬ë˜ëŠ” ê²ƒê³¼ ì¶œë ¥ë˜ëŠ” ê²ƒë“¤ì— ì§‘ì¤‘í•˜ê³ <br>í•­ìƒ ì…ë ¥ì„ ë”•ì…”ë„ˆë¦¬ë¡œ ë°›ì•„ì˜¨ í›„, itemgetter ë“±ìœ¼ë¡œ ë½‘ì•„ì„œ ì‚¬ìš©ëœë‹¤ëŠ” ê²ƒì„ ìŠì§€ ë§ì.**

&nbsp;

ì‚¬ìš©ì ì…ë ¥ì€

1. `chain`ì— ì „ë‹¬ë¼ì„œ ì£¼ì œë¥¼ ê°€ì ¸ì™€ `topic`ì— ì €ì¥í•˜ê³ 
1. `question`ì— ê·¸ëŒ€ë¡œ ì €ì¥ë©ë‹ˆë‹¤.

`topic`ê³¼ `question`ì€ `RunnableLambda`ì— ì˜í•´<br>`route` í•¨ìˆ˜ì—ì„œ `info` ë”•ì…”ë„ˆë¦¬ë¡œ ê·¸ëŒ€ë¡œ ë°›ì•„ì™€ `topic`ì— ë”°ë¼ ë£¨íŠ¸ê°€ ì •í•´ì§‘ë‹ˆë‹¤.

ê²°êµ­, í•´ë‹¹ ì£¼ì œë³„ ì²´ì¸ì— `topic`ê³¼ `question`ì´ ì „ë‹¬ë˜ë©´ì„œ ë³€ìˆ˜ì— ë§ê²Œ í”„ë¡¬í”„íŠ¸ê°€ ì±„ì›Œì§€ëŠ” ê±°ì£ .

&nbsp;

`full_chain.get_graph().print_ascii()`ë¥¼ í•˜ë©´

```python
+-------------------------------+                      
                    | Parallel<topic,question>Input |                      
                    +-------------------------------+                      
                             ***           ***                             
                           **                 **                           
                         **                     **                         
              +----------------+                  **                       
              | PromptTemplate |                   *                       
              +----------------+                   *                       
                       *                           *                       
                       *                           *                       
                       *                           *                       
                +------------+                     *                       
                | ChatOpenAI |                     *                       
                +------------+                     *                       
                       *                           *                       
                       *                           *                       
                       *                           *                       
              +-----------------+             +--------+                   
              | StrOutputParser |             | Lambda |                   
              +-----------------+             +--------+                   
                             ***           ***                             
                                **       **                                
                                  **   **                                  
                    +--------------------------------+                     
                    | Parallel<topic,question>Output |                     
                    +--------------------------------+                     
                                     *                                     
                                     *                                     
                                     *                                     
                              +-------------+                              
                              | route_input |                              
                          ****+-------------+****                          
                     *****           *           *****                     
                 ****                *                ****                 
              ***                    *                    ***              
+----------------+          +----------------+          +----------------+ 
| PromptTemplate |          | PromptTemplate |          | PromptTemplate | 
+----------------+          +----------------+          +----------------+ 
         *                           *                           *         
         *                           *                           *         
         *                           *                           *         
  +------------+              +------------+              +------------+   
  | ChatOpenAI |*             | ChatOpenAI |              | ChatOpenAI |   
  +------------+ ****         +------------+          ****+------------+   
                     *****           *           *****                     
                          ****       *       ****                          
                              ***    *    ***                              
                             +--------------+                              
                             | route_output |                              
                             +--------------+                              
                                     *                                     
                                     *                                     
                                     *                                     
                            +-----------------+                            
                            | StrOutputParser |                            
                            +-----------------+                            
                                     *                                     
                                     *                                     
                                     *                                     
                        +-----------------------+                          
                        | StrOutputParserOutput |                          
                        +-----------------------+
```

ì•„ë¦„ë‹¤ìš´ ê·¸ë¦¼ì´ ë‚˜ì™€ìš”.

&nbsp;

&nbsp;

### `RunnableBranch`ì—ì„œ Routing

`RunnableBranch`ëŠ” `if-elif-else`ì˜ `chain` ë²„ì „ì´ë¼ê³  ìƒê°í•˜ì‹œë©´ ë©ë‹ˆë‹¤.

ìš°ì„ , "`route`ë¥¼ ì •í•´ì£¼ëŠ” `route_chain` ìƒì„±", "`route`ë³„ ìˆ˜í–‰í•´ì•¼ í•  `chain` ìƒì„±"ì„ í•œ í›„

**êµì°¨ë¡œ ì—­í• ì¸ `route` í•¨ìˆ˜ì—ì„œ `if-elif-else`ë¬¸ì„ <br>`RunnableBranch`ì—ì„œ 3ê°œì˜ `Runnable` í˜•ì‹ìœ¼ë¡œ ë‚˜ì—´í•´ì£¼ë©´ ë©ë‹ˆë‹¤**.

```python
from operator import itemgetter
from langchain_core.runnables import RunnableBranch

branch = RunnableBranch(
    # ì£¼ì œì— "ìˆ˜í•™"ì´ í¬í•¨ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸í•˜ê³ , í¬í•¨ë˜ì–´ ìˆë‹¤ë©´ math_chainì„ ì‹¤í–‰í•©ë‹ˆë‹¤.
    (lambda x: "ìˆ˜í•™" in x["topic"].lower(), math_chain),
    # ì£¼ì œì— "ê³¼í•™"ì´ í¬í•¨ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸í•˜ê³ , í¬í•¨ë˜ì–´ ìˆë‹¤ë©´ science_chainì„ ì‹¤í–‰í•©ë‹ˆë‹¤.
    (lambda x: "ê³¼í•™" in x["topic"].lower(), science_chain),
    # ìœ„ì˜ ì¡°ê±´ì— í•´ë‹¹í•˜ì§€ ì•ŠëŠ” ê²½ìš° general_chainì„ ì‹¤í–‰í•©ë‹ˆë‹¤.
    general_chain,
)
# ì£¼ì œì™€ ì§ˆë¬¸ì„ ì…ë ¥ë°›ì•„ branchë¥¼ ì‹¤í–‰í•˜ëŠ” ì „ì²´ ì²´ì¸ì„ ì •ì˜í•©ë‹ˆë‹¤.
full_chain = (
    {"topic": route_chain, "question": itemgetter("question")} | branch | StrOutputParser()
)
```

`RunnableBranch`ì•ˆì—ì„œ `Runnable`ì¸ `lamda` í•¨ìˆ˜ë¡œ if, elif, else ìˆœìœ¼ë¡œ ë‚˜ì—´í•˜ë©´ ë©ë‹ˆë‹¤.

`lamda` í•¨ìˆ˜ëŠ” `(lamda ì…ë ¥: ì¡°ê±´, ì‹¤í–‰í•  ê²ƒ)` ì‹ìœ¼ë¡œ ì‘ì„±í•˜ë©°<br>ì•ì—ì„œë¶€í„° í•´ë‹¹í•˜ëŠ” ì¡°ê±´ì—ì„œ ì‹¤í–‰ë©ë‹ˆë‹¤.

&nbsp;

&nbsp;

ì—¬ê¸°ì„œ ëŠê³  ë„˜ì–´ê°€ë„ë¡ í•˜ê² ìŠµë‹ˆë‹¤. ğŸ‘ğŸ»

```toc

```
